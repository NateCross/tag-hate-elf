{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TRAIN = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The sky is blue and the sun is shining.\",\n",
    "    \"Cats are wonderful pets to have around the house.\",\n",
    "    \"Soccer is a popular sport played all around the world.\",\n",
    "    \"Pizza topped with cheese and pepperoni is my favorite.\",\n",
    "    \"Learning a new language can be challenging but rewarding.\",\n",
    "    \"Reading books is a great way to expand your knowledge.\",\n",
    "    \"The internet has revolutionized the way we communicate.\",\n",
    "    \"Music has the power to evoke strong emotions in people.\",\n",
    "    \"Exercise is important for maintaining good health.\",\n",
    "    \"Science has made incredible advancements in recent years.\",\n",
    "    \"Coffee is the fuel that keeps many people going throughout the day.\",\n",
    "    \"Traveling allows you to experience different cultures and cuisines.\",\n",
    "    \"The importance of education cannot be overstated.\",\n",
    "    \"Technology continues to progress at a rapid pace.\",\n",
    "    \"Dogs are known for their loyalty and companionship.\",\n",
    "    \"Cooking homemade meals can be a fun and rewarding activity.\",\n",
    "    \"Nature has a way of calming the mind and soothing the soul.\",\n",
    "    \"Artistic expression comes in many forms, from painting to music.\",\n",
    "    \"Happiness is often found in the simplest of things.\"\n",
    "]\n",
    "\n",
    "SAMPLE_TEST = [\n",
    "    \"TF-IDF, short for term frequency-inverse document frequency, is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents or a corpus.\",\n",
    "    \"The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word.\",\n",
    "    \"TF-IDF is commonly used in information retrieval and text mining as a weighting factor for scoring the relevance of a word to a document in a corpus.\",\n",
    "    \"The intuition behind TF-IDF is that words that occur frequently in a document but rarely in the corpus are more important in describing the content of the document.\",\n",
    "    \"In contrast, words that occur frequently in both the document and the corpus are less important as they are likely to be common words with less discriminative power.\",\n",
    "    \"To calculate the TF-IDF score for a word in a document, you multiply the term frequency (TF) by the inverse document frequency (IDF).\",\n",
    "    \"TF is the frequency of a term in a document, while IDF is the logarithmically scaled inverse fraction of the documents that contain the word.\",\n",
    "    \"By weighting the TF by IDF, the TF-IDF score penalizes words that are common across documents and emphasizes words that are unique to a specific document.\",\n",
    "    \"Once you have computed the TF-IDF scores for all words in a document, you can represent the document as a vector where each dimension corresponds to a word and the value corresponds to its TF-IDF score.\",\n",
    "    \"TF-IDF vectorization is a fundamental step in many natural language processing tasks, such as document classification, clustering, and information retrieval.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33779/715037670.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sklearn_tfidf = TfidfVectorizer()\n",
    "\n",
    "sklearn_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 111)\t2.0\n",
      "  (0, 93)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 62)\t1.0\n",
      "  (0, 81)\t1.0\n",
      "  (0, 67)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (1, 111)\t2.0\n",
      "  (1, 102)\t1.0\n",
      "  (1, 61)\t2.0\n",
      "  (1, 10)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 108)\t1.0\n",
      "  (1, 100)\t1.0\n",
      "  (2, 111)\t1.0\n",
      "  (2, 17)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (2, 121)\t1.0\n",
      "  (2, 87)\t1.0\n",
      "  (2, 115)\t1.0\n",
      "  (2, 52)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 55)\t1.0\n",
      "  (3, 111)\t1.0\n",
      "  :\t:\n",
      "  (17, 79)\t1.0\n",
      "  (17, 77)\t1.0\n",
      "  (17, 14)\t1.0\n",
      "  (17, 74)\t1.0\n",
      "  (17, 104)\t1.0\n",
      "  (17, 105)\t1.0\n",
      "  (18, 115)\t1.0\n",
      "  (18, 75)\t1.0\n",
      "  (18, 58)\t1.0\n",
      "  (18, 72)\t1.0\n",
      "  (18, 7)\t1.0\n",
      "  (18, 38)\t1.0\n",
      "  (18, 21)\t1.0\n",
      "  (18, 41)\t1.0\n",
      "  (18, 44)\t1.0\n",
      "  (18, 84)\t1.0\n",
      "  (19, 111)\t1.0\n",
      "  (19, 61)\t1.0\n",
      "  (19, 58)\t1.0\n",
      "  (19, 79)\t1.0\n",
      "  (19, 50)\t1.0\n",
      "  (19, 80)\t1.0\n",
      "  (19, 42)\t1.0\n",
      "  (19, 101)\t1.0\n",
      "  (19, 113)\t1.0\n"
     ]
    }
   ],
   "source": [
    "sklearn_result = sklearn_tfidf.fit_transform(SAMPLE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 30)\t0.35431563620454354\n",
      "  (0, 67)\t0.35431563620454354\n",
      "  (0, 81)\t0.35431563620454354\n",
      "  (0, 62)\t0.35431563620454354\n",
      "  (0, 43)\t0.35431563620454354\n",
      "  (0, 12)\t0.35431563620454354\n",
      "  (0, 93)\t0.35431563620454354\n",
      "  (0, 111)\t0.3481709487978384\n",
      "  (1, 100)\t0.38538683279827396\n",
      "  (1, 108)\t0.38538683279827396\n",
      "  (1, 4)\t0.2413270616212252\n",
      "  (1, 10)\t0.38538683279827396\n",
      "  (1, 61)\t0.45194360201823913\n",
      "  (1, 102)\t0.38538683279827396\n",
      "  (1, 111)\t0.3787032959282317\n",
      "  (2, 55)\t0.37322633729126187\n",
      "  (2, 6)\t0.3280716632883578\n",
      "  (2, 52)\t0.37322633729126187\n",
      "  (2, 115)\t0.23371222790400412\n",
      "  (2, 87)\t0.37322633729126187\n",
      "  (2, 121)\t0.37322633729126187\n",
      "  (2, 5)\t0.3280716632883578\n",
      "  (2, 17)\t0.37322633729126187\n",
      "  (2, 111)\t0.18337684636647475\n",
      "  (3, 122)\t0.36865801601525017\n",
      "  :\t:\n",
      "  (17, 77)\t0.35041531879418736\n",
      "  (17, 79)\t0.2779407757754563\n",
      "  (17, 51)\t0.254609184213604\n",
      "  (17, 118)\t0.2779407757754563\n",
      "  (17, 4)\t0.2194280967454082\n",
      "  (17, 111)\t0.34433827229526226\n",
      "  (18, 84)\t0.34369757070594353\n",
      "  (18, 44)\t0.34369757070594353\n",
      "  (18, 41)\t0.34369757070594353\n",
      "  (18, 21)\t0.34369757070594353\n",
      "  (18, 38)\t0.34369757070594353\n",
      "  (18, 7)\t0.34369757070594353\n",
      "  (18, 72)\t0.3021154254761827\n",
      "  (18, 58)\t0.24972811803651476\n",
      "  (18, 75)\t0.3021154254761827\n",
      "  (18, 115)\t0.2152214807718519\n",
      "  (19, 113)\t0.3851206199002829\n",
      "  (19, 101)\t0.3851206199002829\n",
      "  (19, 42)\t0.3851206199002829\n",
      "  (19, 80)\t0.3851206199002829\n",
      "  (19, 50)\t0.3851206199002829\n",
      "  (19, 79)\t0.30546816340834254\n",
      "  (19, 58)\t0.2798257998367937\n",
      "  (19, 61)\t0.2258157069164021\n",
      "  (19, 111)\t0.18922084990187302\n"
     ]
    }
   ],
   "source": [
    "print(sklearn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sklearn_tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 111,\n",
       " 'quick': 93,\n",
       " 'brown': 12,\n",
       " 'fox': 43,\n",
       " 'jumps': 62,\n",
       " 'over': 81,\n",
       " 'lazy': 67,\n",
       " 'dog': 30,\n",
       " 'sky': 102,\n",
       " 'is': 61,\n",
       " 'blue': 10,\n",
       " 'and': 4,\n",
       " 'sun': 108,\n",
       " 'shining': 100,\n",
       " 'cats': 17,\n",
       " 'are': 5,\n",
       " 'wonderful': 121,\n",
       " 'pets': 87,\n",
       " 'to': 115,\n",
       " 'have': 52,\n",
       " 'around': 6,\n",
       " 'house': 55,\n",
       " 'soccer': 103,\n",
       " 'popular': 90,\n",
       " 'sport': 106,\n",
       " 'played': 89,\n",
       " 'all': 2,\n",
       " 'world': 122,\n",
       " 'pizza': 88,\n",
       " 'topped': 116,\n",
       " 'with': 120,\n",
       " 'cheese': 19,\n",
       " 'pepperoni': 86,\n",
       " 'my': 76,\n",
       " 'favorite': 39,\n",
       " 'learning': 68,\n",
       " 'new': 78,\n",
       " 'language': 66,\n",
       " 'can': 15,\n",
       " 'be': 9,\n",
       " 'challenging': 18,\n",
       " 'but': 13,\n",
       " 'rewarding': 98,\n",
       " 'reading': 95,\n",
       " 'books': 11,\n",
       " 'great': 49,\n",
       " 'way': 118,\n",
       " 'expand': 36,\n",
       " 'your': 125,\n",
       " 'knowledge': 64,\n",
       " 'internet': 60,\n",
       " 'has': 51,\n",
       " 'revolutionized': 97,\n",
       " 'we': 119,\n",
       " 'communicate': 22,\n",
       " 'music': 75,\n",
       " 'power': 91,\n",
       " 'evoke': 34,\n",
       " 'strong': 107,\n",
       " 'emotions': 33,\n",
       " 'in': 58,\n",
       " 'people': 85,\n",
       " 'exercise': 35,\n",
       " 'important': 57,\n",
       " 'for': 40,\n",
       " 'maintaining': 71,\n",
       " 'good': 48,\n",
       " 'health': 53,\n",
       " 'science': 99,\n",
       " 'made': 70,\n",
       " 'incredible': 59,\n",
       " 'advancements': 1,\n",
       " 'recent': 96,\n",
       " 'years': 123,\n",
       " 'coffee': 20,\n",
       " 'fuel': 45,\n",
       " 'that': 110,\n",
       " 'keeps': 63,\n",
       " 'many': 72,\n",
       " 'going': 47,\n",
       " 'throughout': 114,\n",
       " 'day': 28,\n",
       " 'traveling': 117,\n",
       " 'allows': 3,\n",
       " 'you': 124,\n",
       " 'experience': 37,\n",
       " 'different': 29,\n",
       " 'cultures': 27,\n",
       " 'cuisines': 26,\n",
       " 'importance': 56,\n",
       " 'of': 79,\n",
       " 'education': 32,\n",
       " 'cannot': 16,\n",
       " 'overstated': 82,\n",
       " 'technology': 109,\n",
       " 'continues': 24,\n",
       " 'progress': 92,\n",
       " 'at': 8,\n",
       " 'rapid': 94,\n",
       " 'pace': 83,\n",
       " 'dogs': 31,\n",
       " 'known': 65,\n",
       " 'their': 112,\n",
       " 'loyalty': 69,\n",
       " 'companionship': 23,\n",
       " 'cooking': 25,\n",
       " 'homemade': 54,\n",
       " 'meals': 73,\n",
       " 'fun': 46,\n",
       " 'activity': 0,\n",
       " 'nature': 77,\n",
       " 'calming': 14,\n",
       " 'mind': 74,\n",
       " 'soothing': 104,\n",
       " 'soul': 105,\n",
       " 'artistic': 7,\n",
       " 'expression': 38,\n",
       " 'comes': 21,\n",
       " 'forms': 41,\n",
       " 'from': 44,\n",
       " 'painting': 84,\n",
       " 'happiness': 50,\n",
       " 'often': 80,\n",
       " 'found': 42,\n",
       " 'simplest': 101,\n",
       " 'things': 113}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lazy</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>over</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jumps</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fox</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brown</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quick</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  index\n",
       "0    dog     30\n",
       "1   lazy     67\n",
       "2   over     81\n",
       "3  jumps     62\n",
       "4    fox     43\n",
       "5  brown     12\n",
       "6  quick     93\n",
       "7    the    111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = sklearn_tfidf.get_feature_names_out()\n",
    "sentence_indices = [30, 67, 81, 62, 43, 12, 93, 111]\n",
    "vocabulary[[sentence_indices]]\n",
    "pd.DataFrame({\n",
    "  'text': vocabulary[sentence_indices],\n",
    "  'index': sentence_indices,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Lowercase text\n",
    "preprocess_train = [\n",
    "  text.lower()\n",
    "  for text \n",
    "  in SAMPLE_TRAIN\n",
    "]\n",
    "\n",
    "# Remove punctuation\n",
    "preprocess_train = [\n",
    "  re.sub(r'[^\\w\\s]', '', text)\n",
    "  for text\n",
    "  in preprocess_train\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unique word to set\n",
    "UNIQUE_WORDS = set()\n",
    "\n",
    "for sample in preprocess_train:\n",
    "  for word in sample.split(' '):\n",
    "    # Only add unique words of 2 or more characters\n",
    "    # SKLearn instead uses this regex pattern when\n",
    "    # processing text:\n",
    "    # r”(?u)\\b\\w\\w+\\b”\n",
    "    if len(word) < 2: continue\n",
    "    UNIQUE_WORDS.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity',\n",
       " 'advancements',\n",
       " 'all',\n",
       " 'allows',\n",
       " 'and',\n",
       " 'are',\n",
       " 'around',\n",
       " 'artistic',\n",
       " 'at',\n",
       " 'be',\n",
       " 'blue',\n",
       " 'books',\n",
       " 'brown',\n",
       " 'but',\n",
       " 'calming',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cats',\n",
       " 'challenging',\n",
       " 'cheese',\n",
       " 'coffee',\n",
       " 'comes',\n",
       " 'communicate',\n",
       " 'companionship',\n",
       " 'continues',\n",
       " 'cooking',\n",
       " 'cuisines',\n",
       " 'cultures',\n",
       " 'day',\n",
       " 'different',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'education',\n",
       " 'emotions',\n",
       " 'evoke',\n",
       " 'exercise',\n",
       " 'expand',\n",
       " 'experience',\n",
       " 'expression',\n",
       " 'favorite',\n",
       " 'for',\n",
       " 'forms',\n",
       " 'found',\n",
       " 'fox',\n",
       " 'from',\n",
       " 'fuel',\n",
       " 'fun',\n",
       " 'going',\n",
       " 'good',\n",
       " 'great',\n",
       " 'happiness',\n",
       " 'has',\n",
       " 'have',\n",
       " 'health',\n",
       " 'homemade',\n",
       " 'house',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'in',\n",
       " 'incredible',\n",
       " 'internet',\n",
       " 'is',\n",
       " 'jumps',\n",
       " 'keeps',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'language',\n",
       " 'lazy',\n",
       " 'learning',\n",
       " 'loyalty',\n",
       " 'made',\n",
       " 'maintaining',\n",
       " 'many',\n",
       " 'meals',\n",
       " 'mind',\n",
       " 'music',\n",
       " 'my',\n",
       " 'nature',\n",
       " 'new',\n",
       " 'of',\n",
       " 'often',\n",
       " 'over',\n",
       " 'overstated',\n",
       " 'pace',\n",
       " 'painting',\n",
       " 'people',\n",
       " 'pepperoni',\n",
       " 'pets',\n",
       " 'pizza',\n",
       " 'played',\n",
       " 'popular',\n",
       " 'power',\n",
       " 'progress',\n",
       " 'quick',\n",
       " 'rapid',\n",
       " 'reading',\n",
       " 'recent',\n",
       " 'revolutionized',\n",
       " 'rewarding',\n",
       " 'science',\n",
       " 'shining',\n",
       " 'simplest',\n",
       " 'sky',\n",
       " 'soccer',\n",
       " 'soothing',\n",
       " 'soul',\n",
       " 'sport',\n",
       " 'strong',\n",
       " 'sun',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'things',\n",
       " 'throughout',\n",
       " 'to',\n",
       " 'topped',\n",
       " 'traveling',\n",
       " 'way',\n",
       " 'we',\n",
       " 'with',\n",
       " 'wonderful',\n",
       " 'world',\n",
       " 'years',\n",
       " 'you',\n",
       " 'your'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIQUE_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIQUE_WORDS == set(sklearn_tfidf.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our dictionaries\n",
    "WORD_TO_INDEX = {}\n",
    "INDEX_TO_WORD = {}\n",
    "\n",
    "for index, word in enumerate(sorted(list(UNIQUE_WORDS))):\n",
    "  WORD_TO_INDEX[word] = index\n",
    "  INDEX_TO_WORD[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity': 0,\n",
       " 'advancements': 1,\n",
       " 'all': 2,\n",
       " 'allows': 3,\n",
       " 'and': 4,\n",
       " 'are': 5,\n",
       " 'around': 6,\n",
       " 'artistic': 7,\n",
       " 'at': 8,\n",
       " 'be': 9,\n",
       " 'blue': 10,\n",
       " 'books': 11,\n",
       " 'brown': 12,\n",
       " 'but': 13,\n",
       " 'calming': 14,\n",
       " 'can': 15,\n",
       " 'cannot': 16,\n",
       " 'cats': 17,\n",
       " 'challenging': 18,\n",
       " 'cheese': 19,\n",
       " 'coffee': 20,\n",
       " 'comes': 21,\n",
       " 'communicate': 22,\n",
       " 'companionship': 23,\n",
       " 'continues': 24,\n",
       " 'cooking': 25,\n",
       " 'cuisines': 26,\n",
       " 'cultures': 27,\n",
       " 'day': 28,\n",
       " 'different': 29,\n",
       " 'dog': 30,\n",
       " 'dogs': 31,\n",
       " 'education': 32,\n",
       " 'emotions': 33,\n",
       " 'evoke': 34,\n",
       " 'exercise': 35,\n",
       " 'expand': 36,\n",
       " 'experience': 37,\n",
       " 'expression': 38,\n",
       " 'favorite': 39,\n",
       " 'for': 40,\n",
       " 'forms': 41,\n",
       " 'found': 42,\n",
       " 'fox': 43,\n",
       " 'from': 44,\n",
       " 'fuel': 45,\n",
       " 'fun': 46,\n",
       " 'going': 47,\n",
       " 'good': 48,\n",
       " 'great': 49,\n",
       " 'happiness': 50,\n",
       " 'has': 51,\n",
       " 'have': 52,\n",
       " 'health': 53,\n",
       " 'homemade': 54,\n",
       " 'house': 55,\n",
       " 'importance': 56,\n",
       " 'important': 57,\n",
       " 'in': 58,\n",
       " 'incredible': 59,\n",
       " 'internet': 60,\n",
       " 'is': 61,\n",
       " 'jumps': 62,\n",
       " 'keeps': 63,\n",
       " 'knowledge': 64,\n",
       " 'known': 65,\n",
       " 'language': 66,\n",
       " 'lazy': 67,\n",
       " 'learning': 68,\n",
       " 'loyalty': 69,\n",
       " 'made': 70,\n",
       " 'maintaining': 71,\n",
       " 'many': 72,\n",
       " 'meals': 73,\n",
       " 'mind': 74,\n",
       " 'music': 75,\n",
       " 'my': 76,\n",
       " 'nature': 77,\n",
       " 'new': 78,\n",
       " 'of': 79,\n",
       " 'often': 80,\n",
       " 'over': 81,\n",
       " 'overstated': 82,\n",
       " 'pace': 83,\n",
       " 'painting': 84,\n",
       " 'people': 85,\n",
       " 'pepperoni': 86,\n",
       " 'pets': 87,\n",
       " 'pizza': 88,\n",
       " 'played': 89,\n",
       " 'popular': 90,\n",
       " 'power': 91,\n",
       " 'progress': 92,\n",
       " 'quick': 93,\n",
       " 'rapid': 94,\n",
       " 'reading': 95,\n",
       " 'recent': 96,\n",
       " 'revolutionized': 97,\n",
       " 'rewarding': 98,\n",
       " 'science': 99,\n",
       " 'shining': 100,\n",
       " 'simplest': 101,\n",
       " 'sky': 102,\n",
       " 'soccer': 103,\n",
       " 'soothing': 104,\n",
       " 'soul': 105,\n",
       " 'sport': 106,\n",
       " 'strong': 107,\n",
       " 'sun': 108,\n",
       " 'technology': 109,\n",
       " 'that': 110,\n",
       " 'the': 111,\n",
       " 'their': 112,\n",
       " 'things': 113,\n",
       " 'throughout': 114,\n",
       " 'to': 115,\n",
       " 'topped': 116,\n",
       " 'traveling': 117,\n",
       " 'way': 118,\n",
       " 'we': 119,\n",
       " 'with': 120,\n",
       " 'wonderful': 121,\n",
       " 'world': 122,\n",
       " 'years': 123,\n",
       " 'you': 124,\n",
       " 'your': 125}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_tfidf.vocabulary_ == WORD_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'activity',\n",
       " 1: 'advancements',\n",
       " 2: 'all',\n",
       " 3: 'allows',\n",
       " 4: 'and',\n",
       " 5: 'are',\n",
       " 6: 'around',\n",
       " 7: 'artistic',\n",
       " 8: 'at',\n",
       " 9: 'be',\n",
       " 10: 'blue',\n",
       " 11: 'books',\n",
       " 12: 'brown',\n",
       " 13: 'but',\n",
       " 14: 'calming',\n",
       " 15: 'can',\n",
       " 16: 'cannot',\n",
       " 17: 'cats',\n",
       " 18: 'challenging',\n",
       " 19: 'cheese',\n",
       " 20: 'coffee',\n",
       " 21: 'comes',\n",
       " 22: 'communicate',\n",
       " 23: 'companionship',\n",
       " 24: 'continues',\n",
       " 25: 'cooking',\n",
       " 26: 'cuisines',\n",
       " 27: 'cultures',\n",
       " 28: 'day',\n",
       " 29: 'different',\n",
       " 30: 'dog',\n",
       " 31: 'dogs',\n",
       " 32: 'education',\n",
       " 33: 'emotions',\n",
       " 34: 'evoke',\n",
       " 35: 'exercise',\n",
       " 36: 'expand',\n",
       " 37: 'experience',\n",
       " 38: 'expression',\n",
       " 39: 'favorite',\n",
       " 40: 'for',\n",
       " 41: 'forms',\n",
       " 42: 'found',\n",
       " 43: 'fox',\n",
       " 44: 'from',\n",
       " 45: 'fuel',\n",
       " 46: 'fun',\n",
       " 47: 'going',\n",
       " 48: 'good',\n",
       " 49: 'great',\n",
       " 50: 'happiness',\n",
       " 51: 'has',\n",
       " 52: 'have',\n",
       " 53: 'health',\n",
       " 54: 'homemade',\n",
       " 55: 'house',\n",
       " 56: 'importance',\n",
       " 57: 'important',\n",
       " 58: 'in',\n",
       " 59: 'incredible',\n",
       " 60: 'internet',\n",
       " 61: 'is',\n",
       " 62: 'jumps',\n",
       " 63: 'keeps',\n",
       " 64: 'knowledge',\n",
       " 65: 'known',\n",
       " 66: 'language',\n",
       " 67: 'lazy',\n",
       " 68: 'learning',\n",
       " 69: 'loyalty',\n",
       " 70: 'made',\n",
       " 71: 'maintaining',\n",
       " 72: 'many',\n",
       " 73: 'meals',\n",
       " 74: 'mind',\n",
       " 75: 'music',\n",
       " 76: 'my',\n",
       " 77: 'nature',\n",
       " 78: 'new',\n",
       " 79: 'of',\n",
       " 80: 'often',\n",
       " 81: 'over',\n",
       " 82: 'overstated',\n",
       " 83: 'pace',\n",
       " 84: 'painting',\n",
       " 85: 'people',\n",
       " 86: 'pepperoni',\n",
       " 87: 'pets',\n",
       " 88: 'pizza',\n",
       " 89: 'played',\n",
       " 90: 'popular',\n",
       " 91: 'power',\n",
       " 92: 'progress',\n",
       " 93: 'quick',\n",
       " 94: 'rapid',\n",
       " 95: 'reading',\n",
       " 96: 'recent',\n",
       " 97: 'revolutionized',\n",
       " 98: 'rewarding',\n",
       " 99: 'science',\n",
       " 100: 'shining',\n",
       " 101: 'simplest',\n",
       " 102: 'sky',\n",
       " 103: 'soccer',\n",
       " 104: 'soothing',\n",
       " 105: 'soul',\n",
       " 106: 'sport',\n",
       " 107: 'strong',\n",
       " 108: 'sun',\n",
       " 109: 'technology',\n",
       " 110: 'that',\n",
       " 111: 'the',\n",
       " 112: 'their',\n",
       " 113: 'things',\n",
       " 114: 'throughout',\n",
       " 115: 'to',\n",
       " 116: 'topped',\n",
       " 117: 'traveling',\n",
       " 118: 'way',\n",
       " 119: 'we',\n",
       " 120: 'with',\n",
       " 121: 'wonderful',\n",
       " 122: 'world',\n",
       " 123: 'years',\n",
       " 124: 'you',\n",
       " 125: 'your'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_TO_WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# The three axes of our matrix\n",
    "row = []\n",
    "column = []\n",
    "value = []\n",
    "\n",
    "for index, sample in enumerate(preprocess_train):\n",
    "\n",
    "  # Get the count of every word in each sample\n",
    "  word_count = dict(Counter(sample.split(' ')))\n",
    "\n",
    "  for word, count in word_count.items():\n",
    "    # Finding the vocab index of each word in the sample\n",
    "    # This will represent the column to add the count to\n",
    "    vocab_index = WORD_TO_INDEX.get(word)\n",
    "\n",
    "    # When word is found in vocabulary\n",
    "    if vocab_index and vocab_index >= 0:\n",
    "      # Determines what's added to the matrix\n",
    "      # Let the matrix shape be (x, y)\n",
    "      # At a certain index common to all\n",
    "      # it will add the sample index to the row (x)\n",
    "      # then it will add which column the value will be (y)\n",
    "      # And it tells what is the value, the count, to be added at position (x, y)\n",
    "      # when we append value\n",
    "      row.append(index)\n",
    "      column.append(vocab_index)\n",
    "      value.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY = csr_matrix(\n",
    "  (value, (row, column)),\n",
    "  shape=(len(preprocess_train), len(WORD_TO_INDEX))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 81)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 111)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 61)\t2\n",
      "  (1, 100)\t1\n",
      "  (1, 102)\t1\n",
      "  (1, 108)\t1\n",
      "  (1, 111)\t2\n",
      "  (2, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 52)\t1\n",
      "  (2, 55)\t1\n",
      "  (2, 87)\t1\n",
      "  (2, 111)\t1\n",
      "  (2, 115)\t1\n",
      "  (2, 121)\t1\n",
      "  (3, 2)\t1\n",
      "  :\t:\n",
      "  (17, 77)\t1\n",
      "  (17, 79)\t1\n",
      "  (17, 104)\t1\n",
      "  (17, 105)\t1\n",
      "  (17, 111)\t2\n",
      "  (17, 118)\t1\n",
      "  (18, 7)\t1\n",
      "  (18, 21)\t1\n",
      "  (18, 38)\t1\n",
      "  (18, 41)\t1\n",
      "  (18, 44)\t1\n",
      "  (18, 58)\t1\n",
      "  (18, 72)\t1\n",
      "  (18, 75)\t1\n",
      "  (18, 84)\t1\n",
      "  (18, 115)\t1\n",
      "  (19, 42)\t1\n",
      "  (19, 50)\t1\n",
      "  (19, 58)\t1\n",
      "  (19, 61)\t1\n",
      "  (19, 79)\t1\n",
      "  (19, 80)\t1\n",
      "  (19, 101)\t1\n",
      "  (19, 111)\t1\n",
      "  (19, 113)\t1\n"
     ]
    }
   ],
   "source": [
    "print(VOCABULARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = (number of times term t appears in a document) / (total number of terms in a document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 126)\n"
     ]
    }
   ],
   "source": [
    "DOCUMENT_FREQUENCY = np.bincount(\n",
    "  VOCABULARY.indices,\n",
    "  minlength=VOCABULARY.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 81)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 111)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 61)\t2\n",
      "  (1, 100)\t1\n",
      "  (1, 102)\t1\n",
      "  (1, 108)\t1\n",
      "  (1, 111)\t2\n",
      "  (2, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 52)\t1\n",
      "  (2, 55)\t1\n",
      "  (2, 87)\t1\n",
      "  (2, 111)\t1\n",
      "  (2, 115)\t1\n",
      "  (2, 121)\t1\n",
      "  (3, 2)\t1\n",
      "  :\t:\n",
      "  (17, 77)\t1\n",
      "  (17, 79)\t1\n",
      "  (17, 104)\t1\n",
      "  (17, 105)\t1\n",
      "  (17, 111)\t2\n",
      "  (17, 118)\t1\n",
      "  (18, 7)\t1\n",
      "  (18, 21)\t1\n",
      "  (18, 38)\t1\n",
      "  (18, 41)\t1\n",
      "  (18, 44)\t1\n",
      "  (18, 58)\t1\n",
      "  (18, 72)\t1\n",
      "  (18, 75)\t1\n",
      "  (18, 84)\t1\n",
      "  (18, 115)\t1\n",
      "  (19, 42)\t1\n",
      "  (19, 50)\t1\n",
      "  (19, 58)\t1\n",
      "  (19, 61)\t1\n",
      "  (19, 79)\t1\n",
      "  (19, 80)\t1\n",
      "  (19, 101)\t1\n",
      "  (19, 111)\t1\n",
      "  (19, 113)\t1\n"
     ]
    }
   ],
   "source": [
    "print(VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  30,  43,  62,  67,  81,  93, 111,   4,  10,  61, 100, 102,\n",
       "       108, 111,   5,   6,  17,  52,  55,  87, 111, 115, 121,   2,   6,\n",
       "        61,  89,  90, 103, 106, 111, 122,   4,  19,  39,  61,  76,  86,\n",
       "        88, 116, 120,   9,  13,  15,  18,  66,  68,  78,  98,  11,  36,\n",
       "        49,  61,  64,  95, 115, 118, 125,  22,  51,  60,  97, 111, 118,\n",
       "       119,  33,  34,  51,  58,  75,  85,  91, 107, 111, 115,  35,  40,\n",
       "        48,  53,  57,  61,  71,   1,  51,  58,  59,  70,  96,  99, 123,\n",
       "        20,  28,  45,  47,  61,  63,  72,  85, 110, 111, 114,   3,   4,\n",
       "        26,  27,  29,  37, 115, 117, 124,   9,  16,  32,  56,  79,  82,\n",
       "       111,   8,  24,  83,  92,  94, 109, 115,   4,   5,  23,  31,  40,\n",
       "        65,  69, 112,   4,   9,  15,  25,  46,  54,  73,  98,   4,  14,\n",
       "        51,  74,  77,  79, 104, 105, 111, 118,   7,  21,  38,  41,  44,\n",
       "        58,  72,  75,  84, 115,  42,  50,  58,  61,  79,  80, 101, 111,\n",
       "       113], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCABULARY.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  6,  2,  2,  1,  1,  3,  1,  1,  1,  1,  1,  2,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        4,  1,  1,  1,  1,  1,  1,  4,  1,  1,  7,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  2,  1,  1,  2,  1,  1,  1,  3,  1,  1,  1,  1,  1,\n",
       "        2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1,  1,  1,  6,  1,  1,  3,\n",
       "        1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOCUMENT_FREQUENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF(t) = log(total number of documents) / (number of documents with term t in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
