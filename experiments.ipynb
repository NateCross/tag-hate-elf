{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss and Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the behavior of cross entropy loss and adam optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEXT = ['the quick brown fox jumped over the lazy dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calamancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nate/miniconda3/lib/python3.9/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'tl_calamancy_md' (0.1.0) specifies an under-constrained spaCy version requirement: >=3.5.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'tl_calamancy_lg' (0.1.0) specifies an under-constrained spaCy version requirement: >=3.5.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.tl.Tagalog at 0x7f5e3c1f7cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calamancy\n",
    "\n",
    "Calamancy = calamancy.load(\"tl_calamancy_md-0.1.0\")\n",
    "\n",
    "Calamancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19799/1945608868.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torch import Tensor\n",
    "from collections import Counter\n",
    "\n",
    "def get_calamancy_tokens(data):\n",
    "  # Allows it to work with both dataframes and\n",
    "  # simple lists of strings\n",
    "  if isinstance(data, pd.Series):\n",
    "    data = data.values\n",
    "\n",
    "  samples = []\n",
    "\n",
    "  progress_bar = tqdm.tqdm(total=len(data))\n",
    "\n",
    "  for sample in Calamancy.pipe(data):\n",
    "    progress_bar.update(1)\n",
    "\n",
    "    tokens = []\n",
    "    for token in sample:\n",
    "      tokens.append(token)\n",
    "\n",
    "    samples.append(tokens)\n",
    "\n",
    "  progress_bar.close()\n",
    "\n",
    "  return samples\n",
    "\n",
    "def get_token_vectors(tokens):\n",
    "  vectors = []\n",
    "\n",
    "  progress_bar = tqdm.tqdm(total=len(tokens))\n",
    "\n",
    "  for sample in tokens:\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    token_vectors = []\n",
    "    # Check in case empty due to processing\n",
    "    if not sample:\n",
    "      token_vectors.append(np.zeros((200)))\n",
    "    else:\n",
    "      for token in sample:\n",
    "        if token.has_vector:\n",
    "          token_vectors.append(token.vector)\n",
    "    token_vectors = Tensor(np.array(token_vectors))\n",
    "\n",
    "    vectors.append(token_vectors)\n",
    "\n",
    "  progress_bar.close()\n",
    "\n",
    "  return vectors\n",
    "\n",
    "def data_remove_stopwords(data):\n",
    "  stopwords_list = open(\n",
    "    './src/stopwords-tl.txt',\n",
    "    'r',\n",
    "  ).read().split('\\n')\n",
    "  stopwords_dict = Counter(stopwords_list)\n",
    "  return [\n",
    "    ' '.join([\n",
    "      word for word in sample.split()\n",
    "      if word not in stopwords_dict\n",
    "    ])\n",
    "    for sample \n",
    "    in data\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.18it/s]\n"
     ]
    }
   ],
   "source": [
    "input_tokenized = get_calamancy_tokens(INPUT_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[the, quick, brown, fox, jumped, over, the, lazy, dog]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 813.01it/s]\n"
     ]
    }
   ],
   "source": [
    "input_vectorized = get_token_vectors(input_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0448,  0.2607,  0.1448,  ...,  0.4243, -0.1153, -0.0620],\n",
       "         [ 0.5258, -0.3996,  0.0114,  ...,  0.4171, -0.3223,  0.1630],\n",
       "         [-0.0630,  0.6724,  1.0455,  ...,  0.2032, -0.4797,  0.5314],\n",
       "         ...,\n",
       "         [-0.0448,  0.2607,  0.1448,  ...,  0.4243, -0.1153, -0.0620],\n",
       "         [-0.1454,  0.5539,  0.2981,  ...,  1.6336, -0.2340, -0.1128],\n",
       "         [ 0.1416, -0.5068,  0.7797,  ...,  0.2225, -0.7088, -0.3081]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vectorized[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim \n",
    "\n",
    "INPUT_SIZE = 200\n",
    "NUM_OF_HIDDEN_NODES = 50\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "OPTIMIZER = optim.Adam\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LstmModel(\n",
       "  (lstm): LSTM(200, 50, batch_first=True)\n",
       "  (linear): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LstmModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.lstm = nn.LSTM(\n",
    "      INPUT_SIZE,\n",
    "      NUM_OF_HIDDEN_NODES,\n",
    "      batch_first=True,\n",
    "    )\n",
    "    self.linear = nn.Linear(NUM_OF_HIDDEN_NODES, OUTPUT_SIZE)\n",
    "\n",
    "    self.lstm_output = None\n",
    "    self.lstm_hidden_state = None\n",
    "    self.lstm_cell_state = None\n",
    "\n",
    "  def forward(self, input):\n",
    "    self.lstm_output, (self.lstm_hidden_state, self.lstm_cell_state) = self.lstm(input)\n",
    "\n",
    "    linear_output = self.linear(self.lstm_output[:, -1])\n",
    "\n",
    "    return linear_output\n",
    "\n",
    "Lstm = LstmModel()\n",
    "\n",
    "Lstm.to(DEVICE)\n",
    "\n",
    "Lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.stack(input_vectorized).to(DEVICE)\n",
    "\n",
    "output = Lstm(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0580, -0.1203]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import LongTensor\n",
    "\n",
    "output_loss = loss_function(\n",
    "  output, \n",
    "  LongTensor([1]).to(DEVICE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7248, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve for Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that actual value is 1\n",
    "\n",
    "Hence, the actual probability distribution is [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_probabilities = torch.softmax(\n",
    "  output,\n",
    "  dim=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5156, 0.4844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247954"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_probabilities = [0, 1]\n",
    "\n",
    "predicted_probabilities = output_probabilities[0][0] * actual_probabilities[0] + output_probabilities[0][1] * actual_probabilities[1]\n",
    "\n",
    "-np.log(predicted_probabilities.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss for Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLE_INPUTS = [\n",
    "  'the quick brown fox jumped',\n",
    "  'over the lazy dog near',\n",
    "  'the bank of the river',\n",
    "]\n",
    "\n",
    "TARGET_INPUTS = [1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 62.61it/s]\n"
     ]
    }
   ],
   "source": [
    "multiple_input_tokens = get_calamancy_tokens(MULTIPLE_INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[the, quick, brown, fox, jumped],\n",
       " [over, the, lazy, dog, near],\n",
       " [the, bank, of, the, river]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2097.85it/s]\n"
     ]
    }
   ],
   "source": [
    "multiple_input_vectors = get_token_vectors(multiple_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.4816e-02,  2.6072e-01,  1.4476e-01,  1.3985e-01,  8.2186e-01,\n",
       "          -1.8453e-01,  3.9610e-01, -3.3248e-01, -1.8321e-03, -3.2702e-01,\n",
       "          -1.4955e-01, -7.9797e-01,  3.2212e-01,  5.0457e-01, -1.4466e-02,\n",
       "          -1.5588e-01, -5.8039e-01, -8.2334e-01, -1.2749e-01,  1.2681e-02,\n",
       "           1.7029e-01,  2.0639e-01,  1.8592e-01,  9.1905e-02,  7.9670e-01,\n",
       "           3.7350e-03, -1.1508e-01, -9.2960e-02, -5.0474e-02, -5.2370e-01,\n",
       "           2.4938e-01,  5.0046e-02, -2.2510e-01,  8.2782e-01, -8.8028e-02,\n",
       "          -3.1285e-01,  2.1367e-01, -1.2164e-01,  6.2164e-02,  3.9969e-02,\n",
       "          -1.9242e-01,  5.9761e-01,  8.7907e-01,  2.6625e-01, -6.2292e-01,\n",
       "           3.5723e-01, -5.6910e-01, -2.2975e-02, -4.4734e-01, -2.3245e-01,\n",
       "          -1.6014e-02,  2.4307e-02, -2.9628e-01,  3.4902e-03,  2.8123e-01,\n",
       "          -3.6569e-01, -5.6186e-02, -8.3109e-02,  3.7591e-01, -3.0810e-01,\n",
       "          -3.9157e-01, -5.8018e-01,  4.4514e-02, -3.4728e-01, -1.4072e-02,\n",
       "           9.6888e-02,  4.2398e-02, -2.0702e-01,  1.1550e-03,  4.9811e-01,\n",
       "          -3.3000e-01, -2.3525e-01, -8.9399e-02,  2.0654e-01, -1.4491e-01,\n",
       "          -4.1638e-02,  2.2768e-01,  1.7223e-01, -1.9337e-01,  5.4533e-01,\n",
       "          -1.8066e-01,  4.5702e-02, -1.8615e-01, -5.7819e-01,  3.1169e-02,\n",
       "           1.2292e-02, -3.2395e-01,  5.6787e-01, -3.4982e-01, -1.6895e-01,\n",
       "          -4.9290e-01,  1.7113e-01,  1.2016e-01,  6.5679e-01,  5.1149e-01,\n",
       "           1.3962e-01, -1.4009e-02,  8.0457e-01, -1.6864e-03,  4.5210e-01,\n",
       "           3.1804e-01, -6.4181e-02, -3.4219e-01, -1.9089e-01, -5.3410e-01,\n",
       "          -5.3507e-01, -5.3707e-02, -5.6995e-02,  4.4185e-02,  2.6180e-01,\n",
       "          -5.3361e-01, -5.3296e-01, -3.7533e-01,  5.2777e-01, -4.5300e-02,\n",
       "          -1.5200e-01, -1.8493e-01, -1.5568e-01,  1.2953e-01,  2.1748e-01,\n",
       "          -4.5083e-01,  1.0669e-01, -2.5463e-01,  2.3678e-01,  5.8170e-03,\n",
       "           1.8802e-01, -9.0083e-02, -9.5030e-01, -3.3442e-01, -4.9307e-01,\n",
       "          -7.0966e-02, -5.5689e-01,  3.3150e-01,  1.6025e-01, -2.6116e-01,\n",
       "           6.1389e-02, -5.4729e-01, -1.4360e-01, -3.0535e-01, -3.5357e-01,\n",
       "          -6.2616e-01, -2.2439e-02, -2.0740e-01,  2.1965e-01,  4.6478e-01,\n",
       "          -1.3669e-01, -1.0145e-01,  1.0842e-01,  5.0507e-03,  2.9468e-01,\n",
       "          -2.0390e-02,  7.9607e-02, -5.0416e-03, -9.2473e-02,  3.1267e-01,\n",
       "           5.8991e-01,  1.1121e+00,  3.1630e-02, -4.6566e-02, -3.7113e-01,\n",
       "          -8.5519e-02, -2.8330e-02, -2.7766e-02, -4.7535e-01, -6.3396e-01,\n",
       "          -7.5772e-02, -3.1621e-03,  3.7479e-02,  1.3982e-01, -5.8328e-02,\n",
       "           3.6327e-01, -4.1039e-02, -9.3303e-02,  6.7044e-02,  3.8285e-01,\n",
       "          -3.5371e-01,  5.5917e-01, -3.6336e-01,  7.0457e-03,  4.0882e-01,\n",
       "           3.3558e-01,  3.1595e-01,  2.6091e-01,  3.2326e-01,  7.1776e-02,\n",
       "          -2.9163e-01,  1.2613e-01,  1.7375e-01, -5.7487e-01,  3.6839e-01,\n",
       "           2.2042e-01,  3.1725e-01, -4.6196e-01, -5.9088e-02, -6.9970e-01,\n",
       "           2.6686e-02, -4.2077e-01,  4.2432e-01, -1.1535e-01, -6.1969e-02],\n",
       "         [ 5.2582e-01, -3.9957e-01,  1.1390e-02,  9.8938e-03,  1.7747e-01,\n",
       "           2.0426e-01,  4.7010e-01, -5.5379e-03,  3.7632e-01,  2.1025e-02,\n",
       "           7.5305e-02, -9.8197e-02,  2.3605e-01,  2.8973e-01, -4.6871e-01,\n",
       "          -1.1958e-01,  5.9096e-03, -7.4165e-01,  2.1289e-01,  4.0479e-02,\n",
       "          -2.0617e-01, -4.1237e-01,  3.6557e-01, -1.3649e-03,  2.2545e-01,\n",
       "           2.5235e-01, -2.0550e-01,  5.1982e-01,  4.9334e-01,  9.2994e-02,\n",
       "          -7.6709e-02,  1.6873e-01,  2.0939e-01,  7.4881e-02, -5.1258e-01,\n",
       "          -8.5820e-01,  1.6354e-01, -8.9909e-01,  4.0316e-01, -1.5315e-01,\n",
       "          -9.1007e-03,  2.1035e-01,  1.1436e+00,  3.5039e-01, -4.9243e-01,\n",
       "           1.1073e+00, -3.9505e-01, -7.3672e-01,  3.1965e-02, -1.1052e-01,\n",
       "           1.4942e-01, -4.3055e-01, -6.3311e-02,  8.1610e-02,  3.4618e-01,\n",
       "          -2.9015e-01, -5.7756e-02, -1.6263e-01,  2.6232e-01, -7.0096e-03,\n",
       "          -4.9251e-01, -8.4032e-01,  1.0436e-02, -4.9564e-01, -2.2579e-01,\n",
       "           4.5158e-03, -2.1058e-01,  6.1756e-02,  2.4745e-01, -1.0154e-01,\n",
       "          -5.3641e-01, -5.4325e-01,  4.7301e-01,  1.0782e-01,  1.3411e-01,\n",
       "          -5.9710e-01,  3.2889e-01,  1.5896e-01, -8.1743e-02,  4.3795e-01,\n",
       "          -4.4972e-01,  1.9432e-01, -3.6185e-01,  5.1602e-03, -1.1319e-01,\n",
       "          -1.5882e-02,  6.6906e-01, -1.2913e-01,  4.0810e-01, -6.6620e-03,\n",
       "          -2.5002e-01, -1.3401e-01, -1.3108e-01,  4.2851e-01,  2.0056e-01,\n",
       "           1.8707e-01, -5.3876e-01,  2.7650e-02, -1.8840e-01,  3.1943e-01,\n",
       "           5.1957e-01, -2.3585e-01, -1.6077e-01, -4.5108e-01, -3.2736e-01,\n",
       "           2.4534e-01, -4.3506e-01, -1.7187e-01,  2.4753e-02,  1.3861e-01,\n",
       "           5.3755e-02, -1.5925e-01, -6.8991e-02, -1.9627e-02, -2.5720e-02,\n",
       "           2.0635e-01, -6.6691e-01,  3.7582e-01,  3.3616e-01, -5.4611e-01,\n",
       "           2.7783e-01, -2.5366e-01,  8.2039e-01,  2.0999e-01, -2.1332e-02,\n",
       "           5.5277e-01, -4.7521e-01, -6.1330e-01,  2.9165e-01, -3.0554e-01,\n",
       "          -1.9863e-01, -4.1631e-01,  6.0528e-01,  1.8256e-01, -2.5560e-02,\n",
       "           5.4986e-01, -4.8742e-01,  3.6153e-01,  9.7532e-03, -8.2782e-02,\n",
       "          -7.1096e-01, -4.7132e-01, -2.7811e-01,  2.4559e-01,  6.0404e-01,\n",
       "          -9.0283e-02,  5.5116e-02,  1.0785e-01, -6.1579e-01,  2.8370e-01,\n",
       "          -2.4776e-01,  1.6538e-01, -2.9603e-01,  2.8756e-01, -6.0230e-02,\n",
       "           3.6150e-01,  2.6907e-01,  1.5677e-01,  1.4881e-01,  1.2983e-01,\n",
       "          -7.3904e-02, -4.4660e-01, -3.3024e-01,  8.4394e-02, -1.7000e-01,\n",
       "          -3.9127e-01, -5.1365e-01,  1.9484e-01,  2.4687e-01, -1.8259e-01,\n",
       "           3.9010e-02,  3.1322e-01,  9.3358e-01, -2.0409e-01,  1.0829e+00,\n",
       "           1.8914e-01,  9.8692e-02, -3.9530e-01, -7.5977e-01,  2.9325e-01,\n",
       "          -3.3745e-01,  1.1537e-01,  1.2746e-01,  4.9039e-01, -5.2925e-02,\n",
       "           3.4013e-01,  7.9464e-02, -2.0501e-01, -1.1362e+00,  3.0718e-01,\n",
       "           2.0904e-01, -4.6873e-01,  1.9942e-01, -1.8950e-01,  8.5889e-02,\n",
       "           2.4270e-01, -2.3279e-01,  4.1708e-01, -3.2227e-01,  1.6304e-01],\n",
       "         [-6.2968e-02,  6.7242e-01,  1.0455e+00,  3.6472e-01,  4.1441e-01,\n",
       "          -4.3495e-02,  3.1925e-01, -8.9794e-02,  4.3778e-01,  1.3582e-01,\n",
       "          -2.0251e-01, -5.7321e-02, -1.8505e-01, -2.3192e-01, -1.3180e-01,\n",
       "           1.2560e-01, -1.2763e-01, -2.0208e-01,  6.4287e-03,  2.6766e-01,\n",
       "           4.8296e-01,  4.5433e-01, -9.4795e-02, -8.3432e-02,  1.3545e-01,\n",
       "           8.1204e-02, -6.4749e-02, -5.1711e-01, -5.1881e-01, -3.6176e-01,\n",
       "          -6.6832e-01,  1.1883e-01, -1.1837e-01, -5.1527e-01,  1.8740e-01,\n",
       "          -1.7782e-01,  1.6195e-01, -1.0626e-01, -7.1311e-01, -2.6944e-01,\n",
       "          -5.9343e-02,  4.4534e-01,  7.9498e-01, -1.7180e-02, -4.4074e-01,\n",
       "           5.0367e-01, -2.1153e-02,  1.2234e-01,  1.4064e-01,  3.4787e-01,\n",
       "          -2.1203e-01, -8.7750e-02, -5.7605e-01,  1.0794e-01,  9.8911e-02,\n",
       "          -1.4260e-01, -4.4556e-01,  5.5467e-01,  3.6178e-01,  3.7078e-01,\n",
       "          -8.2019e-03, -2.8629e-01,  9.2128e-02,  1.2331e-01,  2.3766e-01,\n",
       "           4.3419e-01, -2.8217e-01,  4.4114e-02,  7.7627e-02, -1.3490e-01,\n",
       "          -4.9788e-01,  2.3944e-01,  4.8443e-02, -3.1436e-01,  8.2149e-02,\n",
       "           2.6548e-01,  3.9599e-01, -8.9486e-01, -1.9219e-01,  8.2651e-02,\n",
       "          -3.0722e-01,  4.1871e-01, -6.6705e-01, -4.3573e-01,  1.7064e-01,\n",
       "           8.9452e-02,  3.2756e-02, -1.8004e-01,  5.5068e-02, -7.7420e-01,\n",
       "          -3.7546e-01, -2.4502e-01, -7.8392e-03, -3.3128e-01, -2.3278e-01,\n",
       "          -5.4355e-01,  1.0617e-01,  2.0729e-01, -1.4228e-01, -1.1683e-01,\n",
       "           1.5202e-01,  2.2899e-01, -1.4420e-01, -1.6212e-01, -3.9624e-01,\n",
       "          -1.0645e-01,  2.4998e-01,  8.5707e-01, -4.5600e-01, -5.2756e-02,\n",
       "           2.1509e-01, -2.8672e-01, -1.9751e-02,  2.8852e-02, -3.9469e-01,\n",
       "          -5.5048e-01, -5.3897e-01,  4.6681e-02,  1.0439e-01, -3.0208e-01,\n",
       "           1.6174e-01, -1.0714e-01, -2.6083e-01,  2.2511e-01, -1.6846e-01,\n",
       "           2.9357e-01,  2.5711e-01, -2.2997e-01,  3.0387e-01, -5.5053e-01,\n",
       "           3.7336e-01, -4.3008e-02,  3.1381e-01,  3.4852e-01, -2.4234e-01,\n",
       "           2.7139e-01, -1.0534e-01,  1.9515e-02,  3.3996e-01,  1.0211e-01,\n",
       "          -3.2328e-01,  1.4245e-01, -1.2768e-01,  7.5923e-01, -1.6191e-01,\n",
       "          -5.6238e-01, -8.6730e-01,  2.1947e-01, -2.0236e-01, -4.0445e-01,\n",
       "          -1.1988e-03,  1.6201e-01, -1.3094e-01, -6.2289e-01, -5.4628e-05,\n",
       "           3.6729e-01, -4.4023e-01, -5.4574e-04,  5.0367e-01,  6.4463e-01,\n",
       "           1.1006e-01, -9.8956e-01, -2.4277e-01,  1.8927e-01,  4.2673e-01,\n",
       "          -2.9745e-02,  1.4799e-01,  2.8096e-01,  2.8654e-01, -9.2266e-02,\n",
       "           6.4654e-01,  5.1758e-01,  3.5818e-02, -6.7137e-01,  6.8926e-02,\n",
       "          -2.6086e-01, -1.0211e-01,  2.3365e-01,  3.8064e-02, -1.0616e-01,\n",
       "          -2.1372e-01, -2.0122e-01,  3.0760e-01,  4.6263e-01, -5.9128e-02,\n",
       "          -4.6866e-01,  1.4062e-01, -8.0100e-02,  1.4165e-01, -3.3927e-01,\n",
       "           6.4791e-01, -3.8325e-02, -1.0251e-01,  1.4774e-02, -3.2966e-01,\n",
       "          -8.0827e-01, -1.6598e-01,  2.0323e-01, -4.7967e-01,  5.3143e-01],\n",
       "         [ 5.3453e-01,  8.9322e-01,  5.4035e-01, -3.8142e-01,  5.6625e-01,\n",
       "           5.6520e-01,  7.8617e-01, -3.3560e-01,  2.4861e-01,  3.9402e-01,\n",
       "           2.3372e-01, -1.0249e+00, -5.2546e-01, -1.3582e-01, -1.3783e+00,\n",
       "          -4.3251e-01,  6.6572e-01, -9.9388e-01, -9.3003e-01,  2.6695e-01,\n",
       "           5.4414e-01, -3.6710e-02, -3.3585e-01, -5.5716e-01,  5.2425e-01,\n",
       "           2.2787e-01, -4.5318e-03,  1.6051e-01, -4.3154e-01,  1.3725e+00,\n",
       "           1.6735e-01,  3.7182e-01,  1.0513e+00, -1.2945e-01, -8.9678e-01,\n",
       "           3.6963e-01,  7.7352e-01, -1.4455e+00, -3.5308e-01, -3.3889e-02,\n",
       "          -9.7435e-01, -3.1993e-01,  1.7209e-01,  1.1243e+00, -1.1892e+00,\n",
       "           6.8171e-01,  3.8381e-01, -8.8983e-01,  4.4023e-01, -1.9213e-02,\n",
       "          -6.6555e-01, -1.0384e+00,  1.5955e-01,  5.3144e-04, -7.3056e-02,\n",
       "          -4.7849e-01, -8.5359e-01,  4.6828e-02,  6.6151e-01,  4.4777e-01,\n",
       "          -4.1704e-01, -8.3729e-01, -2.5145e-01, -6.5960e-01, -3.3396e-01,\n",
       "           1.2831e+00,  1.4391e-01, -3.0199e-01, -8.1084e-01,  1.3911e-01,\n",
       "          -1.0649e+00, -2.0366e-01, -3.0544e-01,  3.6532e-01,  3.3138e-01,\n",
       "          -1.0624e-01,  2.1494e-01, -4.2405e-01,  2.6690e-01,  9.7092e-01,\n",
       "          -8.8282e-01, -6.1802e-01,  6.0888e-01, -2.9226e-01,  2.7972e-01,\n",
       "           5.5565e-01,  3.8582e-03,  7.3056e-02, -8.0739e-01, -1.0916e+00,\n",
       "          -2.3233e-01, -4.8161e-01,  5.9149e-02,  3.5635e-01, -1.8832e+00,\n",
       "           2.1809e-01,  4.3210e-01, -1.1417e-01,  1.3493e-01, -6.5069e-01,\n",
       "           6.2443e-01,  1.4634e-01,  8.8526e-02,  2.0698e-01,  7.2677e-02,\n",
       "          -3.3530e-01,  1.3533e+00,  1.5302e-01, -1.2944e-01,  5.5431e-01,\n",
       "           5.9981e-02, -6.7858e-02, -8.7081e-02, -9.7391e-01, -2.9278e-01,\n",
       "          -1.7713e-01,  7.3422e-01,  1.8044e-01, -1.0316e-01,  6.3261e-01,\n",
       "           2.9656e-01,  7.3183e-01, -9.1582e-01,  5.2432e-01,  9.4620e-02,\n",
       "          -5.9796e-02,  7.4538e-01,  1.3032e-01,  3.0220e-01, -1.1962e-01,\n",
       "           1.6633e+00,  8.0571e-03,  1.3139e+00,  1.5560e-01,  6.7555e-01,\n",
       "           7.7513e-01,  8.3048e-01,  1.0965e-01, -2.5111e-01, -4.0532e-02,\n",
       "          -1.1496e+00,  6.9076e-01, -1.5477e-01,  1.1205e+00,  2.7069e-01,\n",
       "          -4.3419e-01, -3.6857e-01, -6.7692e-01, -8.9022e-01,  8.3964e-01,\n",
       "           5.8913e-01,  3.5117e-01,  2.2308e-01,  8.4952e-01,  2.1158e-01,\n",
       "          -7.5775e-01, -2.2421e-02, -1.0313e+00,  1.6339e+00, -1.7067e-01,\n",
       "           1.2633e-01, -1.2614e+00,  3.6366e-01,  2.5118e-01,  4.8618e-01,\n",
       "          -9.8725e-01, -4.5705e-01,  3.3377e-01, -4.2046e-02, -4.2415e-01,\n",
       "           4.7096e-01,  6.4284e-01,  2.5389e-01, -1.0142e-01,  6.7314e-02,\n",
       "          -2.2180e+00,  2.6569e-01,  4.6163e-02, -1.0615e+00,  1.0376e+00,\n",
       "          -5.2256e-01,  3.9886e-01, -2.0516e-01,  2.0748e-01,  1.4123e-01,\n",
       "          -1.8153e-01, -1.0119e+00, -2.5736e-01, -1.0638e-01, -9.5944e-02,\n",
       "           7.4550e-01, -7.7631e-01,  2.0808e-01, -3.7264e-01,  6.8881e-01,\n",
       "          -1.3418e+00, -2.9791e-01,  7.4957e-01, -2.0193e-01,  6.4317e-01],\n",
       "         [ 4.0237e-01, -4.3079e-01,  4.0140e-01,  3.8917e-01,  3.9254e-01,\n",
       "           7.3992e-01, -3.6405e-01,  3.0677e-02, -7.2171e-01, -1.8627e-01,\n",
       "           1.6950e-01, -3.0568e-01, -6.6851e-02,  3.0010e-01, -3.0154e-01,\n",
       "          -8.2374e-01, -5.6618e-01, -7.0135e-01,  3.2981e-01, -1.8343e-01,\n",
       "           5.1941e-01,  7.4040e-01,  3.7198e-01, -9.0341e-02,  3.2229e-01,\n",
       "          -1.1438e-01, -3.4804e-02, -2.3584e-01,  1.2480e-01, -3.1851e-01,\n",
       "           1.5030e-01,  1.6525e-01, -9.1870e-02, -1.5099e-01,  2.8054e-01,\n",
       "          -3.1211e-01,  5.6248e-01, -8.9609e-01, -5.8133e-01, -5.2176e-02,\n",
       "           1.0643e-01,  3.9270e-01,  6.5161e-01,  4.5113e-01, -5.5697e-01,\n",
       "           5.1014e-01, -2.2502e-01,  2.1462e-01, -1.5204e-01, -1.6236e-01,\n",
       "          -2.5608e-01, -3.0328e-01,  2.4568e-02,  3.0776e-01,  1.4191e-01,\n",
       "          -2.1584e-01,  1.6103e-01,  1.4722e-01,  2.7303e-01, -3.1852e-02,\n",
       "          -4.3707e-01, -3.0806e-01,  1.0603e+00,  9.3847e-02, -3.7324e-01,\n",
       "           1.4434e-01, -2.9833e-01,  1.9924e-01,  2.0985e-01,  3.5541e-01,\n",
       "          -4.9584e-01, -2.4642e-01,  1.3900e-01, -1.1140e-01,  3.1301e-01,\n",
       "           3.8376e-01,  5.3094e-01,  2.8201e-01, -2.6519e-01,  1.0257e-01,\n",
       "           2.6175e-01, -1.6348e-01, -1.9408e-01, -5.1454e-01,  2.9924e-01,\n",
       "          -6.5998e-01,  8.6718e-03,  1.9480e-01, -6.4623e-01, -1.7241e-01,\n",
       "           1.4216e-01, -2.9613e-01, -1.8087e-01, -2.3885e-01,  1.0546e-01,\n",
       "           1.9908e-01, -1.7145e-02, -5.4881e-01,  4.0679e-01, -4.6920e-01,\n",
       "           4.9049e-01, -9.2103e-02, -2.5435e-02, -6.5964e-01, -4.7339e-01,\n",
       "           8.5093e-01,  3.0596e-01,  4.4412e-01, -4.7295e-01,  1.1708e+00,\n",
       "           4.8305e-01, -2.4402e-01,  1.5420e-01,  3.5689e-01,  1.1582e-01,\n",
       "          -3.1562e-01, -1.6549e-01,  7.7367e-01,  3.9228e-01,  1.1579e-01,\n",
       "           4.0971e-01,  5.4513e-01,  7.2031e-01,  3.7067e-01, -6.0253e-01,\n",
       "           6.3257e-01,  1.9416e-01, -7.2429e-01,  2.0785e-01, -5.3375e-01,\n",
       "           7.0769e-02,  3.5887e-01,  6.5136e-01, -4.2391e-01, -3.9593e-01,\n",
       "          -1.4935e-01, -8.3433e-01,  8.2376e-01, -1.2467e-01, -2.8000e-01,\n",
       "          -5.4580e-01,  1.6281e-01,  1.5052e-01,  1.1934e-01,  8.8216e-01,\n",
       "          -3.0178e-03,  3.3257e-01,  3.4231e-01,  2.2400e-01, -3.7833e-02,\n",
       "          -2.4915e-01,  3.9799e-01,  4.8354e-01,  4.3415e-01,  4.2723e-01,\n",
       "           1.1100e-01,  2.8731e-01,  1.8105e-01, -1.7005e-01,  4.3117e-02,\n",
       "           6.3371e-01, -6.6275e-01, -5.6791e-01,  6.8223e-01,  5.5571e-01,\n",
       "          -3.5512e-01,  4.2885e-01, -1.7566e-01,  6.3898e-01, -6.9407e-01,\n",
       "           4.4170e-02,  2.2975e-01, -5.4211e-01, -1.4389e-01, -1.5036e-01,\n",
       "          -3.8541e-01,  6.8533e-02, -8.3389e-01, -3.4367e-01, -7.6084e-01,\n",
       "           5.1460e-01,  2.4641e-01,  2.7039e-01,  4.0971e-02,  4.0235e-01,\n",
       "          -4.6860e-01, -6.8394e-03,  2.0025e-01,  2.5531e-01,  3.0677e-01,\n",
       "           5.5962e-02, -1.6154e-02, -6.2793e-01, -4.8660e-02,  4.6340e-01,\n",
       "          -3.4588e-01, -5.2617e-01,  5.4931e-01, -4.1621e-01, -1.8028e-01]]),\n",
       " tensor([[-8.9689e-02,  3.4316e-01,  2.6373e-01,  1.2438e-01,  7.1749e-01,\n",
       "           2.2371e-01,  2.7924e-01,  3.2778e-01,  1.8856e-01, -1.2572e-01,\n",
       "           8.6910e-02, -5.9665e-01, -1.7770e-01,  1.1413e-01, -1.4181e-01,\n",
       "          -1.8178e-01, -3.2238e-01, -5.3837e-01,  1.7155e-04,  1.8803e-01,\n",
       "           3.2020e-01, -3.5529e-01, -2.5224e-01,  1.9141e-01,  6.7685e-01,\n",
       "          -3.7449e-01, -5.2056e-01, -4.9048e-01, -2.3425e-01, -5.5392e-01,\n",
       "           2.0104e-01,  6.8938e-01,  1.0283e-01,  4.1450e-01,  9.8860e-02,\n",
       "          -2.3158e-01, -1.1151e-01, -3.2252e-02,  3.1593e-01, -2.0222e-01,\n",
       "          -2.6186e-01,  6.6811e-01,  8.4184e-01,  4.4114e-01, -9.1005e-01,\n",
       "           6.3740e-01,  1.3109e-01, -3.7000e-01, -6.9599e-01, -1.1701e-01,\n",
       "           8.2138e-02,  4.1532e-01, -2.0829e-01,  7.5296e-02,  3.1932e-01,\n",
       "           1.4721e-01,  1.5803e-01,  3.7935e-02,  1.8456e-01,  2.3756e-01,\n",
       "          -2.7831e-01, -5.3994e-01,  1.9349e-01, -7.1311e-02,  1.1485e-02,\n",
       "          -1.4057e-01, -1.8851e-01, -2.2892e-01,  1.0299e-02, -1.7852e-01,\n",
       "          -5.6609e-01, -1.2454e-01,  2.0107e-01, -6.3303e-02, -5.7659e-02,\n",
       "           4.0747e-01,  4.6605e-01,  2.0016e-02,  1.8296e-01,  1.8736e-01,\n",
       "           3.8332e-02, -2.0561e-03,  1.2988e-01, -6.1068e-01,  9.4046e-02,\n",
       "          -3.3597e-02, -1.3825e-01,  4.4027e-01, -3.2480e-01, -2.0222e-01,\n",
       "          -1.5927e-01, -2.6840e-01, -1.8518e-01,  2.5985e-01,  4.7509e-01,\n",
       "           2.9783e-01, -2.0591e-01,  7.0173e-01,  9.0242e-02, -7.7591e-02,\n",
       "           1.3952e-01,  6.4638e-02, -1.5523e-01, -7.2622e-01, -8.9134e-01,\n",
       "          -1.2291e-01,  5.5753e-02, -5.0978e-02, -1.4115e-02,  4.5564e-01,\n",
       "           1.3976e-01, -4.3956e-01,  2.2807e-01,  5.2432e-01, -2.0999e-02,\n",
       "          -3.3742e-01, -3.0892e-01,  2.7659e-01,  1.2481e-01,  6.4408e-02,\n",
       "          -2.0629e-02, -2.4609e-01,  1.3647e-01,  4.4294e-02,  5.6656e-02,\n",
       "           4.2760e-02,  1.4426e-01, -7.3484e-01,  6.0200e-01, -4.8247e-01,\n",
       "          -2.0407e-02, -1.3671e-01, -5.0679e-02, -3.3230e-02, -1.9161e-01,\n",
       "          -2.8508e-01, -2.1523e-01,  7.2780e-01, -2.4044e-01, -6.2502e-01,\n",
       "          -5.5045e-01,  2.6876e-01, -3.0711e-01,  4.0650e-01,  5.2903e-01,\n",
       "          -2.6782e-01, -4.0558e-01, -3.0511e-03,  3.9286e-01,  5.3367e-02,\n",
       "           3.2650e-02,  1.0442e-02, -3.4164e-01, -1.5811e-01,  3.2665e-01,\n",
       "           6.1399e-01,  3.9384e-01, -3.5572e-01,  7.3814e-02, -1.2838e-01,\n",
       "           1.7337e-01, -1.2974e-02,  2.4907e-02, -3.3338e-01, -2.6492e-01,\n",
       "          -1.7191e-01, -2.3980e-02,  4.1467e-01,  3.5364e-01,  8.3307e-02,\n",
       "          -5.0702e-02,  4.5850e-01,  9.2895e-02,  5.2893e-02,  2.1199e-01,\n",
       "          -1.0219e-01,  1.4996e-01, -3.8431e-01,  9.3946e-02, -2.9961e-01,\n",
       "           2.1955e-01,  2.0197e-01, -2.5227e-02,  2.5625e-01,  4.6795e-02,\n",
       "          -2.7049e-01, -1.9013e-01,  4.4952e-01, -3.9755e-01,  8.3703e-01,\n",
       "           2.4659e-01, -5.1385e-02, -4.3192e-01,  3.0225e-01, -6.7844e-02,\n",
       "          -1.1619e-01, -6.8668e-01,  1.8338e-01, -2.4968e-01,  6.2954e-04],\n",
       "         [-4.4816e-02,  2.6072e-01,  1.4476e-01,  1.3985e-01,  8.2186e-01,\n",
       "          -1.8453e-01,  3.9610e-01, -3.3248e-01, -1.8321e-03, -3.2702e-01,\n",
       "          -1.4955e-01, -7.9797e-01,  3.2212e-01,  5.0457e-01, -1.4466e-02,\n",
       "          -1.5588e-01, -5.8039e-01, -8.2334e-01, -1.2749e-01,  1.2681e-02,\n",
       "           1.7029e-01,  2.0639e-01,  1.8592e-01,  9.1905e-02,  7.9670e-01,\n",
       "           3.7350e-03, -1.1508e-01, -9.2960e-02, -5.0474e-02, -5.2370e-01,\n",
       "           2.4938e-01,  5.0046e-02, -2.2510e-01,  8.2782e-01, -8.8028e-02,\n",
       "          -3.1285e-01,  2.1367e-01, -1.2164e-01,  6.2164e-02,  3.9969e-02,\n",
       "          -1.9242e-01,  5.9761e-01,  8.7907e-01,  2.6625e-01, -6.2292e-01,\n",
       "           3.5723e-01, -5.6910e-01, -2.2975e-02, -4.4734e-01, -2.3245e-01,\n",
       "          -1.6014e-02,  2.4307e-02, -2.9628e-01,  3.4902e-03,  2.8123e-01,\n",
       "          -3.6569e-01, -5.6186e-02, -8.3109e-02,  3.7591e-01, -3.0810e-01,\n",
       "          -3.9157e-01, -5.8018e-01,  4.4514e-02, -3.4728e-01, -1.4072e-02,\n",
       "           9.6888e-02,  4.2398e-02, -2.0702e-01,  1.1550e-03,  4.9811e-01,\n",
       "          -3.3000e-01, -2.3525e-01, -8.9399e-02,  2.0654e-01, -1.4491e-01,\n",
       "          -4.1638e-02,  2.2768e-01,  1.7223e-01, -1.9337e-01,  5.4533e-01,\n",
       "          -1.8066e-01,  4.5702e-02, -1.8615e-01, -5.7819e-01,  3.1169e-02,\n",
       "           1.2292e-02, -3.2395e-01,  5.6787e-01, -3.4982e-01, -1.6895e-01,\n",
       "          -4.9290e-01,  1.7113e-01,  1.2016e-01,  6.5679e-01,  5.1149e-01,\n",
       "           1.3962e-01, -1.4009e-02,  8.0457e-01, -1.6864e-03,  4.5210e-01,\n",
       "           3.1804e-01, -6.4181e-02, -3.4219e-01, -1.9089e-01, -5.3410e-01,\n",
       "          -5.3507e-01, -5.3707e-02, -5.6995e-02,  4.4185e-02,  2.6180e-01,\n",
       "          -5.3361e-01, -5.3296e-01, -3.7533e-01,  5.2777e-01, -4.5300e-02,\n",
       "          -1.5200e-01, -1.8493e-01, -1.5568e-01,  1.2953e-01,  2.1748e-01,\n",
       "          -4.5083e-01,  1.0669e-01, -2.5463e-01,  2.3678e-01,  5.8170e-03,\n",
       "           1.8802e-01, -9.0083e-02, -9.5030e-01, -3.3442e-01, -4.9307e-01,\n",
       "          -7.0966e-02, -5.5689e-01,  3.3150e-01,  1.6025e-01, -2.6116e-01,\n",
       "           6.1389e-02, -5.4729e-01, -1.4360e-01, -3.0535e-01, -3.5357e-01,\n",
       "          -6.2616e-01, -2.2439e-02, -2.0740e-01,  2.1965e-01,  4.6478e-01,\n",
       "          -1.3669e-01, -1.0145e-01,  1.0842e-01,  5.0507e-03,  2.9468e-01,\n",
       "          -2.0390e-02,  7.9607e-02, -5.0416e-03, -9.2473e-02,  3.1267e-01,\n",
       "           5.8991e-01,  1.1121e+00,  3.1630e-02, -4.6566e-02, -3.7113e-01,\n",
       "          -8.5519e-02, -2.8330e-02, -2.7766e-02, -4.7535e-01, -6.3396e-01,\n",
       "          -7.5772e-02, -3.1621e-03,  3.7479e-02,  1.3982e-01, -5.8328e-02,\n",
       "           3.6327e-01, -4.1039e-02, -9.3303e-02,  6.7044e-02,  3.8285e-01,\n",
       "          -3.5371e-01,  5.5917e-01, -3.6336e-01,  7.0457e-03,  4.0882e-01,\n",
       "           3.3558e-01,  3.1595e-01,  2.6091e-01,  3.2326e-01,  7.1776e-02,\n",
       "          -2.9163e-01,  1.2613e-01,  1.7375e-01, -5.7487e-01,  3.6839e-01,\n",
       "           2.2042e-01,  3.1725e-01, -4.6196e-01, -5.9088e-02, -6.9970e-01,\n",
       "           2.6686e-02, -4.2077e-01,  4.2432e-01, -1.1535e-01, -6.1969e-02],\n",
       "         [-1.4536e-01,  5.5392e-01,  2.9812e-01,  4.4193e-01,  4.4817e-01,\n",
       "          -2.9871e-01,  5.8040e-01, -1.4770e+00, -2.0179e-01, -5.4853e-01,\n",
       "           2.7254e-01, -3.0692e-01,  9.1368e-01, -6.0429e-01,  4.9596e-02,\n",
       "          -4.9546e-01, -1.9805e-01, -9.9881e-01, -7.7062e-01, -5.6888e-01,\n",
       "           2.1491e-01, -4.1051e-01, -4.6947e-01, -1.1331e-01,  1.1265e+00,\n",
       "          -9.6643e-02, -4.7978e-01, -5.0860e-01,  1.6646e-01, -1.3358e-01,\n",
       "          -6.2170e-01, -1.9371e-02,  4.0330e-01, -2.4077e-01, -8.4937e-01,\n",
       "           4.9349e-01,  3.9260e-01, -4.6131e-01, -3.6409e-01, -3.4300e-01,\n",
       "           6.3853e-01, -1.1007e+00,  1.5062e+00,  6.1458e-01, -1.2928e+00,\n",
       "           8.1120e-02, -2.8643e-02, -4.1703e-01,  1.2918e-01,  9.3238e-02,\n",
       "           2.1694e-01,  8.3415e-01,  2.0509e-01, -1.2920e-01,  3.6541e-01,\n",
       "          -8.5944e-02, -3.1757e-01,  2.3406e-01,  1.1766e+00,  3.2831e-01,\n",
       "           2.7463e-01, -2.4430e-02, -4.0674e-01,  5.0283e-01,  6.8888e-01,\n",
       "           1.1240e-01, -3.8054e-01,  6.5934e-02, -6.2602e-01,  1.3339e-01,\n",
       "          -3.3167e-01,  4.3306e-02, -6.4323e-01, -6.8720e-01, -3.1595e-02,\n",
       "          -6.4985e-01,  7.4700e-01, -5.0015e-01, -6.2740e-01,  1.1236e+00,\n",
       "          -6.9697e-02, -8.1635e-01, -1.9673e-02, -6.5889e-02, -3.2569e-02,\n",
       "           4.2480e-01, -4.8756e-01,  2.1934e-01, -6.5235e-01, -6.6141e-01,\n",
       "          -7.8216e-02,  2.3134e-01, -9.7027e-02, -2.7521e-01,  1.4148e-01,\n",
       "           2.5657e-01,  2.2111e-01,  1.1657e+00,  4.1412e-01,  4.6133e-01,\n",
       "          -3.7757e-01, -8.0539e-01, -1.2181e-01, -5.1488e-02, -1.0198e-01,\n",
       "           7.3977e-01, -4.3945e-01,  1.8295e-01, -5.4279e-01,  6.7366e-01,\n",
       "           6.5178e-02, -1.1473e-01,  2.2861e-01,  7.9934e-02, -1.9251e-01,\n",
       "           1.1049e-01, -1.4996e-01, -5.4180e-01, -7.2600e-01,  2.2198e-02,\n",
       "           2.8628e-01, -3.8936e-01,  3.1211e-01, -6.5666e-01, -2.6273e-01,\n",
       "           8.6633e-02, -1.1114e+00, -6.0303e-01,  4.9688e-01, -1.8599e-01,\n",
       "          -2.2007e-01, -9.2576e-01,  1.1260e+00,  2.1478e-01,  6.2107e-01,\n",
       "           1.4413e+00,  1.0928e+00,  7.2858e-01,  5.7935e-03, -7.0988e-01,\n",
       "          -1.8991e-02,  2.6676e-01, -4.0584e-01, -1.5072e-01,  3.4060e-01,\n",
       "          -1.3636e+00,  2.9522e-01,  4.4813e-01, -1.1351e+00, -4.3622e-02,\n",
       "          -3.5761e-01,  1.6781e-02,  3.3663e-01,  5.7346e-02, -4.5389e-01,\n",
       "          -7.4884e-02, -2.5031e-01, -9.3544e-02,  3.6636e-01,  2.6193e-01,\n",
       "           1.2648e-01, -5.3385e-01, -3.8216e-01,  3.6900e-01, -4.5524e-01,\n",
       "           1.5273e-01, -3.1704e-01,  3.8389e-02, -6.4259e-01,  7.3908e-04,\n",
       "           1.3356e-01,  1.9521e-01,  5.3425e-01, -7.7229e-01,  6.3780e-01,\n",
       "           3.7297e-02, -8.9557e-01, -5.0720e-01, -3.8165e-01,  1.1355e+00,\n",
       "          -1.9222e-01,  5.3754e-02,  6.1322e-03,  4.2472e-01, -2.1601e-01,\n",
       "          -3.2917e-01,  4.9415e-01, -7.5613e-01,  1.5917e-01,  2.3985e-01,\n",
       "          -2.4819e-01, -2.2880e-01,  1.7150e-01, -9.0013e-02,  4.2296e-01,\n",
       "          -3.0832e-01, -1.6945e-01,  1.6336e+00, -2.3403e-01, -1.1281e-01],\n",
       "         [ 1.4156e-01, -5.0678e-01,  7.7966e-01,  8.0718e-01,  6.0686e-01,\n",
       "          -1.0141e-02,  5.4786e-01,  7.4213e-01,  2.8938e-01,  2.5785e-01,\n",
       "           4.7424e-01, -6.1639e-02,  7.4091e-02, -2.9605e-01,  1.8200e-01,\n",
       "          -8.2949e-03, -6.9129e-01, -7.7586e-01,  2.1147e-01, -5.7034e-01,\n",
       "           2.4722e-01,  2.8962e-01, -5.5969e-01, -7.9522e-03,  3.8855e-02,\n",
       "          -2.5700e-01, -6.2678e-02, -6.0297e-01,  3.3606e-01,  4.9242e-01,\n",
       "          -4.8362e-01,  2.2262e-01,  2.0062e-01,  3.4793e-01, -2.1385e-01,\n",
       "           2.0006e-01,  4.1648e-02, -1.1494e+00, -4.2293e-01,  6.3224e-01,\n",
       "           2.2060e-01,  1.3493e-01,  1.5375e-01,  3.9318e-01,  1.9202e-01,\n",
       "           5.1093e-01, -5.6307e-02, -5.0404e-01, -7.2558e-01,  3.0205e-01,\n",
       "          -1.4780e-01,  3.9894e-01,  2.6029e-01,  5.3768e-02,  6.9952e-01,\n",
       "          -6.7680e-01, -6.8947e-01,  1.0851e-01,  4.5234e-01, -2.7717e-01,\n",
       "           7.2645e-01,  3.9561e-02,  1.4238e-01, -2.7265e-01,  3.7847e-02,\n",
       "          -2.6816e-01,  5.7998e-01, -9.5002e-02,  3.4905e-01, -8.3479e-02,\n",
       "          -1.7814e-02,  1.7977e-01, -3.6334e-01,  9.9569e-02,  3.7420e-01,\n",
       "           3.3040e-01,  3.5661e-01, -2.5240e-01,  1.2895e-01,  9.0691e-02,\n",
       "          -5.3317e-01, -4.0063e-01,  4.9722e-01, -2.5452e-01,  2.8151e-01,\n",
       "          -8.7951e-02,  7.7936e-01,  3.5428e-03, -3.3081e-01,  3.2774e-01,\n",
       "          -6.2967e-01, -2.8500e-01,  7.0700e-03,  9.0628e-02, -2.2130e-01,\n",
       "          -2.5204e-01, -6.7136e-01,  5.7639e-01,  3.8927e-01,  2.1198e-02,\n",
       "           6.2152e-01,  8.5489e-02, -6.6080e-01,  6.1719e-01, -6.1704e-01,\n",
       "          -4.2415e-02,  6.7972e-01, -3.0315e-01,  1.3251e-01,  3.0303e-01,\n",
       "           8.2363e-01,  1.6104e-01,  7.9927e-02, -9.5795e-02, -8.5394e-02,\n",
       "          -6.4389e-01, -1.5715e-01, -1.4235e-01,  4.5985e-01, -6.8769e-01,\n",
       "          -5.5812e-01,  5.5923e-01,  2.9001e-01,  8.8750e-02,  6.0387e-01,\n",
       "           1.0140e-02,  1.0790e-01, -6.0872e-01,  3.2680e-01, -1.2027e-01,\n",
       "          -2.6654e-01, -5.5015e-01, -2.6577e-01, -7.7884e-02, -3.1011e-02,\n",
       "           4.6137e-01, -2.2166e-01, -1.1449e-01,  1.6601e-01,  4.9951e-01,\n",
       "           5.0290e-01,  5.5421e-01, -7.0185e-01,  6.0537e-01,  7.5473e-01,\n",
       "           4.2907e-01, -1.6841e-02, -3.5979e-01, -2.9707e-01,  4.6024e-01,\n",
       "          -3.0080e-02, -8.2760e-02,  6.2749e-01, -8.9281e-02,  2.2780e-01,\n",
       "          -5.5291e-01,  2.7622e-02,  5.9610e-01,  6.8398e-01,  9.3030e-01,\n",
       "          -1.7943e-03, -6.3688e-01, -4.9186e-01,  1.0878e-02,  1.4575e-01,\n",
       "          -6.4138e-01, -1.0492e-01,  5.6630e-01, -2.5475e-01,  1.6291e-01,\n",
       "           1.6652e-01,  5.1555e-01, -2.9265e-01,  1.6371e-01,  4.8898e-02,\n",
       "           5.6251e-02,  1.0005e+00,  1.0314e-02,  4.8191e-02,  5.4363e-02,\n",
       "           1.9312e-01, -4.1189e-01, -2.7724e-01,  3.7188e-01,  7.3635e-02,\n",
       "           2.0972e-01,  3.9814e-01, -1.0235e-01, -3.3091e-01,  2.5060e-01,\n",
       "           7.4936e-01,  1.8735e-01, -6.0726e-01,  2.4869e-01,  5.1823e-01,\n",
       "           7.6680e-02,  5.5211e-01,  2.2254e-01, -7.0877e-01, -3.0814e-01],\n",
       "         [ 8.7517e-02, -2.7345e-01, -4.0358e-01,  4.5261e-01,  5.9520e-01,\n",
       "          -2.9361e-01,  7.6543e-01, -1.1811e-01,  8.6190e-02, -1.7683e-01,\n",
       "          -3.5256e-02, -1.3046e+00, -4.4993e-01,  5.9332e-01,  6.7293e-01,\n",
       "          -1.1390e-01, -1.4913e-01, -3.5427e-01, -2.5689e-01,  1.1874e-01,\n",
       "           3.9823e-01,  1.1887e-01, -1.5072e-01,  5.1768e-01,  1.8243e-01,\n",
       "          -5.4341e-01, -5.5553e-01,  6.9274e-03,  1.5833e-02, -1.5042e-02,\n",
       "           3.2457e-01, -2.5263e-02, -6.9379e-01,  8.9511e-01, -8.1090e-01,\n",
       "          -2.8731e-01,  4.9048e-01, -1.1954e-01, -3.0801e-01,  3.4272e-01,\n",
       "           1.2604e-01,  5.1017e-01,  1.9480e-01,  8.4207e-01, -7.2043e-01,\n",
       "           7.5410e-01, -7.0714e-01,  6.2022e-02, -4.4928e-01, -3.0809e-01,\n",
       "           6.3112e-02,  3.7792e-01,  3.7696e-01, -1.4341e-01,  5.9667e-01,\n",
       "          -8.2156e-01,  4.6235e-01, -1.0687e-01,  9.2590e-02, -6.9684e-02,\n",
       "           3.4310e-03, -1.5380e+00, -1.8168e-01, -8.6865e-01, -3.7861e-01,\n",
       "          -4.8969e-02,  4.5914e-01,  1.1621e-02,  3.7716e-01, -1.8969e-01,\n",
       "          -7.2729e-01, -6.2742e-01,  3.2867e-01,  1.7686e-01, -7.4276e-01,\n",
       "          -1.0157e-01,  1.7580e-02,  1.1884e-01, -8.7564e-02,  2.5035e-01,\n",
       "          -6.6906e-01, -1.4886e-01, -3.2211e-01, -8.1222e-01, -4.7639e-01,\n",
       "          -4.7992e-01, -2.8818e-01,  5.1587e-01, -8.5724e-01, -1.9737e-01,\n",
       "           3.0092e-01,  1.7662e-01, -4.1648e-01,  5.7279e-01,  5.8098e-01,\n",
       "           1.1640e-01, -4.2991e-01,  1.6521e-01,  5.4644e-01,  3.9863e-01,\n",
       "           2.3163e-01,  2.5677e-01,  5.7594e-02, -2.5124e-01, -7.1971e-01,\n",
       "          -5.9191e-01, -4.5631e-02,  3.9170e-01,  6.7746e-01,  3.4129e-01,\n",
       "           1.1936e-01, -6.5064e-01, -2.4273e-01,  3.3908e-01,  3.6667e-01,\n",
       "          -3.4387e-01, -2.6435e-01,  5.2533e-02, -1.9481e-01, -5.1249e-01,\n",
       "           1.2265e-01,  6.7221e-01,  2.5098e-01,  1.0872e-01,  4.5318e-01,\n",
       "           7.1141e-01, -5.1394e-01, -2.0935e-01, -2.1140e-01, -3.1978e-01,\n",
       "           4.3257e-02, -8.4355e-02,  6.5692e-01,  1.0299e+00,  7.5366e-02,\n",
       "           3.4035e-01, -3.1163e-01, -4.5705e-04, -7.4522e-01,  6.7055e-03,\n",
       "           1.6613e-01,  4.0905e-02, -4.6555e-02,  4.6919e-01,  5.4006e-01,\n",
       "          -3.8579e-01, -6.0621e-01,  2.1555e-01, -2.8349e-01, -4.2690e-01,\n",
       "          -2.4389e-01, -4.7151e-02,  2.2807e-01,  6.5343e-01,  2.2175e-02,\n",
       "           1.4745e-01,  7.2050e-01, -2.7625e-02,  1.7752e-01, -2.0289e-01,\n",
       "           3.6847e-01,  2.6291e-01,  8.0636e-01, -1.5845e-01, -1.6706e-02,\n",
       "          -3.3238e-01, -1.4072e-01,  7.8498e-01,  8.4102e-01,  2.9727e-01,\n",
       "           6.7397e-01,  3.4847e-02,  2.5653e-01,  2.6768e-01,  5.4768e-01,\n",
       "          -3.7146e-01,  3.7702e-01, -5.8816e-01,  1.0338e-01,  1.5593e-01,\n",
       "           4.7690e-01,  4.1236e-01,  3.9635e-01,  4.8106e-01,  2.2893e-02,\n",
       "          -6.3951e-01, -6.6784e-01,  1.0034e-01, -3.5333e-01,  1.8592e-01,\n",
       "          -2.9962e-01,  3.9484e-01,  4.8660e-01, -6.7564e-02, -1.0215e-01,\n",
       "           2.2868e-02, -1.6731e-01,  8.7103e-01, -3.8299e-01, -4.3645e-01]]),\n",
       " tensor([[-4.4816e-02,  2.6072e-01,  1.4476e-01,  1.3985e-01,  8.2186e-01,\n",
       "          -1.8453e-01,  3.9610e-01, -3.3248e-01, -1.8321e-03, -3.2702e-01,\n",
       "          -1.4955e-01, -7.9797e-01,  3.2212e-01,  5.0457e-01, -1.4466e-02,\n",
       "          -1.5588e-01, -5.8039e-01, -8.2334e-01, -1.2749e-01,  1.2681e-02,\n",
       "           1.7029e-01,  2.0639e-01,  1.8592e-01,  9.1905e-02,  7.9670e-01,\n",
       "           3.7350e-03, -1.1508e-01, -9.2960e-02, -5.0474e-02, -5.2370e-01,\n",
       "           2.4938e-01,  5.0046e-02, -2.2510e-01,  8.2782e-01, -8.8028e-02,\n",
       "          -3.1285e-01,  2.1367e-01, -1.2164e-01,  6.2164e-02,  3.9969e-02,\n",
       "          -1.9242e-01,  5.9761e-01,  8.7907e-01,  2.6625e-01, -6.2292e-01,\n",
       "           3.5723e-01, -5.6910e-01, -2.2975e-02, -4.4734e-01, -2.3245e-01,\n",
       "          -1.6014e-02,  2.4307e-02, -2.9628e-01,  3.4902e-03,  2.8123e-01,\n",
       "          -3.6569e-01, -5.6186e-02, -8.3109e-02,  3.7591e-01, -3.0810e-01,\n",
       "          -3.9157e-01, -5.8018e-01,  4.4514e-02, -3.4728e-01, -1.4072e-02,\n",
       "           9.6888e-02,  4.2398e-02, -2.0702e-01,  1.1550e-03,  4.9811e-01,\n",
       "          -3.3000e-01, -2.3525e-01, -8.9399e-02,  2.0654e-01, -1.4491e-01,\n",
       "          -4.1638e-02,  2.2768e-01,  1.7223e-01, -1.9337e-01,  5.4533e-01,\n",
       "          -1.8066e-01,  4.5702e-02, -1.8615e-01, -5.7819e-01,  3.1169e-02,\n",
       "           1.2292e-02, -3.2395e-01,  5.6787e-01, -3.4982e-01, -1.6895e-01,\n",
       "          -4.9290e-01,  1.7113e-01,  1.2016e-01,  6.5679e-01,  5.1149e-01,\n",
       "           1.3962e-01, -1.4009e-02,  8.0457e-01, -1.6864e-03,  4.5210e-01,\n",
       "           3.1804e-01, -6.4181e-02, -3.4219e-01, -1.9089e-01, -5.3410e-01,\n",
       "          -5.3507e-01, -5.3707e-02, -5.6995e-02,  4.4185e-02,  2.6180e-01,\n",
       "          -5.3361e-01, -5.3296e-01, -3.7533e-01,  5.2777e-01, -4.5300e-02,\n",
       "          -1.5200e-01, -1.8493e-01, -1.5568e-01,  1.2953e-01,  2.1748e-01,\n",
       "          -4.5083e-01,  1.0669e-01, -2.5463e-01,  2.3678e-01,  5.8170e-03,\n",
       "           1.8802e-01, -9.0083e-02, -9.5030e-01, -3.3442e-01, -4.9307e-01,\n",
       "          -7.0966e-02, -5.5689e-01,  3.3150e-01,  1.6025e-01, -2.6116e-01,\n",
       "           6.1389e-02, -5.4729e-01, -1.4360e-01, -3.0535e-01, -3.5357e-01,\n",
       "          -6.2616e-01, -2.2439e-02, -2.0740e-01,  2.1965e-01,  4.6478e-01,\n",
       "          -1.3669e-01, -1.0145e-01,  1.0842e-01,  5.0507e-03,  2.9468e-01,\n",
       "          -2.0390e-02,  7.9607e-02, -5.0416e-03, -9.2473e-02,  3.1267e-01,\n",
       "           5.8991e-01,  1.1121e+00,  3.1630e-02, -4.6566e-02, -3.7113e-01,\n",
       "          -8.5519e-02, -2.8330e-02, -2.7766e-02, -4.7535e-01, -6.3396e-01,\n",
       "          -7.5772e-02, -3.1621e-03,  3.7479e-02,  1.3982e-01, -5.8328e-02,\n",
       "           3.6327e-01, -4.1039e-02, -9.3303e-02,  6.7044e-02,  3.8285e-01,\n",
       "          -3.5371e-01,  5.5917e-01, -3.6336e-01,  7.0457e-03,  4.0882e-01,\n",
       "           3.3558e-01,  3.1595e-01,  2.6091e-01,  3.2326e-01,  7.1776e-02,\n",
       "          -2.9163e-01,  1.2613e-01,  1.7375e-01, -5.7487e-01,  3.6839e-01,\n",
       "           2.2042e-01,  3.1725e-01, -4.6196e-01, -5.9088e-02, -6.9970e-01,\n",
       "           2.6686e-02, -4.2077e-01,  4.2432e-01, -1.1535e-01, -6.1969e-02],\n",
       "         [-1.4396e-01,  2.1481e-01, -3.5009e-01, -6.5346e-02,  5.2983e-01,\n",
       "           1.1885e-02, -2.6024e-01, -1.1156e-01, -1.1614e-01, -8.3254e-02,\n",
       "          -2.2453e-01,  2.3192e-01, -4.2215e-01, -1.8149e-01, -1.3944e-01,\n",
       "          -2.6138e-01, -1.2130e-01, -7.9088e-01, -3.4227e-01,  1.4570e-01,\n",
       "           3.3751e-02,  2.3919e-01, -8.2738e-02,  1.8252e-01,  2.6087e-01,\n",
       "          -1.6529e-01, -2.8137e-01,  3.6956e-01,  2.8971e-01,  7.7912e-01,\n",
       "          -3.7560e-01, -9.9901e-02,  1.2130e-01,  1.7315e-01, -3.3254e-01,\n",
       "          -4.8140e-01, -5.9787e-01,  3.2991e-01, -2.5274e-01, -2.3591e-01,\n",
       "           1.0740e-02,  8.7820e-02,  3.2987e-01, -4.4031e-02, -6.5200e-01,\n",
       "           1.1049e-01,  7.7680e-02, -4.5371e-01, -5.4696e-01, -6.2639e-01,\n",
       "           3.3679e-03, -4.7706e-01,  2.8693e-01, -1.2150e-01, -9.0868e-02,\n",
       "           1.1261e-01, -2.5957e-01, -2.0086e-01,  3.0610e-01, -3.2639e-01,\n",
       "          -5.7243e-01,  6.4499e-01,  1.2269e-01, -6.9326e-02,  4.5879e-02,\n",
       "           4.5423e-01, -3.4557e-01,  2.1610e-01,  2.7005e-01,  3.6942e-01,\n",
       "          -3.7049e-01, -3.3404e-01, -1.1758e-01,  2.6109e-01,  2.5053e-01,\n",
       "           3.7146e-01, -3.2846e-01, -4.4636e-01,  2.1562e-01,  5.2984e-01,\n",
       "          -6.7958e-02,  2.0044e-01, -7.1392e-01,  1.9113e-01,  3.3152e-01,\n",
       "          -1.4613e-01,  5.7090e-01,  2.5116e-02,  1.2803e-05, -6.3544e-01,\n",
       "           1.0075e-01, -1.1546e+00, -5.6727e-02, -7.8067e-02,  1.4473e-01,\n",
       "          -2.1801e-01, -1.4957e-02,  8.8176e-01,  1.0772e-01,  8.3376e-01,\n",
       "           3.0782e-01,  5.8873e-02,  3.8509e-02, -9.1644e-02, -4.5544e-01,\n",
       "          -1.8400e-01, -2.5928e-01,  2.8496e-01,  1.3513e-01,  2.5362e-01,\n",
       "          -7.2363e-01,  3.7540e-01,  5.1872e-01,  4.2864e-01, -2.7660e-01,\n",
       "           3.4767e-03, -3.1505e-01, -2.3124e-01, -7.6480e-02, -4.4539e-01,\n",
       "           3.4426e-01,  3.6610e-01, -8.0097e-01,  5.5373e-01,  4.6654e-01,\n",
       "           3.9718e-02,  3.1395e-01, -1.1974e+00,  4.4751e-01,  1.6503e-01,\n",
       "          -2.3665e-01, -6.4710e-02, -1.0447e-01,  4.5263e-02,  1.9797e-01,\n",
       "          -1.3300e-01, -3.1619e-01, -1.4163e-01, -2.5632e-01, -7.6195e-01,\n",
       "           5.9320e-01,  1.3063e-01,  3.8656e-01,  3.6273e-01,  2.8524e-01,\n",
       "          -1.1337e-01,  5.2575e-01,  5.7943e-01, -2.0706e-01, -4.8154e-01,\n",
       "          -6.1839e-02, -2.2911e-01,  4.5455e-01,  2.4437e-01,  1.5888e-01,\n",
       "           3.4238e-02,  1.1307e-01,  2.4155e-02,  4.2919e-01,  3.7045e-01,\n",
       "           2.2619e-01, -9.0192e-01,  1.9372e-02,  2.5740e-01, -1.8927e-01,\n",
       "          -2.3282e-01, -3.0733e-01,  5.0908e-01,  2.4381e-01,  2.8834e-01,\n",
       "          -1.9346e-01,  1.8007e-01,  3.9422e-02, -5.6632e-01,  2.3718e-01,\n",
       "          -2.1120e-01,  2.3435e-01, -1.4699e-01, -2.1394e-01, -3.3583e-01,\n",
       "           4.6670e-01,  5.8768e-01,  6.1518e-01,  1.2019e-01,  3.2928e-01,\n",
       "          -1.8714e-02,  3.1321e-01, -4.0959e-01, -4.3951e-02, -1.7004e-02,\n",
       "           4.6783e-02,  9.3191e-02, -8.4512e-01,  1.4903e-02,  6.8291e-01,\n",
       "          -2.0756e-01, -4.8853e-01,  1.6923e-01, -1.7999e-01,  1.4646e-01],\n",
       "         [-6.0200e-02,  6.7795e-01,  4.3946e-01,  2.3110e-01,  5.3686e-01,\n",
       "          -1.6125e-01,  1.4847e-01, -3.3724e-01,  1.1674e-02, -9.3484e-02,\n",
       "           2.9573e-02, -4.9728e-01,  3.8120e-01,  4.6101e-01, -9.8824e-02,\n",
       "          -2.9805e-01, -2.5457e-01, -5.9887e-01, -9.3961e-02, -5.4609e-02,\n",
       "           1.9000e-04,  3.7492e-02,  1.1499e-02,  3.9090e-01,  7.5765e-01,\n",
       "           1.8973e-01, -7.4093e-02, -1.2624e-01,  1.4864e-01, -4.4352e-01,\n",
       "           5.1175e-01,  3.9434e-01, -2.6017e-01,  8.1767e-01,  1.1335e-01,\n",
       "          -2.3792e-01, -2.5978e-01, -4.5919e-01,  1.5570e-01,  8.6123e-02,\n",
       "          -2.3690e-01,  5.1015e-01,  5.4774e-01,  1.9783e-01, -3.9902e-01,\n",
       "          -1.3025e-01, -3.9501e-01,  9.8975e-03, -2.6508e-01, -1.2424e-01,\n",
       "          -5.0638e-02,  8.9328e-02, -2.1367e-01,  8.3521e-02,  3.5002e-01,\n",
       "          -3.7924e-01, -5.2893e-02, -1.6210e-01,  4.5505e-01, -4.7546e-02,\n",
       "          -5.1950e-01, -3.1812e-01,  9.3436e-02, -5.2239e-01,  2.7634e-01,\n",
       "          -1.6042e-01, -2.4219e-01, -9.8085e-02,  8.5785e-02,  1.5771e-01,\n",
       "          -3.4957e-01, -2.8029e-01, -4.0376e-02,  2.4061e-01, -8.1955e-02,\n",
       "          -4.2529e-01,  3.2125e-01,  2.7218e-02,  1.1657e-01,  2.2890e-01,\n",
       "          -1.4386e-01, -1.2758e-01, -8.3897e-02, -2.0104e-01,  3.6062e-01,\n",
       "           3.1880e-02, -3.7200e-01,  2.1298e-01, -2.2907e-01, -1.0683e-01,\n",
       "          -1.9289e-01,  8.6656e-02, -1.6185e-01,  4.0439e-01,  3.0462e-01,\n",
       "           1.8924e-01,  1.2827e-01,  4.6709e-01,  5.7765e-01,  2.3836e-01,\n",
       "           1.3184e-01, -1.6096e-01, -1.6918e-01, -8.2903e-02, -3.3935e-01,\n",
       "          -7.1439e-01, -9.5788e-02, -2.5996e-01,  2.0538e-01,  3.0879e-01,\n",
       "          -4.1917e-01, -2.3519e-01, -1.0509e-01,  3.8413e-01, -1.1683e-01,\n",
       "          -3.0670e-01, -6.2121e-04, -3.6614e-01, -8.7534e-02, -2.3368e-01,\n",
       "          -5.6445e-01, -3.7052e-02, -2.0083e-01,  2.5548e-01,  2.6027e-01,\n",
       "           3.1072e-01,  9.5195e-02, -9.1055e-01, -3.0402e-01, -2.4066e-01,\n",
       "          -1.1391e-01, -5.6033e-01,  5.8719e-02,  8.2264e-02,  1.6512e-03,\n",
       "           3.1217e-01, -6.3473e-01, -1.2900e-01, -5.1286e-01, -4.3817e-01,\n",
       "          -1.6406e-01,  2.7804e-01, -2.8734e-01,  2.5258e-01,  2.3454e-01,\n",
       "          -2.7116e-01, -9.4259e-02,  3.2925e-02, -1.6711e-01,  5.4052e-01,\n",
       "           1.3911e-02, -2.4934e-01, -9.5650e-02, -1.1411e-01,  1.8863e-01,\n",
       "           2.4827e-01,  6.8400e-01, -3.2786e-01, -1.9717e-01, -1.0976e-01,\n",
       "          -1.1020e-01, -7.5480e-02, -9.4221e-02, -6.5897e-01, -2.4192e-01,\n",
       "          -5.7905e-02,  8.0696e-02,  4.1716e-01,  2.5168e-01, -1.5813e-01,\n",
       "           1.6550e-01, -1.7860e-01, -4.0642e-01, -1.1334e-01,  7.6290e-02,\n",
       "          -1.1712e-01,  4.4572e-01, -5.0249e-01, -1.4953e-01,  4.0058e-01,\n",
       "           3.8590e-01,  2.8534e-01,  3.2363e-01,  1.0158e-01, -5.4234e-02,\n",
       "          -4.1939e-01,  4.9763e-01,  2.7607e-01, -4.4584e-01,  3.2613e-01,\n",
       "           3.6119e-01,  7.7879e-02, -4.8412e-01, -2.2078e-01, -8.7630e-01,\n",
       "          -7.7526e-02, -7.8600e-02,  3.1040e-01, -7.7514e-02,  5.5448e-01],\n",
       "         [-4.4816e-02,  2.6072e-01,  1.4476e-01,  1.3985e-01,  8.2186e-01,\n",
       "          -1.8453e-01,  3.9610e-01, -3.3248e-01, -1.8321e-03, -3.2702e-01,\n",
       "          -1.4955e-01, -7.9797e-01,  3.2212e-01,  5.0457e-01, -1.4466e-02,\n",
       "          -1.5588e-01, -5.8039e-01, -8.2334e-01, -1.2749e-01,  1.2681e-02,\n",
       "           1.7029e-01,  2.0639e-01,  1.8592e-01,  9.1905e-02,  7.9670e-01,\n",
       "           3.7350e-03, -1.1508e-01, -9.2960e-02, -5.0474e-02, -5.2370e-01,\n",
       "           2.4938e-01,  5.0046e-02, -2.2510e-01,  8.2782e-01, -8.8028e-02,\n",
       "          -3.1285e-01,  2.1367e-01, -1.2164e-01,  6.2164e-02,  3.9969e-02,\n",
       "          -1.9242e-01,  5.9761e-01,  8.7907e-01,  2.6625e-01, -6.2292e-01,\n",
       "           3.5723e-01, -5.6910e-01, -2.2975e-02, -4.4734e-01, -2.3245e-01,\n",
       "          -1.6014e-02,  2.4307e-02, -2.9628e-01,  3.4902e-03,  2.8123e-01,\n",
       "          -3.6569e-01, -5.6186e-02, -8.3109e-02,  3.7591e-01, -3.0810e-01,\n",
       "          -3.9157e-01, -5.8018e-01,  4.4514e-02, -3.4728e-01, -1.4072e-02,\n",
       "           9.6888e-02,  4.2398e-02, -2.0702e-01,  1.1550e-03,  4.9811e-01,\n",
       "          -3.3000e-01, -2.3525e-01, -8.9399e-02,  2.0654e-01, -1.4491e-01,\n",
       "          -4.1638e-02,  2.2768e-01,  1.7223e-01, -1.9337e-01,  5.4533e-01,\n",
       "          -1.8066e-01,  4.5702e-02, -1.8615e-01, -5.7819e-01,  3.1169e-02,\n",
       "           1.2292e-02, -3.2395e-01,  5.6787e-01, -3.4982e-01, -1.6895e-01,\n",
       "          -4.9290e-01,  1.7113e-01,  1.2016e-01,  6.5679e-01,  5.1149e-01,\n",
       "           1.3962e-01, -1.4009e-02,  8.0457e-01, -1.6864e-03,  4.5210e-01,\n",
       "           3.1804e-01, -6.4181e-02, -3.4219e-01, -1.9089e-01, -5.3410e-01,\n",
       "          -5.3507e-01, -5.3707e-02, -5.6995e-02,  4.4185e-02,  2.6180e-01,\n",
       "          -5.3361e-01, -5.3296e-01, -3.7533e-01,  5.2777e-01, -4.5300e-02,\n",
       "          -1.5200e-01, -1.8493e-01, -1.5568e-01,  1.2953e-01,  2.1748e-01,\n",
       "          -4.5083e-01,  1.0669e-01, -2.5463e-01,  2.3678e-01,  5.8170e-03,\n",
       "           1.8802e-01, -9.0083e-02, -9.5030e-01, -3.3442e-01, -4.9307e-01,\n",
       "          -7.0966e-02, -5.5689e-01,  3.3150e-01,  1.6025e-01, -2.6116e-01,\n",
       "           6.1389e-02, -5.4729e-01, -1.4360e-01, -3.0535e-01, -3.5357e-01,\n",
       "          -6.2616e-01, -2.2439e-02, -2.0740e-01,  2.1965e-01,  4.6478e-01,\n",
       "          -1.3669e-01, -1.0145e-01,  1.0842e-01,  5.0507e-03,  2.9468e-01,\n",
       "          -2.0390e-02,  7.9607e-02, -5.0416e-03, -9.2473e-02,  3.1267e-01,\n",
       "           5.8991e-01,  1.1121e+00,  3.1630e-02, -4.6566e-02, -3.7113e-01,\n",
       "          -8.5519e-02, -2.8330e-02, -2.7766e-02, -4.7535e-01, -6.3396e-01,\n",
       "          -7.5772e-02, -3.1621e-03,  3.7479e-02,  1.3982e-01, -5.8328e-02,\n",
       "           3.6327e-01, -4.1039e-02, -9.3303e-02,  6.7044e-02,  3.8285e-01,\n",
       "          -3.5371e-01,  5.5917e-01, -3.6336e-01,  7.0457e-03,  4.0882e-01,\n",
       "           3.3558e-01,  3.1595e-01,  2.6091e-01,  3.2326e-01,  7.1776e-02,\n",
       "          -2.9163e-01,  1.2613e-01,  1.7375e-01, -5.7487e-01,  3.6839e-01,\n",
       "           2.2042e-01,  3.1725e-01, -4.6196e-01, -5.9088e-02, -6.9970e-01,\n",
       "           2.6686e-02, -4.2077e-01,  4.2432e-01, -1.1535e-01, -6.1969e-02],\n",
       "         [-9.2930e-01, -9.2135e-03,  4.2353e-01,  1.6734e-01,  4.4009e-01,\n",
       "          -2.2296e-01,  4.1152e-01, -2.6278e-02, -1.5302e-01, -6.8330e-01,\n",
       "           3.6782e-02, -2.5053e-01, -4.6807e-01, -3.0188e-02,  4.0027e-01,\n",
       "          -1.6179e-01,  2.3475e-01, -7.3425e-01,  2.2147e-01, -1.4457e-01,\n",
       "           2.6918e-01,  3.8407e-01, -3.5920e-03,  2.0688e-02,  4.6355e-01,\n",
       "          -1.3068e-01, -6.8304e-01,  9.9794e-02,  2.4794e-01, -6.1920e-01,\n",
       "          -1.8514e-01,  3.2041e-01, -4.5715e-02,  4.9203e-01, -3.6473e-01,\n",
       "          -8.9405e-02, -5.0924e-01, -2.8503e-01, -4.3668e-02,  5.4589e-02,\n",
       "          -1.9689e-01, -1.8938e-01, -2.5355e-01,  3.2896e-01, -5.9109e-01,\n",
       "          -1.6952e-01,  5.4394e-02,  1.8031e-01, -4.9719e-01, -4.6237e-01,\n",
       "          -3.4295e-01, -1.6637e-01, -1.4335e-01, -2.1018e-01,  6.0869e-01,\n",
       "           1.1496e-02, -2.5030e-01, -3.8457e-01,  6.3989e-01,  3.2420e-01,\n",
       "           2.5028e-01, -1.5940e-02, -2.7241e-01,  2.6412e-01, -2.0011e-02,\n",
       "          -3.2361e-01, -1.4562e-01,  9.0856e-02, -8.9571e-02, -1.0344e-01,\n",
       "          -3.1588e-01,  1.2845e-01,  6.7745e-01,  4.8054e-02, -2.1955e-01,\n",
       "          -2.4669e-01, -6.4512e-02, -2.9918e-01,  9.8561e-02, -1.1140e-02,\n",
       "          -3.8459e-01, -6.3687e-01, -1.6964e-01, -1.2895e-01,  2.6887e-01,\n",
       "          -9.9578e-03,  1.3532e-01,  3.2465e-01, -5.0565e-01, -3.5743e-01,\n",
       "          -3.5666e-01, -5.7944e-01, -9.2758e-01,  2.5207e-01,  2.6595e-01,\n",
       "          -5.2561e-02,  1.3124e-01, -6.2583e-02,  6.1142e-01,  1.6781e-01,\n",
       "          -1.7657e-02,  9.4858e-01, -2.3061e-01,  1.2464e-01, -2.9930e-01,\n",
       "           1.7431e-01,  2.0563e-01, -2.1501e-01,  9.2296e-02,  2.3111e-01,\n",
       "           2.4290e-02, -2.6300e-02,  5.1902e-02,  4.2089e-01, -3.9684e-01,\n",
       "           3.1285e-01, -4.0177e-01, -1.8316e-01, -2.0869e-01, -2.0673e-01,\n",
       "           2.7119e-01,  1.2501e+00, -1.8888e-01,  5.6085e-02,  1.1932e-01,\n",
       "           3.8024e-01, -5.7864e-01,  1.5977e-01,  2.5242e-01, -6.8198e-01,\n",
       "           3.0098e-01,  4.1073e-01,  3.8200e-01,  3.5848e-01, -5.0015e-01,\n",
       "          -4.7571e-01, -2.5609e-01,  3.1861e-01, -5.3759e-01,  2.0168e-01,\n",
       "          -7.4545e-02,  4.7931e-01, -9.3755e-02,  2.8486e-01,  5.1019e-01,\n",
       "          -1.2590e-01, -1.9318e-01, -1.8902e-01, -2.8591e-01, -1.5392e-01,\n",
       "           2.5834e-02,  4.5554e-01,  1.1442e-01,  3.7914e-02,  3.3602e-01,\n",
       "          -5.3507e-01,  3.0078e-01,  1.9925e-01,  9.2256e-01, -5.3039e-01,\n",
       "           2.3933e-01, -6.3226e-01, -6.8685e-02,  4.7607e-01,  7.1693e-01,\n",
       "          -6.6275e-01, -2.5663e-01,  3.7022e-01,  5.6524e-01,  1.0342e+00,\n",
       "           5.6138e-02,  4.7404e-01, -3.1056e-02, -2.3646e-01,  5.3365e-01,\n",
       "          -2.9200e-03,  1.9827e-01, -3.2508e-01, -3.8627e-01,  2.2466e-01,\n",
       "           1.5874e-01, -6.3870e-02, -1.0380e-01,  1.0451e-01,  8.9899e-02,\n",
       "          -4.0556e-01,  5.5388e-01,  3.8112e-02, -3.9193e-01,  4.7238e-01,\n",
       "          -6.6472e-02,  4.8676e-01,  5.2961e-02,  1.9852e-01,  6.0552e-01,\n",
       "          -1.1039e-01, -3.0687e-01,  2.9094e-01, -6.0585e-01, -3.0507e-01]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_input_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 200])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_input_vectors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_input_tensor = torch.stack(multiple_input_vectors).to(DEVICE)\n",
    "\n",
    "multiple_output = Lstm(multiple_input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0153,  0.0258],\n",
       "        [-0.0802, -0.0404],\n",
       "        [ 0.0309,  0.0406]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_loss = loss_function(\n",
    "  multiple_output,\n",
    "  LongTensor(TARGET_INPUTS).to(DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6914, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving for Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_softmax = torch.softmax(\n",
    "  multiple_output,\n",
    "  dim=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4897, 0.5103],\n",
       "        [0.4901, 0.5099],\n",
       "        [0.4976, 0.5024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_log = -np.log(\n",
    "  multiple_softmax.cpu().detach().numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71389526, 0.67282087],\n",
       "       [0.71321046, 0.67347854],\n",
       "       [0.698017  , 0.6883009 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_log_sum = negative_log[0][1] + negative_log[1][0] + negative_log[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0743322"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_log_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914440790812174"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_log_sum / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss.backward() and optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = OPTIMIZER(Lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "lstm.weight_ih_l0\n",
      "Data:\n",
      "tensor([[-0.1239,  0.1066, -0.0891,  ..., -0.0025,  0.0033, -0.1201],\n",
      "        [-0.0176,  0.0893, -0.0530,  ...,  0.1127, -0.1001,  0.1381],\n",
      "        [-0.0037, -0.0664, -0.0285,  ..., -0.0991,  0.1128,  0.1191],\n",
      "        ...,\n",
      "        [ 0.0917, -0.1298, -0.0994,  ..., -0.1303, -0.0218, -0.0057],\n",
      "        [ 0.1219,  0.0866, -0.0026,  ..., -0.1135, -0.0781, -0.1379],\n",
      "        [-0.0120,  0.1171,  0.0788,  ...,  0.0240, -0.0921,  0.0717]],\n",
      "       device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([200, 200])\n",
      "-----\n",
      "lstm.weight_hh_l0\n",
      "Data:\n",
      "tensor([[-0.0472, -0.0489, -0.0697,  ...,  0.0132, -0.0693, -0.0331],\n",
      "        [ 0.0785, -0.0701,  0.0671,  ...,  0.0086,  0.1316,  0.0077],\n",
      "        [ 0.0520,  0.0476,  0.0237,  ..., -0.0411,  0.0880, -0.0962],\n",
      "        ...,\n",
      "        [ 0.0227,  0.0427, -0.0436,  ...,  0.0777,  0.0803, -0.1196],\n",
      "        [-0.0443, -0.0592, -0.1309,  ..., -0.1297, -0.0988,  0.0421],\n",
      "        [ 0.1303, -0.0453, -0.0733,  ..., -0.0631,  0.0065, -0.0610]],\n",
      "       device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([200, 50])\n",
      "-----\n",
      "lstm.bias_ih_l0\n",
      "Data:\n",
      "tensor([-0.0294, -0.0940,  0.1060, -0.0234,  0.1103, -0.1158, -0.0416, -0.0622,\n",
      "         0.0033, -0.1046,  0.0373,  0.1059, -0.0853,  0.0003,  0.0606, -0.0607,\n",
      "         0.0925, -0.0367,  0.0331, -0.1149,  0.1035, -0.1304,  0.1339,  0.1269,\n",
      "        -0.0623,  0.0739, -0.1275, -0.1375, -0.0471, -0.0256,  0.1066,  0.1386,\n",
      "         0.0527,  0.0820, -0.1093,  0.0466, -0.0591, -0.0197,  0.0823, -0.0866,\n",
      "         0.0842, -0.0940, -0.0354, -0.0975,  0.0010,  0.0811, -0.1248,  0.0333,\n",
      "        -0.0643, -0.0891,  0.1383,  0.0129,  0.0358,  0.0991, -0.0049, -0.0321,\n",
      "        -0.1380, -0.1035, -0.0542,  0.0569,  0.0089,  0.0686,  0.0203,  0.1321,\n",
      "         0.0178, -0.0867,  0.1106,  0.0281, -0.0766, -0.0328,  0.0159,  0.0589,\n",
      "         0.0536,  0.1247, -0.0854, -0.0204,  0.1116, -0.0345, -0.1359, -0.0031,\n",
      "        -0.0795,  0.0226, -0.0231, -0.0565, -0.0112,  0.0553,  0.1030, -0.1311,\n",
      "         0.0492, -0.0068, -0.0408, -0.0287,  0.0932, -0.0413,  0.0191,  0.0532,\n",
      "        -0.0780, -0.0158, -0.1067, -0.0765,  0.0339, -0.0571, -0.1270,  0.0632,\n",
      "         0.1003,  0.1183,  0.0385, -0.0203, -0.0029,  0.0925,  0.1378, -0.1349,\n",
      "        -0.0507, -0.0409,  0.1295, -0.1033,  0.0957,  0.0228,  0.1082, -0.0266,\n",
      "         0.0411,  0.0304, -0.0221,  0.0010, -0.1271, -0.1288, -0.1251, -0.0446,\n",
      "         0.0744, -0.0932, -0.0388,  0.0609, -0.0800,  0.0406, -0.0290, -0.0294,\n",
      "         0.0482, -0.0195, -0.0657, -0.0602,  0.0697, -0.0532,  0.0118,  0.1230,\n",
      "         0.1037,  0.0690,  0.0346, -0.0268,  0.1037,  0.1167, -0.0002, -0.1134,\n",
      "         0.0284, -0.0610,  0.0363,  0.1058,  0.0290,  0.1334, -0.0105,  0.0660,\n",
      "        -0.0360,  0.0050, -0.0635,  0.1409,  0.1384, -0.0063,  0.0693,  0.1079,\n",
      "        -0.0322,  0.0432, -0.0522,  0.0873, -0.0849, -0.1002,  0.0676,  0.0062,\n",
      "        -0.0694, -0.0770,  0.0749, -0.1065, -0.1118,  0.0674,  0.0933, -0.0517,\n",
      "        -0.0493,  0.1036, -0.1281,  0.0980, -0.0157, -0.0178,  0.0854,  0.0811,\n",
      "         0.1085, -0.0188,  0.1381,  0.0247, -0.0386,  0.1098, -0.0400,  0.1335],\n",
      "       device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([200])\n",
      "-----\n",
      "lstm.bias_hh_l0\n",
      "Data:\n",
      "tensor([ 0.0390, -0.0370,  0.1039, -0.0063,  0.1345, -0.0566, -0.1188,  0.0396,\n",
      "         0.0519,  0.0536,  0.0055, -0.1372,  0.0811, -0.0459, -0.0884, -0.0526,\n",
      "         0.0588, -0.1027,  0.0750,  0.0034, -0.0629, -0.0022, -0.0550,  0.0467,\n",
      "         0.0907, -0.0147,  0.1289, -0.1050,  0.1187, -0.1272, -0.0166,  0.0433,\n",
      "        -0.0796, -0.0061, -0.0179,  0.0307, -0.0322,  0.0744, -0.0705, -0.1317,\n",
      "        -0.1027, -0.0749,  0.1188,  0.0254, -0.1341,  0.0806,  0.1038, -0.0994,\n",
      "        -0.0943, -0.0115,  0.1321,  0.0787,  0.0435,  0.0976,  0.1137,  0.0996,\n",
      "        -0.0265, -0.0420,  0.1295, -0.1234, -0.0272,  0.0897,  0.1195,  0.0391,\n",
      "        -0.0776,  0.0182, -0.1307,  0.1371, -0.0437, -0.0673, -0.0823,  0.1001,\n",
      "         0.0933, -0.0447, -0.0579, -0.1117,  0.0504, -0.0172, -0.0228, -0.1413,\n",
      "         0.0856,  0.0888, -0.0564, -0.0430, -0.1301, -0.0439, -0.0019, -0.0811,\n",
      "        -0.0110,  0.0583, -0.0249, -0.1382,  0.1325, -0.0119, -0.0334,  0.0882,\n",
      "         0.1002, -0.0821,  0.0559, -0.1149,  0.0916,  0.0872, -0.1332,  0.0302,\n",
      "         0.1074, -0.1273, -0.1339, -0.0278, -0.0097,  0.0221, -0.0827,  0.1145,\n",
      "        -0.0156,  0.1083, -0.1021,  0.0274, -0.1049,  0.1034,  0.1408, -0.0888,\n",
      "         0.1148,  0.0091, -0.1138,  0.1368, -0.0218,  0.1123,  0.0153,  0.1069,\n",
      "         0.0202, -0.0689, -0.0818, -0.1062,  0.0950, -0.1386, -0.1373,  0.0169,\n",
      "         0.0335, -0.0622, -0.1188, -0.1002, -0.1058,  0.0178, -0.0100, -0.1349,\n",
      "         0.0447,  0.0054,  0.0144, -0.0015,  0.1046,  0.0687,  0.1207, -0.0133,\n",
      "        -0.0734, -0.0858, -0.0935,  0.0678, -0.0101, -0.0011, -0.0013, -0.0287,\n",
      "         0.1356,  0.0411,  0.0517,  0.1093,  0.0369, -0.1363,  0.1186,  0.0137,\n",
      "         0.0465, -0.0239, -0.0319,  0.0090,  0.0971, -0.1003, -0.0281,  0.1195,\n",
      "        -0.1028,  0.1037, -0.0591,  0.0849, -0.0124, -0.0648,  0.1003,  0.0793,\n",
      "         0.0968, -0.1178, -0.0832,  0.0672,  0.0700, -0.0234, -0.1020, -0.0738,\n",
      "         0.0533,  0.0582,  0.1102, -0.0204, -0.0817, -0.0570, -0.1250,  0.1048],\n",
      "       device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([200])\n",
      "-----\n",
      "linear.weight\n",
      "Data:\n",
      "tensor([[ 0.1359,  0.0777,  0.1259,  0.1196,  0.0903,  0.0060,  0.0817,  0.0794,\n",
      "          0.0833, -0.1229, -0.0166,  0.1124, -0.0705,  0.1071,  0.0738, -0.0623,\n",
      "         -0.1366,  0.0336, -0.0927,  0.1273,  0.0463,  0.0073,  0.1349, -0.0599,\n",
      "          0.1165,  0.0774,  0.0987, -0.0607, -0.0596, -0.0170,  0.0687,  0.0061,\n",
      "          0.1375, -0.0627,  0.1263,  0.0340,  0.0506,  0.0119,  0.0634, -0.0460,\n",
      "          0.1344, -0.0531,  0.0705, -0.1146, -0.0335, -0.0921,  0.0057,  0.1096,\n",
      "         -0.0955, -0.0992],\n",
      "        [ 0.1098,  0.0206, -0.0116, -0.0229,  0.1024, -0.0570, -0.1259, -0.0176,\n",
      "          0.0624, -0.1192,  0.0450,  0.0635,  0.0300, -0.0765, -0.0038,  0.0884,\n",
      "         -0.1398,  0.0456, -0.0868, -0.0743, -0.1226,  0.0816, -0.1267, -0.0753,\n",
      "          0.0224,  0.1297, -0.1203,  0.0622, -0.1070, -0.0285,  0.0137,  0.0197,\n",
      "         -0.0961,  0.0118, -0.0471, -0.0267,  0.0357, -0.1101,  0.0212,  0.0321,\n",
      "          0.1312, -0.0512,  0.0844,  0.1108,  0.1078, -0.0069, -0.0398,  0.0087,\n",
      "          0.0277,  0.0322]], device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([2, 50])\n",
      "-----\n",
      "linear.bias\n",
      "Data:\n",
      "tensor([ 0.0110, -0.0324], device='cuda:0')\n",
      "Grad:\n",
      "None\n",
      "Shape: torch.Size([2])\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\"-----\")\n",
    "for name, param in Lstm.named_parameters():\n",
    "  if param.requires_grad: \n",
    "    print(name)\n",
    "    print(\"Data:\")\n",
    "    print(param.data)\n",
    "    print(\"Grad:\")\n",
    "    print(param.grad)\n",
    "    print(f\"Shape: {param.data.shape}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate gradients in parameters\n",
    "output_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "lstm.weight_ih_l0\n",
      "Data:\n",
      "tensor([[-0.1239,  0.1066, -0.0891,  ..., -0.0025,  0.0033, -0.1201],\n",
      "        [-0.0176,  0.0893, -0.0530,  ...,  0.1127, -0.1001,  0.1381],\n",
      "        [-0.0037, -0.0664, -0.0285,  ..., -0.0991,  0.1128,  0.1191],\n",
      "        ...,\n",
      "        [ 0.0917, -0.1298, -0.0994,  ..., -0.1303, -0.0218, -0.0057],\n",
      "        [ 0.1219,  0.0866, -0.0026,  ..., -0.1135, -0.0781, -0.1379],\n",
      "        [-0.0120,  0.1171,  0.0788,  ...,  0.0240, -0.0921,  0.0717]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[-1.1116e-04,  6.3557e-04,  4.2248e-05,  ...,  6.5106e-04,\n",
      "          4.7354e-05,  1.4595e-04],\n",
      "        [ 1.9653e-04, -5.4470e-04,  1.1752e-03,  ...,  3.9320e-04,\n",
      "         -1.0222e-03, -3.5215e-04],\n",
      "        [ 1.4098e-03, -3.6519e-03,  3.9341e-03,  ..., -3.2020e-04,\n",
      "         -3.5482e-03, -1.2275e-03],\n",
      "        ...,\n",
      "        [-5.5501e-04,  2.1539e-03, -3.4086e-03,  ..., -1.2783e-03,\n",
      "          3.1127e-03,  1.4112e-03],\n",
      "        [-1.6210e-04,  6.7285e-04, -5.7584e-04,  ...,  3.9204e-04,\n",
      "          5.4450e-04,  2.5687e-04],\n",
      "        [-1.3493e-03,  5.0441e-03, -6.5634e-03,  ..., -3.7191e-04,\n",
      "          5.9779e-03,  2.6127e-03]], device='cuda:0')\n",
      "Grad Shape: torch.Size([200, 200])\n",
      "---------\n",
      "lstm.weight_hh_l0\n",
      "Data:\n",
      "tensor([[-0.0472, -0.0489, -0.0697,  ...,  0.0132, -0.0693, -0.0331],\n",
      "        [ 0.0785, -0.0701,  0.0671,  ...,  0.0086,  0.1316,  0.0077],\n",
      "        [ 0.0520,  0.0476,  0.0237,  ..., -0.0411,  0.0880, -0.0962],\n",
      "        ...,\n",
      "        [ 0.0227,  0.0427, -0.0436,  ...,  0.0777,  0.0803, -0.1196],\n",
      "        [-0.0443, -0.0592, -0.1309,  ..., -0.1297, -0.0988,  0.0421],\n",
      "        [ 0.1303, -0.0453, -0.0733,  ..., -0.0631,  0.0065, -0.0610]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 50])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[ 4.6294e-05, -1.6310e-05, -1.8744e-05,  ..., -2.4998e-05,\n",
      "         -1.4356e-05,  1.8713e-04],\n",
      "        [ 1.4181e-04,  5.1702e-05, -1.8473e-04,  ..., -5.3770e-05,\n",
      "          1.3756e-04,  3.2266e-04],\n",
      "        [ 1.5798e-04,  2.5016e-05, -4.8622e-04,  ..., -6.7822e-05,\n",
      "          6.3623e-04,  7.8070e-05],\n",
      "        ...,\n",
      "        [-4.5648e-04, -7.4034e-05,  5.2118e-04,  ...,  1.7475e-04,\n",
      "         -4.1546e-04, -8.5483e-04],\n",
      "        [-5.1870e-05, -1.9428e-05,  1.8784e-05,  ...,  5.7879e-05,\n",
      "         -3.7609e-05, -1.2293e-05],\n",
      "        [-7.4743e-04, -1.9628e-04,  8.1057e-04,  ...,  3.8571e-04,\n",
      "         -7.3055e-04, -1.2008e-03]], device='cuda:0')\n",
      "Grad Shape: torch.Size([200, 50])\n",
      "---------\n",
      "lstm.bias_ih_l0\n",
      "Data:\n",
      "tensor([-0.0294, -0.0940,  0.1060, -0.0234,  0.1103, -0.1158, -0.0416, -0.0622,\n",
      "         0.0033, -0.1046,  0.0373,  0.1059, -0.0853,  0.0003,  0.0606, -0.0607,\n",
      "         0.0925, -0.0367,  0.0331, -0.1149,  0.1035, -0.1304,  0.1339,  0.1269,\n",
      "        -0.0623,  0.0739, -0.1275, -0.1375, -0.0471, -0.0256,  0.1066,  0.1386,\n",
      "         0.0527,  0.0820, -0.1093,  0.0466, -0.0591, -0.0197,  0.0823, -0.0866,\n",
      "         0.0842, -0.0940, -0.0354, -0.0975,  0.0010,  0.0811, -0.1248,  0.0333,\n",
      "        -0.0643, -0.0891,  0.1383,  0.0129,  0.0358,  0.0991, -0.0049, -0.0321,\n",
      "        -0.1380, -0.1035, -0.0542,  0.0569,  0.0089,  0.0686,  0.0203,  0.1321,\n",
      "         0.0178, -0.0867,  0.1106,  0.0281, -0.0766, -0.0328,  0.0159,  0.0589,\n",
      "         0.0536,  0.1247, -0.0854, -0.0204,  0.1116, -0.0345, -0.1359, -0.0031,\n",
      "        -0.0795,  0.0226, -0.0231, -0.0565, -0.0112,  0.0553,  0.1030, -0.1311,\n",
      "         0.0492, -0.0068, -0.0408, -0.0287,  0.0932, -0.0413,  0.0191,  0.0532,\n",
      "        -0.0780, -0.0158, -0.1067, -0.0765,  0.0339, -0.0571, -0.1270,  0.0632,\n",
      "         0.1003,  0.1183,  0.0385, -0.0203, -0.0029,  0.0925,  0.1378, -0.1349,\n",
      "        -0.0507, -0.0409,  0.1295, -0.1033,  0.0957,  0.0228,  0.1082, -0.0266,\n",
      "         0.0411,  0.0304, -0.0221,  0.0010, -0.1271, -0.1288, -0.1251, -0.0446,\n",
      "         0.0744, -0.0932, -0.0388,  0.0609, -0.0800,  0.0406, -0.0290, -0.0294,\n",
      "         0.0482, -0.0195, -0.0657, -0.0602,  0.0697, -0.0532,  0.0118,  0.1230,\n",
      "         0.1037,  0.0690,  0.0346, -0.0268,  0.1037,  0.1167, -0.0002, -0.1134,\n",
      "         0.0284, -0.0610,  0.0363,  0.1058,  0.0290,  0.1334, -0.0105,  0.0660,\n",
      "        -0.0360,  0.0050, -0.0635,  0.1409,  0.1384, -0.0063,  0.0693,  0.1079,\n",
      "        -0.0322,  0.0432, -0.0522,  0.0873, -0.0849, -0.1002,  0.0676,  0.0062,\n",
      "        -0.0694, -0.0770,  0.0749, -0.1065, -0.1118,  0.0674,  0.0933, -0.0517,\n",
      "        -0.0493,  0.1036, -0.1281,  0.0980, -0.0157, -0.0178,  0.0854,  0.0811,\n",
      "         0.1085, -0.0188,  0.1381,  0.0247, -0.0386,  0.1098, -0.0400,  0.1335],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 5.2553e-04,  1.5043e-03,  2.7679e-03,  3.1194e-05,  9.1023e-05,\n",
      "        -6.7650e-04, -1.0477e-03,  4.8301e-03,  3.2252e-04, -2.8080e-03,\n",
      "        -5.5830e-04, -1.2454e-03,  4.8457e-03,  8.0413e-03,  1.0575e-03,\n",
      "         2.1156e-03, -2.2107e-04, -4.0056e-04, -9.2549e-04,  8.8532e-03,\n",
      "         2.3855e-03, -5.6027e-03, -1.2907e-02,  1.9248e-03,  5.2283e-04,\n",
      "         1.1116e-04,  3.7227e-03, -8.7110e-04,  3.4226e-04,  2.1713e-03,\n",
      "         8.0000e-04,  7.6739e-04, -2.8608e-03,  5.4492e-04, -3.5322e-03,\n",
      "         1.1541e-03,  8.5603e-04,  4.3504e-03, -1.0054e-03,  9.1586e-04,\n",
      "         9.5578e-05,  1.7968e-04, -2.4274e-04, -2.5106e-03,  8.8096e-05,\n",
      "        -4.5238e-03,  8.4124e-04, -4.5319e-03, -1.2561e-03, -6.8183e-03,\n",
      "         1.1065e-03,  2.5460e-04, -3.0989e-03, -2.7600e-03,  5.0461e-05,\n",
      "        -2.3353e-03,  2.1921e-04,  1.1654e-03, -2.2648e-04, -1.9377e-03,\n",
      "         1.0263e-04,  1.7586e-03,  2.2863e-03,  1.2167e-02,  4.0710e-03,\n",
      "        -1.0305e-03, -1.9830e-03, -3.1069e-04, -6.8502e-04,  6.6182e-03,\n",
      "         9.5978e-03, -4.1612e-03, -1.6145e-02,  4.7143e-04,  2.9981e-03,\n",
      "        -1.2357e-03, -3.5606e-03, -1.1067e-03, -8.2526e-06,  1.5474e-03,\n",
      "        -4.3048e-04,  7.5368e-04, -6.3355e-03,  3.5655e-03, -7.5063e-03,\n",
      "        -1.0455e-03,  4.8137e-04,  1.9009e-03, -1.8923e-03,  1.1576e-03,\n",
      "        -2.5539e-05,  1.8215e-05, -1.6207e-05,  1.0245e-03,  1.7768e-03,\n",
      "        -8.0035e-03,  2.8958e-03, -1.1394e-03, -2.3440e-03, -5.7276e-03,\n",
      "         5.0997e-03,  2.8318e-03,  4.4259e-02,  3.1716e-02, -9.5023e-05,\n",
      "         1.9959e-02,  2.4057e-02,  6.1458e-03, -5.9378e-03, -5.8946e-03,\n",
      "        -1.2802e-02,  4.3581e-03, -1.6272e-02,  4.7648e-02,  2.5276e-02,\n",
      "        -2.6968e-02, -2.2585e-02, -5.3607e-03, -3.6686e-03,  2.1231e-02,\n",
      "         4.3615e-02, -2.0946e-02,  5.1026e-02,  8.0541e-03,  2.0544e-02,\n",
      "        -1.1784e-02,  4.4807e-02, -8.2492e-03, -3.4799e-03, -3.9835e-03,\n",
      "        -1.4841e-03, -3.4227e-03,  6.4428e-02, -1.6103e-02,  2.9377e-02,\n",
      "         5.5658e-03,  2.6293e-03,  2.1672e-02,  1.1749e-02, -1.3013e-02,\n",
      "         5.9687e-04, -1.3196e-03,  5.4314e-04, -3.6943e-02, -5.2267e-02,\n",
      "        -2.5874e-02,  2.5143e-02,  2.3972e-02, -1.6481e-02, -1.6000e-02,\n",
      "         4.9371e-04,  1.3485e-03,  1.0846e-03, -7.0517e-05,  9.8905e-05,\n",
      "        -8.9233e-04, -7.7487e-04,  4.4093e-03,  1.0441e-03, -2.0853e-03,\n",
      "         1.0081e-03, -1.3750e-03,  5.4642e-03,  7.5857e-03,  1.7759e-03,\n",
      "         1.4322e-03, -9.3510e-04, -4.3643e-04, -1.3711e-03,  1.5802e-02,\n",
      "         5.5885e-03, -4.2066e-03, -1.8157e-02,  1.8646e-03,  7.1484e-04,\n",
      "         3.0559e-04,  3.8056e-03, -6.4736e-04,  1.7739e-03,  3.5112e-03,\n",
      "         4.8880e-04,  4.4535e-04, -1.7299e-03,  3.1382e-04, -1.7130e-03,\n",
      "         1.8554e-03,  8.1627e-04,  5.9417e-03, -8.9499e-04,  1.3370e-03,\n",
      "         1.3319e-04,  1.6180e-04, -2.4941e-04, -1.5018e-03, -5.5855e-04,\n",
      "        -5.4203e-03,  1.4314e-03, -4.4626e-03, -5.0691e-04, -7.4890e-03],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([200])\n",
      "---------\n",
      "lstm.bias_hh_l0\n",
      "Data:\n",
      "tensor([ 0.0390, -0.0370,  0.1039, -0.0063,  0.1345, -0.0566, -0.1188,  0.0396,\n",
      "         0.0519,  0.0536,  0.0055, -0.1372,  0.0811, -0.0459, -0.0884, -0.0526,\n",
      "         0.0588, -0.1027,  0.0750,  0.0034, -0.0629, -0.0022, -0.0550,  0.0467,\n",
      "         0.0907, -0.0147,  0.1289, -0.1050,  0.1187, -0.1272, -0.0166,  0.0433,\n",
      "        -0.0796, -0.0061, -0.0179,  0.0307, -0.0322,  0.0744, -0.0705, -0.1317,\n",
      "        -0.1027, -0.0749,  0.1188,  0.0254, -0.1341,  0.0806,  0.1038, -0.0994,\n",
      "        -0.0943, -0.0115,  0.1321,  0.0787,  0.0435,  0.0976,  0.1137,  0.0996,\n",
      "        -0.0265, -0.0420,  0.1295, -0.1234, -0.0272,  0.0897,  0.1195,  0.0391,\n",
      "        -0.0776,  0.0182, -0.1307,  0.1371, -0.0437, -0.0673, -0.0823,  0.1001,\n",
      "         0.0933, -0.0447, -0.0579, -0.1117,  0.0504, -0.0172, -0.0228, -0.1413,\n",
      "         0.0856,  0.0888, -0.0564, -0.0430, -0.1301, -0.0439, -0.0019, -0.0811,\n",
      "        -0.0110,  0.0583, -0.0249, -0.1382,  0.1325, -0.0119, -0.0334,  0.0882,\n",
      "         0.1002, -0.0821,  0.0559, -0.1149,  0.0916,  0.0872, -0.1332,  0.0302,\n",
      "         0.1074, -0.1273, -0.1339, -0.0278, -0.0097,  0.0221, -0.0827,  0.1145,\n",
      "        -0.0156,  0.1083, -0.1021,  0.0274, -0.1049,  0.1034,  0.1408, -0.0888,\n",
      "         0.1148,  0.0091, -0.1138,  0.1368, -0.0218,  0.1123,  0.0153,  0.1069,\n",
      "         0.0202, -0.0689, -0.0818, -0.1062,  0.0950, -0.1386, -0.1373,  0.0169,\n",
      "         0.0335, -0.0622, -0.1188, -0.1002, -0.1058,  0.0178, -0.0100, -0.1349,\n",
      "         0.0447,  0.0054,  0.0144, -0.0015,  0.1046,  0.0687,  0.1207, -0.0133,\n",
      "        -0.0734, -0.0858, -0.0935,  0.0678, -0.0101, -0.0011, -0.0013, -0.0287,\n",
      "         0.1356,  0.0411,  0.0517,  0.1093,  0.0369, -0.1363,  0.1186,  0.0137,\n",
      "         0.0465, -0.0239, -0.0319,  0.0090,  0.0971, -0.1003, -0.0281,  0.1195,\n",
      "        -0.1028,  0.1037, -0.0591,  0.0849, -0.0124, -0.0648,  0.1003,  0.0793,\n",
      "         0.0968, -0.1178, -0.0832,  0.0672,  0.0700, -0.0234, -0.1020, -0.0738,\n",
      "         0.0533,  0.0582,  0.1102, -0.0204, -0.0817, -0.0570, -0.1250,  0.1048],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 5.2553e-04,  1.5043e-03,  2.7679e-03,  3.1194e-05,  9.1023e-05,\n",
      "        -6.7650e-04, -1.0477e-03,  4.8301e-03,  3.2252e-04, -2.8080e-03,\n",
      "        -5.5830e-04, -1.2454e-03,  4.8457e-03,  8.0413e-03,  1.0575e-03,\n",
      "         2.1156e-03, -2.2107e-04, -4.0056e-04, -9.2549e-04,  8.8532e-03,\n",
      "         2.3855e-03, -5.6027e-03, -1.2907e-02,  1.9248e-03,  5.2283e-04,\n",
      "         1.1116e-04,  3.7227e-03, -8.7110e-04,  3.4226e-04,  2.1713e-03,\n",
      "         8.0000e-04,  7.6739e-04, -2.8608e-03,  5.4492e-04, -3.5322e-03,\n",
      "         1.1541e-03,  8.5603e-04,  4.3504e-03, -1.0054e-03,  9.1586e-04,\n",
      "         9.5578e-05,  1.7968e-04, -2.4274e-04, -2.5106e-03,  8.8096e-05,\n",
      "        -4.5238e-03,  8.4124e-04, -4.5319e-03, -1.2561e-03, -6.8183e-03,\n",
      "         1.1065e-03,  2.5460e-04, -3.0989e-03, -2.7600e-03,  5.0461e-05,\n",
      "        -2.3353e-03,  2.1921e-04,  1.1654e-03, -2.2648e-04, -1.9377e-03,\n",
      "         1.0263e-04,  1.7586e-03,  2.2863e-03,  1.2167e-02,  4.0710e-03,\n",
      "        -1.0305e-03, -1.9830e-03, -3.1069e-04, -6.8502e-04,  6.6182e-03,\n",
      "         9.5978e-03, -4.1612e-03, -1.6145e-02,  4.7143e-04,  2.9981e-03,\n",
      "        -1.2357e-03, -3.5606e-03, -1.1067e-03, -8.2526e-06,  1.5474e-03,\n",
      "        -4.3048e-04,  7.5368e-04, -6.3355e-03,  3.5655e-03, -7.5063e-03,\n",
      "        -1.0455e-03,  4.8137e-04,  1.9009e-03, -1.8923e-03,  1.1576e-03,\n",
      "        -2.5539e-05,  1.8215e-05, -1.6207e-05,  1.0245e-03,  1.7768e-03,\n",
      "        -8.0035e-03,  2.8958e-03, -1.1394e-03, -2.3440e-03, -5.7276e-03,\n",
      "         5.0997e-03,  2.8318e-03,  4.4259e-02,  3.1716e-02, -9.5023e-05,\n",
      "         1.9959e-02,  2.4057e-02,  6.1458e-03, -5.9378e-03, -5.8946e-03,\n",
      "        -1.2802e-02,  4.3581e-03, -1.6272e-02,  4.7648e-02,  2.5276e-02,\n",
      "        -2.6968e-02, -2.2585e-02, -5.3607e-03, -3.6686e-03,  2.1231e-02,\n",
      "         4.3615e-02, -2.0946e-02,  5.1026e-02,  8.0541e-03,  2.0544e-02,\n",
      "        -1.1784e-02,  4.4807e-02, -8.2492e-03, -3.4799e-03, -3.9835e-03,\n",
      "        -1.4841e-03, -3.4227e-03,  6.4428e-02, -1.6103e-02,  2.9377e-02,\n",
      "         5.5658e-03,  2.6293e-03,  2.1672e-02,  1.1749e-02, -1.3013e-02,\n",
      "         5.9687e-04, -1.3196e-03,  5.4314e-04, -3.6943e-02, -5.2267e-02,\n",
      "        -2.5874e-02,  2.5143e-02,  2.3972e-02, -1.6481e-02, -1.6000e-02,\n",
      "         4.9371e-04,  1.3485e-03,  1.0846e-03, -7.0517e-05,  9.8905e-05,\n",
      "        -8.9233e-04, -7.7487e-04,  4.4093e-03,  1.0441e-03, -2.0853e-03,\n",
      "         1.0081e-03, -1.3750e-03,  5.4642e-03,  7.5857e-03,  1.7759e-03,\n",
      "         1.4322e-03, -9.3510e-04, -4.3643e-04, -1.3711e-03,  1.5802e-02,\n",
      "         5.5885e-03, -4.2066e-03, -1.8157e-02,  1.8646e-03,  7.1484e-04,\n",
      "         3.0559e-04,  3.8056e-03, -6.4736e-04,  1.7739e-03,  3.5112e-03,\n",
      "         4.8880e-04,  4.4535e-04, -1.7299e-03,  3.1382e-04, -1.7130e-03,\n",
      "         1.8554e-03,  8.1627e-04,  5.9417e-03, -8.9499e-04,  1.3370e-03,\n",
      "         1.3319e-04,  1.6180e-04, -2.4941e-04, -1.5018e-03, -5.5855e-04,\n",
      "        -5.4203e-03,  1.4314e-03, -4.4626e-03, -5.0691e-04, -7.4890e-03],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([200])\n",
      "---------\n",
      "linear.weight\n",
      "Data:\n",
      "tensor([[ 0.1359,  0.0777,  0.1259,  0.1196,  0.0903,  0.0060,  0.0817,  0.0794,\n",
      "          0.0833, -0.1229, -0.0166,  0.1124, -0.0705,  0.1071,  0.0738, -0.0623,\n",
      "         -0.1366,  0.0336, -0.0927,  0.1273,  0.0463,  0.0073,  0.1349, -0.0599,\n",
      "          0.1165,  0.0774,  0.0987, -0.0607, -0.0596, -0.0170,  0.0687,  0.0061,\n",
      "          0.1375, -0.0627,  0.1263,  0.0340,  0.0506,  0.0119,  0.0634, -0.0460,\n",
      "          0.1344, -0.0531,  0.0705, -0.1146, -0.0335, -0.0921,  0.0057,  0.1096,\n",
      "         -0.0955, -0.0992],\n",
      "        [ 0.1098,  0.0206, -0.0116, -0.0229,  0.1024, -0.0570, -0.1259, -0.0176,\n",
      "          0.0624, -0.1192,  0.0450,  0.0635,  0.0300, -0.0765, -0.0038,  0.0884,\n",
      "         -0.1398,  0.0456, -0.0868, -0.0743, -0.1226,  0.0816, -0.1267, -0.0753,\n",
      "          0.0224,  0.1297, -0.1203,  0.0622, -0.1070, -0.0285,  0.0137,  0.0197,\n",
      "         -0.0961,  0.0118, -0.0471, -0.0267,  0.0357, -0.1101,  0.0212,  0.0321,\n",
      "          0.1312, -0.0512,  0.0844,  0.1108,  0.1078, -0.0069, -0.0398,  0.0087,\n",
      "          0.0277,  0.0322]], device='cuda:0')\n",
      "Data Shape: torch.Size([2, 50])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[ 2.6859e-02,  4.5946e-02,  1.7331e-02, -6.7305e-03,  1.2219e-01,\n",
      "         -1.8179e-02, -6.6938e-03,  9.3123e-02, -1.0741e-01,  2.1341e-01,\n",
      "         -3.7175e-02,  1.2956e-03, -9.7011e-02,  9.2185e-02,  1.9496e-02,\n",
      "         -1.5485e-02,  2.9129e-02,  1.0468e-01,  6.5967e-02,  1.4680e-01,\n",
      "          4.9655e-02,  1.6410e-01, -8.7873e-02,  1.0479e-01, -1.2734e-04,\n",
      "          9.4380e-03,  3.0487e-02,  9.6085e-03,  7.6275e-02, -3.1409e-02,\n",
      "         -1.3919e-02, -9.9593e-02, -8.5133e-03, -7.8679e-03, -4.9799e-02,\n",
      "          5.1921e-02,  7.5084e-02,  1.1609e-01, -3.7188e-02, -2.5163e-02,\n",
      "          2.4003e-02, -3.2116e-03,  2.5594e-03,  1.6170e-02,  1.2347e-02,\n",
      "          9.6118e-02,  6.3274e-02, -9.8181e-02,  1.3037e-02,  2.1480e-01],\n",
      "        [-2.6859e-02, -4.5946e-02, -1.7331e-02,  6.7305e-03, -1.2219e-01,\n",
      "          1.8179e-02,  6.6938e-03, -9.3123e-02,  1.0741e-01, -2.1341e-01,\n",
      "          3.7175e-02, -1.2956e-03,  9.7011e-02, -9.2185e-02, -1.9496e-02,\n",
      "          1.5485e-02, -2.9129e-02, -1.0468e-01, -6.5967e-02, -1.4680e-01,\n",
      "         -4.9655e-02, -1.6410e-01,  8.7873e-02, -1.0479e-01,  1.2734e-04,\n",
      "         -9.4380e-03, -3.0487e-02, -9.6085e-03, -7.6275e-02,  3.1409e-02,\n",
      "          1.3919e-02,  9.9593e-02,  8.5133e-03,  7.8679e-03,  4.9799e-02,\n",
      "         -5.1921e-02, -7.5084e-02, -1.1609e-01,  3.7188e-02,  2.5163e-02,\n",
      "         -2.4003e-02,  3.2116e-03, -2.5594e-03, -1.6170e-02, -1.2347e-02,\n",
      "         -9.6118e-02, -6.3274e-02,  9.8181e-02, -1.3037e-02, -2.1480e-01]],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([2, 50])\n",
      "---------\n",
      "linear.bias\n",
      "Data:\n",
      "tensor([ 0.0110, -0.0324], device='cuda:0')\n",
      "Data Shape: torch.Size([2])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 0.5156, -0.5156], device='cuda:0')\n",
      "Grad Shape: torch.Size([2])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Note that each parameter has a grad value\n",
    "\n",
    "print(\"---------\")\n",
    "for name, param in Lstm.named_parameters():\n",
    "  if param.requires_grad: \n",
    "    print(name)\n",
    "    print(\"Data:\")\n",
    "    print(param.data)\n",
    "    print(f\"Data Shape: {param.data.shape}\")\n",
    "    print(\"-----\")\n",
    "    print(\"Grad:\")\n",
    "    print(param.grad)\n",
    "    print(f\"Grad Shape: {param.grad.shape}\")\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "lstm.weight_ih_l0\n",
      "Data:\n",
      "tensor([[-0.1139,  0.0966, -0.0991,  ..., -0.0125, -0.0067, -0.1301],\n",
      "        [-0.0276,  0.0993, -0.0630,  ...,  0.1027, -0.0901,  0.1481],\n",
      "        [-0.0137, -0.0564, -0.0385,  ..., -0.0891,  0.1228,  0.1291],\n",
      "        ...,\n",
      "        [ 0.1017, -0.1398, -0.0894,  ..., -0.1203, -0.0318, -0.0157],\n",
      "        [ 0.1319,  0.0766,  0.0074,  ..., -0.1235, -0.0881, -0.1479],\n",
      "        [-0.0020,  0.1071,  0.0888,  ...,  0.0340, -0.1021,  0.0617]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[-1.1116e-04,  6.3557e-04,  4.2248e-05,  ...,  6.5106e-04,\n",
      "          4.7354e-05,  1.4595e-04],\n",
      "        [ 1.9653e-04, -5.4470e-04,  1.1752e-03,  ...,  3.9320e-04,\n",
      "         -1.0222e-03, -3.5215e-04],\n",
      "        [ 1.4098e-03, -3.6519e-03,  3.9341e-03,  ..., -3.2020e-04,\n",
      "         -3.5482e-03, -1.2275e-03],\n",
      "        ...,\n",
      "        [-5.5501e-04,  2.1539e-03, -3.4086e-03,  ..., -1.2783e-03,\n",
      "          3.1127e-03,  1.4112e-03],\n",
      "        [-1.6210e-04,  6.7285e-04, -5.7584e-04,  ...,  3.9204e-04,\n",
      "          5.4450e-04,  2.5687e-04],\n",
      "        [-1.3493e-03,  5.0441e-03, -6.5634e-03,  ..., -3.7191e-04,\n",
      "          5.9779e-03,  2.6127e-03]], device='cuda:0')\n",
      "Grad Shape: torch.Size([200, 200])\n",
      "---------\n",
      "lstm.weight_hh_l0\n",
      "Data:\n",
      "tensor([[-0.0572, -0.0389, -0.0597,  ...,  0.0232, -0.0593, -0.0431],\n",
      "        [ 0.0685, -0.0801,  0.0771,  ...,  0.0186,  0.1216, -0.0023],\n",
      "        [ 0.0420,  0.0376,  0.0337,  ..., -0.0311,  0.0780, -0.1062],\n",
      "        ...,\n",
      "        [ 0.0327,  0.0527, -0.0536,  ...,  0.0677,  0.0903, -0.1096],\n",
      "        [-0.0343, -0.0493, -0.1409,  ..., -0.1397, -0.0888,  0.0521],\n",
      "        [ 0.1403, -0.0353, -0.0833,  ..., -0.0731,  0.0165, -0.0510]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 50])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[ 4.6294e-05, -1.6310e-05, -1.8744e-05,  ..., -2.4998e-05,\n",
      "         -1.4356e-05,  1.8713e-04],\n",
      "        [ 1.4181e-04,  5.1702e-05, -1.8473e-04,  ..., -5.3770e-05,\n",
      "          1.3756e-04,  3.2266e-04],\n",
      "        [ 1.5798e-04,  2.5016e-05, -4.8622e-04,  ..., -6.7822e-05,\n",
      "          6.3623e-04,  7.8070e-05],\n",
      "        ...,\n",
      "        [-4.5648e-04, -7.4034e-05,  5.2118e-04,  ...,  1.7475e-04,\n",
      "         -4.1546e-04, -8.5483e-04],\n",
      "        [-5.1870e-05, -1.9428e-05,  1.8784e-05,  ...,  5.7879e-05,\n",
      "         -3.7609e-05, -1.2293e-05],\n",
      "        [-7.4743e-04, -1.9628e-04,  8.1057e-04,  ...,  3.8571e-04,\n",
      "         -7.3055e-04, -1.2008e-03]], device='cuda:0')\n",
      "Grad Shape: torch.Size([200, 50])\n",
      "---------\n",
      "lstm.bias_ih_l0\n",
      "Data:\n",
      "tensor([-0.0394, -0.1040,  0.0960, -0.0333,  0.1003, -0.1058, -0.0316, -0.0722,\n",
      "        -0.0067, -0.0946,  0.0473,  0.1159, -0.0953, -0.0097,  0.0506, -0.0707,\n",
      "         0.1025, -0.0267,  0.0431, -0.1249,  0.0935, -0.1204,  0.1439,  0.1169,\n",
      "        -0.0723,  0.0639, -0.1375, -0.1275, -0.0571, -0.0356,  0.0966,  0.1286,\n",
      "         0.0627,  0.0720, -0.0993,  0.0366, -0.0691, -0.0297,  0.0923, -0.0966,\n",
      "         0.0742, -0.1040, -0.0255, -0.0875, -0.0090,  0.0911, -0.1348,  0.0433,\n",
      "        -0.0543, -0.0791,  0.1283,  0.0029,  0.0458,  0.1091, -0.0149, -0.0221,\n",
      "        -0.1480, -0.1135, -0.0442,  0.0669, -0.0011,  0.0586,  0.0103,  0.1221,\n",
      "         0.0078, -0.0767,  0.1206,  0.0381, -0.0666, -0.0428,  0.0059,  0.0689,\n",
      "         0.0636,  0.1147, -0.0954, -0.0104,  0.1216, -0.0245, -0.1259, -0.0131,\n",
      "        -0.0695,  0.0126, -0.0131, -0.0665, -0.0012,  0.0653,  0.0930, -0.1411,\n",
      "         0.0592, -0.0168, -0.0308, -0.0387,  0.1031, -0.0513,  0.0091,  0.0632,\n",
      "        -0.0880, -0.0058, -0.0967, -0.0665,  0.0239, -0.0671, -0.1370,  0.0532,\n",
      "         0.1103,  0.1083,  0.0285, -0.0303,  0.0071,  0.1025,  0.1478, -0.1449,\n",
      "        -0.0407, -0.0509,  0.1195, -0.0933,  0.1057,  0.0328,  0.1182, -0.0366,\n",
      "         0.0311,  0.0404, -0.0321, -0.0090, -0.1371, -0.1188, -0.1351, -0.0346,\n",
      "         0.0844, -0.0832, -0.0288,  0.0709, -0.0900,  0.0506, -0.0390, -0.0394,\n",
      "         0.0382, -0.0295, -0.0757, -0.0502,  0.0597, -0.0432,  0.0018,  0.1330,\n",
      "         0.1137,  0.0790,  0.0246, -0.0368,  0.1137,  0.1267, -0.0102, -0.1234,\n",
      "         0.0184, -0.0510,  0.0263,  0.1158,  0.0390,  0.1234, -0.0205,  0.0760,\n",
      "        -0.0460,  0.0150, -0.0735,  0.1309,  0.1284, -0.0163,  0.0793,  0.1179,\n",
      "        -0.0222,  0.0332, -0.0622,  0.0973, -0.0749, -0.1102,  0.0576, -0.0038,\n",
      "        -0.0794, -0.0670,  0.0649, -0.1165, -0.1218,  0.0574,  0.1033, -0.0617,\n",
      "        -0.0393,  0.0936, -0.1381,  0.0880, -0.0057, -0.0278,  0.0754,  0.0711,\n",
      "         0.1185, -0.0088,  0.1481,  0.0347, -0.0486,  0.1198, -0.0300,  0.1435],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 5.2553e-04,  1.5043e-03,  2.7679e-03,  3.1194e-05,  9.1023e-05,\n",
      "        -6.7650e-04, -1.0477e-03,  4.8301e-03,  3.2252e-04, -2.8080e-03,\n",
      "        -5.5830e-04, -1.2454e-03,  4.8457e-03,  8.0413e-03,  1.0575e-03,\n",
      "         2.1156e-03, -2.2107e-04, -4.0056e-04, -9.2549e-04,  8.8532e-03,\n",
      "         2.3855e-03, -5.6027e-03, -1.2907e-02,  1.9248e-03,  5.2283e-04,\n",
      "         1.1116e-04,  3.7227e-03, -8.7110e-04,  3.4226e-04,  2.1713e-03,\n",
      "         8.0000e-04,  7.6739e-04, -2.8608e-03,  5.4492e-04, -3.5322e-03,\n",
      "         1.1541e-03,  8.5603e-04,  4.3504e-03, -1.0054e-03,  9.1586e-04,\n",
      "         9.5578e-05,  1.7968e-04, -2.4274e-04, -2.5106e-03,  8.8096e-05,\n",
      "        -4.5238e-03,  8.4124e-04, -4.5319e-03, -1.2561e-03, -6.8183e-03,\n",
      "         1.1065e-03,  2.5460e-04, -3.0989e-03, -2.7600e-03,  5.0461e-05,\n",
      "        -2.3353e-03,  2.1921e-04,  1.1654e-03, -2.2648e-04, -1.9377e-03,\n",
      "         1.0263e-04,  1.7586e-03,  2.2863e-03,  1.2167e-02,  4.0710e-03,\n",
      "        -1.0305e-03, -1.9830e-03, -3.1069e-04, -6.8502e-04,  6.6182e-03,\n",
      "         9.5978e-03, -4.1612e-03, -1.6145e-02,  4.7143e-04,  2.9981e-03,\n",
      "        -1.2357e-03, -3.5606e-03, -1.1067e-03, -8.2526e-06,  1.5474e-03,\n",
      "        -4.3048e-04,  7.5368e-04, -6.3355e-03,  3.5655e-03, -7.5063e-03,\n",
      "        -1.0455e-03,  4.8137e-04,  1.9009e-03, -1.8923e-03,  1.1576e-03,\n",
      "        -2.5539e-05,  1.8215e-05, -1.6207e-05,  1.0245e-03,  1.7768e-03,\n",
      "        -8.0035e-03,  2.8958e-03, -1.1394e-03, -2.3440e-03, -5.7276e-03,\n",
      "         5.0997e-03,  2.8318e-03,  4.4259e-02,  3.1716e-02, -9.5023e-05,\n",
      "         1.9959e-02,  2.4057e-02,  6.1458e-03, -5.9378e-03, -5.8946e-03,\n",
      "        -1.2802e-02,  4.3581e-03, -1.6272e-02,  4.7648e-02,  2.5276e-02,\n",
      "        -2.6968e-02, -2.2585e-02, -5.3607e-03, -3.6686e-03,  2.1231e-02,\n",
      "         4.3615e-02, -2.0946e-02,  5.1026e-02,  8.0541e-03,  2.0544e-02,\n",
      "        -1.1784e-02,  4.4807e-02, -8.2492e-03, -3.4799e-03, -3.9835e-03,\n",
      "        -1.4841e-03, -3.4227e-03,  6.4428e-02, -1.6103e-02,  2.9377e-02,\n",
      "         5.5658e-03,  2.6293e-03,  2.1672e-02,  1.1749e-02, -1.3013e-02,\n",
      "         5.9687e-04, -1.3196e-03,  5.4314e-04, -3.6943e-02, -5.2267e-02,\n",
      "        -2.5874e-02,  2.5143e-02,  2.3972e-02, -1.6481e-02, -1.6000e-02,\n",
      "         4.9371e-04,  1.3485e-03,  1.0846e-03, -7.0517e-05,  9.8905e-05,\n",
      "        -8.9233e-04, -7.7487e-04,  4.4093e-03,  1.0441e-03, -2.0853e-03,\n",
      "         1.0081e-03, -1.3750e-03,  5.4642e-03,  7.5857e-03,  1.7759e-03,\n",
      "         1.4322e-03, -9.3510e-04, -4.3643e-04, -1.3711e-03,  1.5802e-02,\n",
      "         5.5885e-03, -4.2066e-03, -1.8157e-02,  1.8646e-03,  7.1484e-04,\n",
      "         3.0559e-04,  3.8056e-03, -6.4736e-04,  1.7739e-03,  3.5112e-03,\n",
      "         4.8880e-04,  4.4535e-04, -1.7299e-03,  3.1382e-04, -1.7130e-03,\n",
      "         1.8554e-03,  8.1627e-04,  5.9417e-03, -8.9499e-04,  1.3370e-03,\n",
      "         1.3319e-04,  1.6180e-04, -2.4941e-04, -1.5018e-03, -5.5855e-04,\n",
      "        -5.4203e-03,  1.4314e-03, -4.4626e-03, -5.0691e-04, -7.4890e-03],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([200])\n",
      "---------\n",
      "lstm.bias_hh_l0\n",
      "Data:\n",
      "tensor([ 2.9005e-02, -4.6989e-02,  9.3896e-02, -1.6264e-02,  1.2450e-01,\n",
      "        -4.6628e-02, -1.0879e-01,  2.9611e-02,  4.1941e-02,  6.3638e-02,\n",
      "         1.5534e-02, -1.2716e-01,  7.1124e-02, -5.5933e-02, -9.8354e-02,\n",
      "        -6.2568e-02,  6.8763e-02, -9.2721e-02,  8.4977e-02, -6.6304e-03,\n",
      "        -7.2937e-02,  7.8271e-03, -4.4975e-02,  3.6747e-02,  8.0695e-02,\n",
      "        -2.4665e-02,  1.1888e-01, -9.4987e-02,  1.0868e-01, -1.3719e-01,\n",
      "        -2.6587e-02,  3.3347e-02, -6.9598e-02, -1.6059e-02, -7.9365e-03,\n",
      "         2.0716e-02, -4.2179e-02,  6.4439e-02, -6.0475e-02, -1.4170e-01,\n",
      "        -1.1269e-01, -8.4905e-02,  1.2879e-01,  3.5355e-02, -1.4409e-01,\n",
      "         9.0573e-02,  9.3763e-02, -8.9416e-02, -8.4344e-02, -1.5023e-03,\n",
      "         1.2213e-01,  6.8678e-02,  5.3542e-02,  1.0756e-01,  1.0368e-01,\n",
      "         1.0964e-01, -3.6529e-02, -5.2022e-02,  1.3954e-01, -1.1335e-01,\n",
      "        -3.7166e-02,  7.9741e-02,  1.0949e-01,  2.9107e-02, -8.7635e-02,\n",
      "         2.8242e-02, -1.2074e-01,  1.4707e-01, -3.3665e-02, -7.7333e-02,\n",
      "        -9.2341e-02,  1.1006e-01,  1.0329e-01, -5.4705e-02, -6.7937e-02,\n",
      "        -1.0169e-01,  6.0409e-02, -7.2282e-03, -1.2862e-02, -1.5133e-01,\n",
      "         9.5591e-02,  7.8847e-02, -4.6372e-02, -5.3011e-02, -1.2008e-01,\n",
      "        -3.3904e-02, -1.1880e-02, -9.1127e-02, -9.5635e-04,  4.8286e-02,\n",
      "        -1.4929e-02, -1.4817e-01,  1.4246e-01, -2.1854e-02, -4.3448e-02,\n",
      "         9.8154e-02,  9.0216e-02, -7.2057e-02,  6.5885e-02, -1.0488e-01,\n",
      "         8.1608e-02,  7.7250e-02, -1.4324e-01,  2.0169e-02,  1.1736e-01,\n",
      "        -1.3730e-01, -1.4388e-01, -3.7778e-02,  3.0462e-04,  3.2093e-02,\n",
      "        -7.2657e-02,  1.0449e-01, -5.6378e-03,  9.8312e-02, -1.1214e-01,\n",
      "         3.7407e-02, -9.4940e-02,  1.1341e-01,  1.5079e-01, -9.8821e-02,\n",
      "         1.0476e-01,  1.9121e-02, -1.2383e-01,  1.2685e-01, -3.1846e-02,\n",
      "         1.2225e-01,  5.2655e-03,  1.1689e-01,  3.0197e-02, -5.8918e-02,\n",
      "        -7.1803e-02, -9.6178e-02,  8.5019e-02, -1.2859e-01, -1.4730e-01,\n",
      "         6.9215e-03,  2.3546e-02, -7.2243e-02, -1.2881e-01, -9.0241e-02,\n",
      "        -1.1584e-01,  2.7826e-02, -2.0006e-02, -1.2493e-01,  5.4747e-02,\n",
      "         1.5379e-02,  4.4242e-03, -1.1476e-02,  1.1465e-01,  7.8717e-02,\n",
      "         1.1075e-01, -2.3290e-02, -8.3388e-02, -7.5815e-02, -1.0355e-01,\n",
      "         7.7781e-02, -1.4459e-04, -1.1131e-02, -1.1251e-02, -1.8680e-02,\n",
      "         1.2557e-01,  5.1071e-02,  4.1735e-02,  9.9322e-02,  2.6857e-02,\n",
      "        -1.4630e-01,  1.2862e-01,  2.3678e-02,  5.6542e-02, -3.3930e-02,\n",
      "        -4.1891e-02,  1.9030e-02,  1.0712e-01, -1.1032e-01, -3.8088e-02,\n",
      "         1.0954e-01, -1.1280e-01,  1.1368e-01, -6.9081e-02,  7.4896e-02,\n",
      "        -2.2417e-02, -7.4771e-02,  1.1032e-01,  6.9327e-02,  1.0679e-01,\n",
      "        -1.2779e-01, -9.3181e-02,  5.7181e-02,  7.9991e-02, -3.3391e-02,\n",
      "        -1.1199e-01, -8.3832e-02,  6.3324e-02,  6.8245e-02,  1.2025e-01,\n",
      "        -1.0427e-02, -9.1697e-02, -4.6995e-02, -1.1498e-01,  1.1476e-01],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 5.2553e-04,  1.5043e-03,  2.7679e-03,  3.1194e-05,  9.1023e-05,\n",
      "        -6.7650e-04, -1.0477e-03,  4.8301e-03,  3.2252e-04, -2.8080e-03,\n",
      "        -5.5830e-04, -1.2454e-03,  4.8457e-03,  8.0413e-03,  1.0575e-03,\n",
      "         2.1156e-03, -2.2107e-04, -4.0056e-04, -9.2549e-04,  8.8532e-03,\n",
      "         2.3855e-03, -5.6027e-03, -1.2907e-02,  1.9248e-03,  5.2283e-04,\n",
      "         1.1116e-04,  3.7227e-03, -8.7110e-04,  3.4226e-04,  2.1713e-03,\n",
      "         8.0000e-04,  7.6739e-04, -2.8608e-03,  5.4492e-04, -3.5322e-03,\n",
      "         1.1541e-03,  8.5603e-04,  4.3504e-03, -1.0054e-03,  9.1586e-04,\n",
      "         9.5578e-05,  1.7968e-04, -2.4274e-04, -2.5106e-03,  8.8096e-05,\n",
      "        -4.5238e-03,  8.4124e-04, -4.5319e-03, -1.2561e-03, -6.8183e-03,\n",
      "         1.1065e-03,  2.5460e-04, -3.0989e-03, -2.7600e-03,  5.0461e-05,\n",
      "        -2.3353e-03,  2.1921e-04,  1.1654e-03, -2.2648e-04, -1.9377e-03,\n",
      "         1.0263e-04,  1.7586e-03,  2.2863e-03,  1.2167e-02,  4.0710e-03,\n",
      "        -1.0305e-03, -1.9830e-03, -3.1069e-04, -6.8502e-04,  6.6182e-03,\n",
      "         9.5978e-03, -4.1612e-03, -1.6145e-02,  4.7143e-04,  2.9981e-03,\n",
      "        -1.2357e-03, -3.5606e-03, -1.1067e-03, -8.2526e-06,  1.5474e-03,\n",
      "        -4.3048e-04,  7.5368e-04, -6.3355e-03,  3.5655e-03, -7.5063e-03,\n",
      "        -1.0455e-03,  4.8137e-04,  1.9009e-03, -1.8923e-03,  1.1576e-03,\n",
      "        -2.5539e-05,  1.8215e-05, -1.6207e-05,  1.0245e-03,  1.7768e-03,\n",
      "        -8.0035e-03,  2.8958e-03, -1.1394e-03, -2.3440e-03, -5.7276e-03,\n",
      "         5.0997e-03,  2.8318e-03,  4.4259e-02,  3.1716e-02, -9.5023e-05,\n",
      "         1.9959e-02,  2.4057e-02,  6.1458e-03, -5.9378e-03, -5.8946e-03,\n",
      "        -1.2802e-02,  4.3581e-03, -1.6272e-02,  4.7648e-02,  2.5276e-02,\n",
      "        -2.6968e-02, -2.2585e-02, -5.3607e-03, -3.6686e-03,  2.1231e-02,\n",
      "         4.3615e-02, -2.0946e-02,  5.1026e-02,  8.0541e-03,  2.0544e-02,\n",
      "        -1.1784e-02,  4.4807e-02, -8.2492e-03, -3.4799e-03, -3.9835e-03,\n",
      "        -1.4841e-03, -3.4227e-03,  6.4428e-02, -1.6103e-02,  2.9377e-02,\n",
      "         5.5658e-03,  2.6293e-03,  2.1672e-02,  1.1749e-02, -1.3013e-02,\n",
      "         5.9687e-04, -1.3196e-03,  5.4314e-04, -3.6943e-02, -5.2267e-02,\n",
      "        -2.5874e-02,  2.5143e-02,  2.3972e-02, -1.6481e-02, -1.6000e-02,\n",
      "         4.9371e-04,  1.3485e-03,  1.0846e-03, -7.0517e-05,  9.8905e-05,\n",
      "        -8.9233e-04, -7.7487e-04,  4.4093e-03,  1.0441e-03, -2.0853e-03,\n",
      "         1.0081e-03, -1.3750e-03,  5.4642e-03,  7.5857e-03,  1.7759e-03,\n",
      "         1.4322e-03, -9.3510e-04, -4.3643e-04, -1.3711e-03,  1.5802e-02,\n",
      "         5.5885e-03, -4.2066e-03, -1.8157e-02,  1.8646e-03,  7.1484e-04,\n",
      "         3.0559e-04,  3.8056e-03, -6.4736e-04,  1.7739e-03,  3.5112e-03,\n",
      "         4.8880e-04,  4.4535e-04, -1.7299e-03,  3.1382e-04, -1.7130e-03,\n",
      "         1.8554e-03,  8.1627e-04,  5.9417e-03, -8.9499e-04,  1.3370e-03,\n",
      "         1.3319e-04,  1.6180e-04, -2.4941e-04, -1.5018e-03, -5.5855e-04,\n",
      "        -5.4203e-03,  1.4314e-03, -4.4626e-03, -5.0691e-04, -7.4890e-03],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([200])\n",
      "---------\n",
      "linear.weight\n",
      "Data:\n",
      "tensor([[ 0.1259,  0.0677,  0.1159,  0.1296,  0.0803,  0.0160,  0.0917,  0.0694,\n",
      "          0.0933, -0.1329, -0.0066,  0.1024, -0.0605,  0.0971,  0.0638, -0.0523,\n",
      "         -0.1466,  0.0236, -0.1027,  0.1173,  0.0363, -0.0027,  0.1449, -0.0699,\n",
      "          0.1265,  0.0674,  0.0887, -0.0707, -0.0696, -0.0070,  0.0787,  0.0161,\n",
      "          0.1475, -0.0527,  0.1363,  0.0240,  0.0406,  0.0019,  0.0734, -0.0360,\n",
      "          0.1244, -0.0431,  0.0605, -0.1246, -0.0435, -0.1021, -0.0043,  0.1196,\n",
      "         -0.1055, -0.1092],\n",
      "        [ 0.1198,  0.0306, -0.0016, -0.0329,  0.1124, -0.0670, -0.1359, -0.0076,\n",
      "          0.0524, -0.1092,  0.0350,  0.0735,  0.0200, -0.0665,  0.0062,  0.0784,\n",
      "         -0.1298,  0.0556, -0.0768, -0.0643, -0.1126,  0.0916, -0.1367, -0.0653,\n",
      "          0.0124,  0.1397, -0.1103,  0.0722, -0.0970, -0.0385,  0.0037,  0.0097,\n",
      "         -0.1061,  0.0018, -0.0571, -0.0167,  0.0457, -0.1001,  0.0112,  0.0221,\n",
      "          0.1412, -0.0612,  0.0944,  0.1208,  0.1178,  0.0031, -0.0298, -0.0013,\n",
      "          0.0377,  0.0422]], device='cuda:0')\n",
      "Data Shape: torch.Size([2, 50])\n",
      "-----\n",
      "Grad:\n",
      "tensor([[ 2.6859e-02,  4.5946e-02,  1.7331e-02, -6.7305e-03,  1.2219e-01,\n",
      "         -1.8179e-02, -6.6938e-03,  9.3123e-02, -1.0741e-01,  2.1341e-01,\n",
      "         -3.7175e-02,  1.2956e-03, -9.7011e-02,  9.2185e-02,  1.9496e-02,\n",
      "         -1.5485e-02,  2.9129e-02,  1.0468e-01,  6.5967e-02,  1.4680e-01,\n",
      "          4.9655e-02,  1.6410e-01, -8.7873e-02,  1.0479e-01, -1.2734e-04,\n",
      "          9.4380e-03,  3.0487e-02,  9.6085e-03,  7.6275e-02, -3.1409e-02,\n",
      "         -1.3919e-02, -9.9593e-02, -8.5133e-03, -7.8679e-03, -4.9799e-02,\n",
      "          5.1921e-02,  7.5084e-02,  1.1609e-01, -3.7188e-02, -2.5163e-02,\n",
      "          2.4003e-02, -3.2116e-03,  2.5594e-03,  1.6170e-02,  1.2347e-02,\n",
      "          9.6118e-02,  6.3274e-02, -9.8181e-02,  1.3037e-02,  2.1480e-01],\n",
      "        [-2.6859e-02, -4.5946e-02, -1.7331e-02,  6.7305e-03, -1.2219e-01,\n",
      "          1.8179e-02,  6.6938e-03, -9.3123e-02,  1.0741e-01, -2.1341e-01,\n",
      "          3.7175e-02, -1.2956e-03,  9.7011e-02, -9.2185e-02, -1.9496e-02,\n",
      "          1.5485e-02, -2.9129e-02, -1.0468e-01, -6.5967e-02, -1.4680e-01,\n",
      "         -4.9655e-02, -1.6410e-01,  8.7873e-02, -1.0479e-01,  1.2734e-04,\n",
      "         -9.4380e-03, -3.0487e-02, -9.6085e-03, -7.6275e-02,  3.1409e-02,\n",
      "          1.3919e-02,  9.9593e-02,  8.5133e-03,  7.8679e-03,  4.9799e-02,\n",
      "         -5.1921e-02, -7.5084e-02, -1.1609e-01,  3.7188e-02,  2.5163e-02,\n",
      "         -2.4003e-02,  3.2116e-03, -2.5594e-03, -1.6170e-02, -1.2347e-02,\n",
      "         -9.6118e-02, -6.3274e-02,  9.8181e-02, -1.3037e-02, -2.1480e-01]],\n",
      "       device='cuda:0')\n",
      "Grad Shape: torch.Size([2, 50])\n",
      "---------\n",
      "linear.bias\n",
      "Data:\n",
      "tensor([ 0.0010, -0.0224], device='cuda:0')\n",
      "Data Shape: torch.Size([2])\n",
      "-----\n",
      "Grad:\n",
      "tensor([ 0.5156, -0.5156], device='cuda:0')\n",
      "Grad Shape: torch.Size([2])\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Note that the parameter data has changed\n",
    "\n",
    "print(\"---------\")\n",
    "for name, param in Lstm.named_parameters():\n",
    "  if param.requires_grad: \n",
    "    print(name)\n",
    "    print(\"Data:\")\n",
    "    print(param.data)\n",
    "    print(f\"Data Shape: {param.data.shape}\")\n",
    "    print(\"-----\")\n",
    "    print(\"Grad:\")\n",
    "    print(param.grad)\n",
    "    print(f\"Grad Shape: {param.grad.shape}\")\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "lstm.weight_ih_l0\n",
      "Data:\n",
      "tensor([[-0.1139,  0.0966, -0.0991,  ..., -0.0125, -0.0067, -0.1301],\n",
      "        [-0.0276,  0.0993, -0.0630,  ...,  0.1027, -0.0901,  0.1481],\n",
      "        [-0.0137, -0.0564, -0.0385,  ..., -0.0891,  0.1228,  0.1291],\n",
      "        ...,\n",
      "        [ 0.1017, -0.1398, -0.0894,  ..., -0.1203, -0.0318, -0.0157],\n",
      "        [ 0.1319,  0.0766,  0.0074,  ..., -0.1235, -0.0881, -0.1479],\n",
      "        [-0.0020,  0.1071,  0.0888,  ...,  0.0340, -0.1021,  0.0617]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 200])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n",
      "lstm.weight_hh_l0\n",
      "Data:\n",
      "tensor([[-0.0572, -0.0389, -0.0597,  ...,  0.0232, -0.0593, -0.0431],\n",
      "        [ 0.0685, -0.0801,  0.0771,  ...,  0.0186,  0.1216, -0.0023],\n",
      "        [ 0.0420,  0.0376,  0.0337,  ..., -0.0311,  0.0780, -0.1062],\n",
      "        ...,\n",
      "        [ 0.0327,  0.0527, -0.0536,  ...,  0.0677,  0.0903, -0.1096],\n",
      "        [-0.0343, -0.0493, -0.1409,  ..., -0.1397, -0.0888,  0.0521],\n",
      "        [ 0.1403, -0.0353, -0.0833,  ..., -0.0731,  0.0165, -0.0510]],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200, 50])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n",
      "lstm.bias_ih_l0\n",
      "Data:\n",
      "tensor([-0.0394, -0.1040,  0.0960, -0.0333,  0.1003, -0.1058, -0.0316, -0.0722,\n",
      "        -0.0067, -0.0946,  0.0473,  0.1159, -0.0953, -0.0097,  0.0506, -0.0707,\n",
      "         0.1025, -0.0267,  0.0431, -0.1249,  0.0935, -0.1204,  0.1439,  0.1169,\n",
      "        -0.0723,  0.0639, -0.1375, -0.1275, -0.0571, -0.0356,  0.0966,  0.1286,\n",
      "         0.0627,  0.0720, -0.0993,  0.0366, -0.0691, -0.0297,  0.0923, -0.0966,\n",
      "         0.0742, -0.1040, -0.0255, -0.0875, -0.0090,  0.0911, -0.1348,  0.0433,\n",
      "        -0.0543, -0.0791,  0.1283,  0.0029,  0.0458,  0.1091, -0.0149, -0.0221,\n",
      "        -0.1480, -0.1135, -0.0442,  0.0669, -0.0011,  0.0586,  0.0103,  0.1221,\n",
      "         0.0078, -0.0767,  0.1206,  0.0381, -0.0666, -0.0428,  0.0059,  0.0689,\n",
      "         0.0636,  0.1147, -0.0954, -0.0104,  0.1216, -0.0245, -0.1259, -0.0131,\n",
      "        -0.0695,  0.0126, -0.0131, -0.0665, -0.0012,  0.0653,  0.0930, -0.1411,\n",
      "         0.0592, -0.0168, -0.0308, -0.0387,  0.1031, -0.0513,  0.0091,  0.0632,\n",
      "        -0.0880, -0.0058, -0.0967, -0.0665,  0.0239, -0.0671, -0.1370,  0.0532,\n",
      "         0.1103,  0.1083,  0.0285, -0.0303,  0.0071,  0.1025,  0.1478, -0.1449,\n",
      "        -0.0407, -0.0509,  0.1195, -0.0933,  0.1057,  0.0328,  0.1182, -0.0366,\n",
      "         0.0311,  0.0404, -0.0321, -0.0090, -0.1371, -0.1188, -0.1351, -0.0346,\n",
      "         0.0844, -0.0832, -0.0288,  0.0709, -0.0900,  0.0506, -0.0390, -0.0394,\n",
      "         0.0382, -0.0295, -0.0757, -0.0502,  0.0597, -0.0432,  0.0018,  0.1330,\n",
      "         0.1137,  0.0790,  0.0246, -0.0368,  0.1137,  0.1267, -0.0102, -0.1234,\n",
      "         0.0184, -0.0510,  0.0263,  0.1158,  0.0390,  0.1234, -0.0205,  0.0760,\n",
      "        -0.0460,  0.0150, -0.0735,  0.1309,  0.1284, -0.0163,  0.0793,  0.1179,\n",
      "        -0.0222,  0.0332, -0.0622,  0.0973, -0.0749, -0.1102,  0.0576, -0.0038,\n",
      "        -0.0794, -0.0670,  0.0649, -0.1165, -0.1218,  0.0574,  0.1033, -0.0617,\n",
      "        -0.0393,  0.0936, -0.1381,  0.0880, -0.0057, -0.0278,  0.0754,  0.0711,\n",
      "         0.1185, -0.0088,  0.1481,  0.0347, -0.0486,  0.1198, -0.0300,  0.1435],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n",
      "lstm.bias_hh_l0\n",
      "Data:\n",
      "tensor([ 2.9005e-02, -4.6989e-02,  9.3896e-02, -1.6264e-02,  1.2450e-01,\n",
      "        -4.6628e-02, -1.0879e-01,  2.9611e-02,  4.1941e-02,  6.3638e-02,\n",
      "         1.5534e-02, -1.2716e-01,  7.1124e-02, -5.5933e-02, -9.8354e-02,\n",
      "        -6.2568e-02,  6.8763e-02, -9.2721e-02,  8.4977e-02, -6.6304e-03,\n",
      "        -7.2937e-02,  7.8271e-03, -4.4975e-02,  3.6747e-02,  8.0695e-02,\n",
      "        -2.4665e-02,  1.1888e-01, -9.4987e-02,  1.0868e-01, -1.3719e-01,\n",
      "        -2.6587e-02,  3.3347e-02, -6.9598e-02, -1.6059e-02, -7.9365e-03,\n",
      "         2.0716e-02, -4.2179e-02,  6.4439e-02, -6.0475e-02, -1.4170e-01,\n",
      "        -1.1269e-01, -8.4905e-02,  1.2879e-01,  3.5355e-02, -1.4409e-01,\n",
      "         9.0573e-02,  9.3763e-02, -8.9416e-02, -8.4344e-02, -1.5023e-03,\n",
      "         1.2213e-01,  6.8678e-02,  5.3542e-02,  1.0756e-01,  1.0368e-01,\n",
      "         1.0964e-01, -3.6529e-02, -5.2022e-02,  1.3954e-01, -1.1335e-01,\n",
      "        -3.7166e-02,  7.9741e-02,  1.0949e-01,  2.9107e-02, -8.7635e-02,\n",
      "         2.8242e-02, -1.2074e-01,  1.4707e-01, -3.3665e-02, -7.7333e-02,\n",
      "        -9.2341e-02,  1.1006e-01,  1.0329e-01, -5.4705e-02, -6.7937e-02,\n",
      "        -1.0169e-01,  6.0409e-02, -7.2282e-03, -1.2862e-02, -1.5133e-01,\n",
      "         9.5591e-02,  7.8847e-02, -4.6372e-02, -5.3011e-02, -1.2008e-01,\n",
      "        -3.3904e-02, -1.1880e-02, -9.1127e-02, -9.5635e-04,  4.8286e-02,\n",
      "        -1.4929e-02, -1.4817e-01,  1.4246e-01, -2.1854e-02, -4.3448e-02,\n",
      "         9.8154e-02,  9.0216e-02, -7.2057e-02,  6.5885e-02, -1.0488e-01,\n",
      "         8.1608e-02,  7.7250e-02, -1.4324e-01,  2.0169e-02,  1.1736e-01,\n",
      "        -1.3730e-01, -1.4388e-01, -3.7778e-02,  3.0462e-04,  3.2093e-02,\n",
      "        -7.2657e-02,  1.0449e-01, -5.6378e-03,  9.8312e-02, -1.1214e-01,\n",
      "         3.7407e-02, -9.4940e-02,  1.1341e-01,  1.5079e-01, -9.8821e-02,\n",
      "         1.0476e-01,  1.9121e-02, -1.2383e-01,  1.2685e-01, -3.1846e-02,\n",
      "         1.2225e-01,  5.2655e-03,  1.1689e-01,  3.0197e-02, -5.8918e-02,\n",
      "        -7.1803e-02, -9.6178e-02,  8.5019e-02, -1.2859e-01, -1.4730e-01,\n",
      "         6.9215e-03,  2.3546e-02, -7.2243e-02, -1.2881e-01, -9.0241e-02,\n",
      "        -1.1584e-01,  2.7826e-02, -2.0006e-02, -1.2493e-01,  5.4747e-02,\n",
      "         1.5379e-02,  4.4242e-03, -1.1476e-02,  1.1465e-01,  7.8717e-02,\n",
      "         1.1075e-01, -2.3290e-02, -8.3388e-02, -7.5815e-02, -1.0355e-01,\n",
      "         7.7781e-02, -1.4459e-04, -1.1131e-02, -1.1251e-02, -1.8680e-02,\n",
      "         1.2557e-01,  5.1071e-02,  4.1735e-02,  9.9322e-02,  2.6857e-02,\n",
      "        -1.4630e-01,  1.2862e-01,  2.3678e-02,  5.6542e-02, -3.3930e-02,\n",
      "        -4.1891e-02,  1.9030e-02,  1.0712e-01, -1.1032e-01, -3.8088e-02,\n",
      "         1.0954e-01, -1.1280e-01,  1.1368e-01, -6.9081e-02,  7.4896e-02,\n",
      "        -2.2417e-02, -7.4771e-02,  1.1032e-01,  6.9327e-02,  1.0679e-01,\n",
      "        -1.2779e-01, -9.3181e-02,  5.7181e-02,  7.9991e-02, -3.3391e-02,\n",
      "        -1.1199e-01, -8.3832e-02,  6.3324e-02,  6.8245e-02,  1.2025e-01,\n",
      "        -1.0427e-02, -9.1697e-02, -4.6995e-02, -1.1498e-01,  1.1476e-01],\n",
      "       device='cuda:0')\n",
      "Data Shape: torch.Size([200])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n",
      "linear.weight\n",
      "Data:\n",
      "tensor([[ 0.1259,  0.0677,  0.1159,  0.1296,  0.0803,  0.0160,  0.0917,  0.0694,\n",
      "          0.0933, -0.1329, -0.0066,  0.1024, -0.0605,  0.0971,  0.0638, -0.0523,\n",
      "         -0.1466,  0.0236, -0.1027,  0.1173,  0.0363, -0.0027,  0.1449, -0.0699,\n",
      "          0.1265,  0.0674,  0.0887, -0.0707, -0.0696, -0.0070,  0.0787,  0.0161,\n",
      "          0.1475, -0.0527,  0.1363,  0.0240,  0.0406,  0.0019,  0.0734, -0.0360,\n",
      "          0.1244, -0.0431,  0.0605, -0.1246, -0.0435, -0.1021, -0.0043,  0.1196,\n",
      "         -0.1055, -0.1092],\n",
      "        [ 0.1198,  0.0306, -0.0016, -0.0329,  0.1124, -0.0670, -0.1359, -0.0076,\n",
      "          0.0524, -0.1092,  0.0350,  0.0735,  0.0200, -0.0665,  0.0062,  0.0784,\n",
      "         -0.1298,  0.0556, -0.0768, -0.0643, -0.1126,  0.0916, -0.1367, -0.0653,\n",
      "          0.0124,  0.1397, -0.1103,  0.0722, -0.0970, -0.0385,  0.0037,  0.0097,\n",
      "         -0.1061,  0.0018, -0.0571, -0.0167,  0.0457, -0.1001,  0.0112,  0.0221,\n",
      "          0.1412, -0.0612,  0.0944,  0.1208,  0.1178,  0.0031, -0.0298, -0.0013,\n",
      "          0.0377,  0.0422]], device='cuda:0')\n",
      "Data Shape: torch.Size([2, 50])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n",
      "linear.bias\n",
      "Data:\n",
      "tensor([ 0.0010, -0.0224], device='cuda:0')\n",
      "Data Shape: torch.Size([2])\n",
      "-----\n",
      "Grad:\n",
      "None\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Note that the gradients have been cleared\n",
    "\n",
    "print(\"---------\")\n",
    "for name, param in Lstm.named_parameters():\n",
    "  if param.requires_grad: \n",
    "    print(name)\n",
    "    print(\"Data:\")\n",
    "    print(param.data)\n",
    "    print(f\"Data Shape: {param.data.shape}\")\n",
    "    print(\"-----\")\n",
    "    print(\"Grad:\")\n",
    "    print(param.grad)\n",
    "    print(\"---------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
