{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This notebook demonstrates the process of training an ensemble learning model using a provided CSV file. It showcases data preprocessing, model training, evaluation, and saving the trained model. The ensemble method (hard voting, soft voting, or stacking) can be selected based on the user's choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "First, we import all the necessary libraries and modules needed for this script. This includes libraries for handling warnings, data manipulation, machine learning, and the custom Ensemble module containing ensemble learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    f1_score\n",
    ")\n",
    "from src import Ensemble, Bayes, LSTM, BERT\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Read CSV File\n",
    "\n",
    "The `read_csv_file` function reads the CSV file and returns a pandas DataFrame. If the file is not found, the script will exit with an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file read successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binay: Patuloy ang kahirapan dahil sa maling p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait so ur telling me Let Leni Lead mo pero NY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[USERNAME]wish this is just a nightmare that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc willie ong and isko sabunutan po</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28456</th>\n",
       "      <td>Bisaya, Probinsyano/a, mostly Bisaya = katulong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>Amnesia. In my whole life wala pa ako nakasala...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>Kontrabida na ilang beses na tinalo at obvious...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>Yung antagonist laging kailangang sobrang sama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>May nabaril or nasaksak na pero 'di pa tatawag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28461 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Binay: Patuloy ang kahirapan dahil sa maling p...      0\n",
       "1      SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...      0\n",
       "2      wait so ur telling me Let Leni Lead mo pero NY...      1\n",
       "3       [USERNAME]wish this is just a nightmare that ...      0\n",
       "4                   doc willie ong and isko sabunutan po      0\n",
       "...                                                  ...    ...\n",
       "28456    Bisaya, Probinsyano/a, mostly Bisaya = katulong      1\n",
       "28457  Amnesia. In my whole life wala pa ako nakasala...      1\n",
       "28458  Kontrabida na ilang beses na tinalo at obvious...      1\n",
       "28459  Yung antagonist laging kailangang sobrang sama...      1\n",
       "28460  May nabaril or nasaksak na pero 'di pa tatawag...      1\n",
       "\n",
       "[28461 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv_file(filename: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        data = pd.read_csv(filename, lineterminator='\\n', usecols=range(2))\n",
    "        print(\"CSV file read successfully!\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: File not found\")\n",
    "        exit(1)\n",
    "\n",
    "# Demonstrate reading a CSV file (use a sample or mock filename)\n",
    "dataset = read_csv_file('datasets/datasetall.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14115\n",
       "1    14346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Seed Random Number Generators\n",
    "\n",
    "To ensure reproducibility, the `seed_random_number_generators` function seeds the random number generators for PyTorch and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number generators seeded.\n"
     ]
    }
   ],
   "source": [
    "def seed_random_number_generators(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    print(\"Random number generators seeded.\")\n",
    "\n",
    "# Seed the random number generators\n",
    "seed_random_number_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Train-Test Split\n",
    "\n",
    "The `get_train_test_split` function splits the dataset into training and testing sets with an 80-20 split ratio and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data_frame(data_frame):\n",
    "    text = list(data_frame['text'])\n",
    "    label = list(data_frame['label'])\n",
    "\n",
    "    assert(len(text) == len(label))\n",
    "\n",
    "    indices = list(range(len(label)))\n",
    "\n",
    "    # Make a random number generator that will shuffle list of indices\n",
    "    # It is seeded to be reproducible\n",
    "    random_number_generator = np.random.default_rng(seed=0)\n",
    "    random_number_generator.shuffle(indices)\n",
    "\n",
    "    shuffled_text = []\n",
    "    shuffled_labels = []\n",
    "\n",
    "    # Iterate through the list of indices and add the original data\n",
    "    # from those shuffled indices\n",
    "    for index in indices:\n",
    "        shuffled_text.append(text[index])\n",
    "        shuffled_labels.append(label[index])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'text': shuffled_text,\n",
    "        'label': shuffled_labels,\n",
    "    })\n",
    "\n",
    "\n",
    "def get_train_test_split(data_frame: pd.DataFrame, test_size: float):\n",
    "    \"\"\"\n",
    "    Makes a stratified train test split.\n",
    "    This aims to preserve the distribution between classes.\n",
    "    \"\"\"\n",
    "    if not (1 >= test_size >= 0):\n",
    "        print('ERROR: test_size must be between 0 and 1')\n",
    "        return\n",
    "\n",
    "    data_frame = shuffle_data_frame(data_frame)\n",
    "\n",
    "    data_frame_length = len(data_frame)\n",
    "    train_size = 1 - test_size\n",
    "\n",
    "    nonhate_rows = data_frame[data_frame['label'] == 0] \n",
    "    nonhate_row_length = len(nonhate_rows)\n",
    "\n",
    "    nonhate_row_train_size = math.ceil(nonhate_row_length * train_size)\n",
    "\n",
    "    nonhate_row_train = nonhate_rows[0:nonhate_row_train_size]\n",
    "    nonhate_row_test = nonhate_rows[nonhate_row_train_size:nonhate_row_length]\n",
    "\n",
    "    assert(len(nonhate_row_train) + len(nonhate_row_test) == nonhate_row_length)\n",
    "\n",
    "    hate_rows = data_frame[data_frame['label'] == 1] \n",
    "    hate_row_length = len(hate_rows)\n",
    "\n",
    "    hate_row_train_size = math.ceil(hate_row_length * train_size)\n",
    "\n",
    "    hate_row_train = hate_rows[0:hate_row_train_size]\n",
    "    hate_row_test = hate_rows[hate_row_train_size:hate_row_length]\n",
    "\n",
    "    assert(len(hate_row_train) + len(hate_row_test) == hate_row_length)\n",
    "\n",
    "    combined_train = pd.concat([nonhate_row_train, hate_row_train])\n",
    "    combined_test = pd.concat([nonhate_row_test, hate_row_test])\n",
    "\n",
    "    shuffled_train = shuffle_data_frame(combined_train)\n",
    "    shuffled_test = shuffle_data_frame(combined_test)\n",
    "\n",
    "    return (\n",
    "        shuffled_train['text'],\n",
    "        shuffled_test['text'],\n",
    "        shuffled_train['label'],\n",
    "        shuffled_test['label'],\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(dataset, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[USERNAME] Palangga ka man sang mga taga Baco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who dafuq is Jose Montemayor Jr.???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Di na nakakatuwa yung mukha ni Mar Roxas sa TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>national elections. | via[USERNAME]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay will be staring in a movie called \"The D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22764</th>\n",
       "      <td>\"Kala ko wala andito pala si Marcos.\"*pertaini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22765</th>\n",
       "      <td>sie ~ [USERNAME]Marcos Magnanakaw Marcos Dikta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22766</th>\n",
       "      <td>If Mar is BatMarBinay is Bane-ay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22767</th>\n",
       "      <td>to my moots im sorry in not sorry for flooding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>Uunlad tayo kay Binay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22769 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0       [USERNAME] Palangga ka man sang mga taga Baco...\n",
       "1                    Who dafuq is Jose Montemayor Jr.???\n",
       "2      Di na nakakatuwa yung mukha ni Mar Roxas sa TV...\n",
       "3                    national elections. | via[USERNAME]\n",
       "4      Binay will be staring in a movie called \"The D...\n",
       "...                                                  ...\n",
       "22764  \"Kala ko wala andito pala si Marcos.\"*pertaini...\n",
       "22765  sie ~ [USERNAME]Marcos Magnanakaw Marcos Dikta...\n",
       "22766                  If Mar is BatMarBinay is Bane-ay.\n",
       "22767  to my moots im sorry in not sorry for flooding...\n",
       "22768                              Uunlad tayo kay Binay\n",
       "\n",
       "[22769 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22765</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22767</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22769 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          0\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "...      ...\n",
       "22764      0\n",
       "22765      1\n",
       "22766      1\n",
       "22767      1\n",
       "22768      0\n",
       "\n",
       "[22769 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dataframe = pd.DataFrame(y_train, columns=['label'])\n",
    "y_train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        11292\n",
       "1        11477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dataframe.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakit trending ang Only Binay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mare @ Cebu [USERNAME][USERNAME] Marcos Never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kahit anong gawin ko bakit di ko ma appreciate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oras na para tayo'y bumoto ng taong mag tataas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VP[USERNAME]is currently in Zamboanga Sibugay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>[USERNAME] Laban LeniAngat Buhay LahatLeni Kiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>Nagconcede ka man Maimarwala ka prinnagdala ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>Did You Know that former Philippine secretary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>Bakit nakakairita commercial ni Mar Roxas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>To Doc Willie Ong I'd like to believe you are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5692 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                        Bakit trending ang Only Binay?\n",
       "1     Mare @ Cebu [USERNAME][USERNAME] Marcos Never ...\n",
       "2     Kahit anong gawin ko bakit di ko ma appreciate...\n",
       "3     Oras na para tayo'y bumoto ng taong mag tataas...\n",
       "4     VP[USERNAME]is currently in Zamboanga Sibugay ...\n",
       "...                                                 ...\n",
       "5687    [USERNAME] Laban LeniAngat Buhay LahatLeni Kiko\n",
       "5688  Nagconcede ka man Maimarwala ka prinnagdala ka...\n",
       "5689  Did You Know that former Philippine secretary ...\n",
       "5690         Bakit nakakairita commercial ni Mar Roxas?\n",
       "5691  To Doc Willie Ong I'd like to believe you are ...\n",
       "\n",
       "[5692 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5692 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "5687      0\n",
       "5688      1\n",
       "5689      0\n",
       "5690      1\n",
       "5691      0\n",
       "\n",
       "[5692 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dataframe = pd.DataFrame(y_test, columns=['label'])\n",
    "y_test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        2823\n",
       "1        2869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dataframe.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;akin&#x27;,\n",
       "                                                                    &#x27;aking&#x27;,\n",
       "                                                                    &#x27;ako&#x27;,\n",
       "                                                                    &#x27;alin&#x27;,\n",
       "                                                                    &#x27;am&#x27;,\n",
       "                                                                    &#x27;amin&#x27;,\n",
       "                                                                    &#x27;aming&#x27;,\n",
       "                                                                    &#x27;ang&#x27;,\n",
       "                                                                    &#x27;ano&#x27;,\n",
       "                                                                    &#x27;anumang&#x27;,\n",
       "                                                                    &#x27;apat&#x27;,\n",
       "                                                                    &#x27;at&#x27;,\n",
       "                                                                    &#x27;atin&#x27;,\n",
       "                                                                    &#x27;ating&#x27;,\n",
       "                                                                    &#x27;ay&#x27;,\n",
       "                                                                    &#x27;bababa&#x27;,\n",
       "                                                                    &#x27;bago&#x27;,\n",
       "                                                                    &#x27;bakit&#x27;,\n",
       "                                                                    &#x27;bawat&#x27;,\n",
       "                                                                    &#x27;bilang&#x27;,\n",
       "                                                                    &#x27;dahil&#x27;,\n",
       "                                                                    &#x27;dalawa&#x27;,\n",
       "                                                                    &#x27;dapat&#x27;,\n",
       "                                                                    &#x27;din&#x27;,\n",
       "                                                                    &#x27;dito&#x27;,\n",
       "                                                                    &#x27;doon&#x27;,\n",
       "                                                                    &#x27;gagawin&#x27;,\n",
       "                                                                    &#x27;gayunman&#x27;,\n",
       "                                                                    &#x27;ginagawa&#x27;,\n",
       "                                                                    &#x27;ginawa&#x27;, ...])),\n",
       "                                       (&#x27;bayes&#x27;, BernoulliNB())]),\n",
       "             param_grid={&#x27;bayes__alpha&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                          0.7, 0.8, 0.9, 1.0],\n",
       "                         &#x27;bayes__force_alpha&#x27;: [False, True]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;akin&#x27;,\n",
       "                                                                    &#x27;aking&#x27;,\n",
       "                                                                    &#x27;ako&#x27;,\n",
       "                                                                    &#x27;alin&#x27;,\n",
       "                                                                    &#x27;am&#x27;,\n",
       "                                                                    &#x27;amin&#x27;,\n",
       "                                                                    &#x27;aming&#x27;,\n",
       "                                                                    &#x27;ang&#x27;,\n",
       "                                                                    &#x27;ano&#x27;,\n",
       "                                                                    &#x27;anumang&#x27;,\n",
       "                                                                    &#x27;apat&#x27;,\n",
       "                                                                    &#x27;at&#x27;,\n",
       "                                                                    &#x27;atin&#x27;,\n",
       "                                                                    &#x27;ating&#x27;,\n",
       "                                                                    &#x27;ay&#x27;,\n",
       "                                                                    &#x27;bababa&#x27;,\n",
       "                                                                    &#x27;bago&#x27;,\n",
       "                                                                    &#x27;bakit&#x27;,\n",
       "                                                                    &#x27;bawat&#x27;,\n",
       "                                                                    &#x27;bilang&#x27;,\n",
       "                                                                    &#x27;dahil&#x27;,\n",
       "                                                                    &#x27;dalawa&#x27;,\n",
       "                                                                    &#x27;dapat&#x27;,\n",
       "                                                                    &#x27;din&#x27;,\n",
       "                                                                    &#x27;dito&#x27;,\n",
       "                                                                    &#x27;doon&#x27;,\n",
       "                                                                    &#x27;gagawin&#x27;,\n",
       "                                                                    &#x27;gayunman&#x27;,\n",
       "                                                                    &#x27;ginagawa&#x27;,\n",
       "                                                                    &#x27;ginawa&#x27;, ...])),\n",
       "                                       (&#x27;bayes&#x27;, BernoulliNB())]),\n",
       "             param_grid={&#x27;bayes__alpha&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                          0.7, 0.8, 0.9, 1.0],\n",
       "                         &#x27;bayes__force_alpha&#x27;: [False, True]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;akin&#x27;, &#x27;aking&#x27;, &#x27;ako&#x27;, &#x27;alin&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;amin&#x27;, &#x27;aming&#x27;, &#x27;ang&#x27;,\n",
       "                                             &#x27;ano&#x27;, &#x27;anumang&#x27;, &#x27;apat&#x27;, &#x27;at&#x27;,\n",
       "                                             &#x27;atin&#x27;, &#x27;ating&#x27;, &#x27;ay&#x27;, &#x27;bababa&#x27;,\n",
       "                                             &#x27;bago&#x27;, &#x27;bakit&#x27;, &#x27;bawat&#x27;, &#x27;bilang&#x27;,\n",
       "                                             &#x27;dahil&#x27;, &#x27;dalawa&#x27;, &#x27;dapat&#x27;, &#x27;din&#x27;,\n",
       "                                             &#x27;dito&#x27;, &#x27;doon&#x27;, &#x27;gagawin&#x27;,\n",
       "                                             &#x27;gayunman&#x27;, &#x27;ginagawa&#x27;, &#x27;ginawa&#x27;, ...])),\n",
       "                (&#x27;bayes&#x27;, BernoulliNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;akin&#x27;, &#x27;aking&#x27;, &#x27;ako&#x27;, &#x27;alin&#x27;, &#x27;am&#x27;, &#x27;amin&#x27;,\n",
       "                            &#x27;aming&#x27;, &#x27;ang&#x27;, &#x27;ano&#x27;, &#x27;anumang&#x27;, &#x27;apat&#x27;, &#x27;at&#x27;,\n",
       "                            &#x27;atin&#x27;, &#x27;ating&#x27;, &#x27;ay&#x27;, &#x27;bababa&#x27;, &#x27;bago&#x27;, &#x27;bakit&#x27;,\n",
       "                            &#x27;bawat&#x27;, &#x27;bilang&#x27;, &#x27;dahil&#x27;, &#x27;dalawa&#x27;, &#x27;dapat&#x27;,\n",
       "                            &#x27;din&#x27;, &#x27;dito&#x27;, &#x27;doon&#x27;, &#x27;gagawin&#x27;, &#x27;gayunman&#x27;,\n",
       "                            &#x27;ginagawa&#x27;, &#x27;ginawa&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['akin',\n",
       "                                                                    'aking',\n",
       "                                                                    'ako',\n",
       "                                                                    'alin',\n",
       "                                                                    'am',\n",
       "                                                                    'amin',\n",
       "                                                                    'aming',\n",
       "                                                                    'ang',\n",
       "                                                                    'ano',\n",
       "                                                                    'anumang',\n",
       "                                                                    'apat',\n",
       "                                                                    'at',\n",
       "                                                                    'atin',\n",
       "                                                                    'ating',\n",
       "                                                                    'ay',\n",
       "                                                                    'bababa',\n",
       "                                                                    'bago',\n",
       "                                                                    'bakit',\n",
       "                                                                    'bawat',\n",
       "                                                                    'bilang',\n",
       "                                                                    'dahil',\n",
       "                                                                    'dalawa',\n",
       "                                                                    'dapat',\n",
       "                                                                    'din',\n",
       "                                                                    'dito',\n",
       "                                                                    'doon',\n",
       "                                                                    'gagawin',\n",
       "                                                                    'gayunman',\n",
       "                                                                    'ginagawa',\n",
       "                                                                    'ginawa', ...])),\n",
       "                                       ('bayes', BernoulliNB())]),\n",
       "             param_grid={'bayes__alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6,\n",
       "                                          0.7, 0.8, 0.9, 1.0],\n",
       "                         'bayes__force_alpha': [False, True]},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search = GridSearchCV(\n",
    "  estimator=Bayes.BayesPipeline,\n",
    "  param_grid={\n",
    "    'bayes__alpha': [\n",
    "      0.0, \n",
    "      0.1,\n",
    "      0.2, \n",
    "      0.3,\n",
    "      0.4, \n",
    "      0.5,\n",
    "      0.6, \n",
    "      0.7,\n",
    "      0.8, \n",
    "      0.9,\n",
    "      1.0,\n",
    "    ],\n",
    "    'bayes__force_alpha': [False, True],\n",
    "  },\n",
    "  scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "  refit='f1',\n",
    "  cv=cross_validator,\n",
    ")\n",
    "\n",
    "nb_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.5223249 , 0.4896481 , 0.47244115, 0.46712408, 0.47542639,\n",
       "        0.44985943, 0.44800286, 0.45198665, 0.48398552, 0.46826272,\n",
       "        0.47541704, 0.47585812, 0.45430717, 0.44378109, 0.44722958,\n",
       "        0.44757495, 0.45077658, 0.44767056, 0.45050225, 0.42875443,\n",
       "        0.42553067, 0.46647315]),\n",
       " 'std_fit_time': array([0.0689711 , 0.03020135, 0.01440048, 0.01633345, 0.02235043,\n",
       "        0.00560936, 0.00428408, 0.02067163, 0.01702272, 0.02200826,\n",
       "        0.02618092, 0.02062235, 0.00472322, 0.00391361, 0.0084868 ,\n",
       "        0.00390104, 0.00993896, 0.0093401 , 0.01209115, 0.01064606,\n",
       "        0.00676846, 0.03468616]),\n",
       " 'mean_score_time': array([0.1165215 , 0.1159162 , 0.11313138, 0.11472807, 0.11290216,\n",
       "        0.10704799, 0.1088119 , 0.11368947, 0.11444073, 0.11271482,\n",
       "        0.11208215, 0.11966667, 0.10954599, 0.10940342, 0.10911126,\n",
       "        0.10957127, 0.10913196, 0.10933256, 0.11028666, 0.105615  ,\n",
       "        0.10555358, 0.11434054]),\n",
       " 'std_score_time': array([0.00704809, 0.00939407, 0.00721398, 0.00878005, 0.00319732,\n",
       "        0.00188539, 0.00433531, 0.00968221, 0.00301719, 0.00422486,\n",
       "        0.00518609, 0.00435823, 0.00303591, 0.00326877, 0.00213953,\n",
       "        0.00390908, 0.00233403, 0.00410852, 0.00550264, 0.00268077,\n",
       "        0.00191475, 0.01943998]),\n",
       " 'param_bayes__alpha': masked_array(data=[0.0, 0.0, 0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5,\n",
       "                    0.5, 0.6, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 0.9, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_bayes__force_alpha': masked_array(data=[False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True, False, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'bayes__alpha': 0.0, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.0, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.1, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.1, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.2, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.2, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.3, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.3, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.4, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.4, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.5, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.5, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.6, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.6, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.7, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.7, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.8, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.8, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.9, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.9, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 1.0, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 1.0, 'bayes__force_alpha': True}],\n",
       " 'split0_test_accuracy': array([0.76921388, 0.73429952, 0.80632411, 0.80632411, 0.80610452,\n",
       "        0.80610452, 0.80808081, 0.80808081, 0.80764163, 0.80764163,\n",
       "        0.80764163, 0.80764163, 0.8083004 , 0.8083004 , 0.80917874,\n",
       "        0.80917874, 0.80917874, 0.80917874, 0.80895916, 0.80895916,\n",
       "        0.80851998, 0.80851998]),\n",
       " 'split1_test_accuracy': array([0.77140975, 0.75054897, 0.81774264, 0.81774264, 0.81906017,\n",
       "        0.81906017, 0.81927975, 0.81927975, 0.81708388, 0.81708388,\n",
       "        0.81532718, 0.81532718, 0.81554677, 0.81554677, 0.8151076 ,\n",
       "        0.8151076 , 0.81444884, 0.81444884, 0.81357049, 0.81357049,\n",
       "        0.81444884, 0.81444884]),\n",
       " 'split2_test_accuracy': array([0.77382521, 0.74462011, 0.8151076 , 0.8151076 , 0.81642512,\n",
       "        0.81642512, 0.81818182, 0.81818182, 0.81774264, 0.81774264,\n",
       "        0.81774264, 0.81774264, 0.81774264, 0.81774264, 0.81642512,\n",
       "        0.81642512, 0.81642512, 0.81642512, 0.8151076 , 0.8151076 ,\n",
       "        0.81466842, 0.81466842]),\n",
       " 'split3_test_accuracy': array([0.77470356, 0.74264383, 0.81576636, 0.81576636, 0.81818182,\n",
       "        0.81818182, 0.81993852, 0.81993852, 0.82103645, 0.82103645,\n",
       "        0.82235397, 0.82235397, 0.8236715 , 0.8236715 , 0.82411067,\n",
       "        0.82411067, 0.82345191, 0.82345191, 0.82213439, 0.82213439,\n",
       "        0.82169521, 0.82169521]),\n",
       " 'split4_test_accuracy': array([0.77970569, 0.75093345, 0.81682407, 0.81682407, 0.81506699,\n",
       "        0.81506699, 0.8163848 , 0.8163848 , 0.81594553, 0.81594553,\n",
       "        0.81616517, 0.81616517, 0.81616517, 0.81616517, 0.81550626,\n",
       "        0.81550626, 0.81550626, 0.81550626, 0.81528662, 0.81528662,\n",
       "        0.81309027, 0.81309027]),\n",
       " 'mean_test_accuracy': array([0.77377162, 0.74460918, 0.81435296, 0.81435296, 0.81496772,\n",
       "        0.81496772, 0.81637314, 0.81637314, 0.81589003, 0.81589003,\n",
       "        0.81584612, 0.81584612, 0.81628529, 0.81628529, 0.81606568,\n",
       "        0.81606568, 0.81580217, 0.81580217, 0.81501165, 0.81501165,\n",
       "        0.81448455, 0.81448455]),\n",
       " 'std_test_accuracy': array([0.00353372, 0.00608982, 0.00411402, 0.00411402, 0.0046426 ,\n",
       "        0.0046426 , 0.00431728, 0.00431728, 0.0044583 , 0.0044583 ,\n",
       "        0.00476726, 0.00476726, 0.00491932, 0.00491932, 0.0047647 ,\n",
       "        0.0047647 , 0.00457592, 0.00457592, 0.0042315 , 0.0042315 ,\n",
       "        0.00423199, 0.00423199]),\n",
       " 'rank_test_accuracy': array([21, 22, 19, 19, 15, 15,  1,  1,  7,  7,  9,  9,  3,  3,  5,  5, 11,\n",
       "        11, 13, 13, 17, 17], dtype=int32),\n",
       " 'split0_test_precision': array([0.74721781, 0.73867136, 0.77500973, 0.77500973, 0.77428127,\n",
       "        0.77428127, 0.77656676, 0.77656676, 0.77553398, 0.77553398,\n",
       "        0.77574815, 0.77574815, 0.77643857, 0.77643857, 0.77743191,\n",
       "        0.77743191, 0.77700078, 0.77700078, 0.77648428, 0.77648428,\n",
       "        0.7754549 , 0.7754549 ]),\n",
       " 'split1_test_precision': array([0.75059952, 0.76068376, 0.79032897, 0.79032897, 0.79244533,\n",
       "        0.79244533, 0.79206349, 0.79206349, 0.79030977, 0.79030977,\n",
       "        0.78849206, 0.78849206, 0.78857596, 0.78857596, 0.78795085,\n",
       "        0.78795085, 0.78701504, 0.78701504, 0.78531965, 0.78531965,\n",
       "        0.78656126, 0.78656126]),\n",
       " 'split2_test_precision': array([0.7492126 , 0.75121951, 0.78376269, 0.78376269, 0.78316524,\n",
       "        0.78316524, 0.78493789, 0.78493789, 0.78477078, 0.78477078,\n",
       "        0.78410853, 0.78410853, 0.78410853, 0.78410853, 0.78272657,\n",
       "        0.78272657, 0.78294574, 0.78294574, 0.78069498, 0.78069498,\n",
       "        0.77987664, 0.77987664]),\n",
       " 'split3_test_precision': array([0.75      , 0.74823322, 0.78401559, 0.78401559, 0.78560311,\n",
       "        0.78560311, 0.78738318, 0.78738318, 0.78757282, 0.78757282,\n",
       "        0.78873786, 0.78873786, 0.79012825, 0.79012825, 0.79029126,\n",
       "        0.79029126, 0.78937161, 0.78937161, 0.78709428, 0.78709428,\n",
       "        0.78670788, 0.78670788]),\n",
       " 'split4_test_precision': array([0.7596463 , 0.75926753, 0.78748524, 0.78748524, 0.78546169,\n",
       "        0.78546169, 0.78574226, 0.78574226, 0.7844592 , 0.7844592 ,\n",
       "        0.78498827, 0.78498827, 0.78476563, 0.78476563, 0.78384705,\n",
       "        0.78384705, 0.78384705, 0.78384705, 0.78354134, 0.78354134,\n",
       "        0.7807154 , 0.7807154 ]),\n",
       " 'mean_test_precision': array([0.75133525, 0.75161508, 0.78412045, 0.78412045, 0.78419133,\n",
       "        0.78419133, 0.78533872, 0.78533872, 0.78452931, 0.78452931,\n",
       "        0.78441498, 0.78441498, 0.78480339, 0.78480339, 0.78444953,\n",
       "        0.78444953, 0.78403604, 0.78403604, 0.78262691, 0.78262691,\n",
       "        0.78186322, 0.78186322]),\n",
       " 'std_test_precision': array([0.00430945, 0.00799918, 0.00515775, 0.00515775, 0.00584803,\n",
       "        0.00584803, 0.00503335, 0.00503335, 0.00497304, 0.00497304,\n",
       "        0.00470843, 0.00470843, 0.00475481, 0.00475481, 0.0044489 ,\n",
       "        0.0044489 , 0.00419672, 0.00419672, 0.0037285 , 0.0037285 ,\n",
       "        0.00428656, 0.00428656]),\n",
       " 'rank_test_precision': array([22, 21, 13, 13, 11, 11,  1,  1,  5,  5,  9,  9,  3,  3,  7,  7, 15,\n",
       "        15, 17, 17, 19, 19], dtype=int32),\n",
       " 'split0_test_recall': array([0.81917211, 0.73159041, 0.86753813, 0.86753813, 0.86840959,\n",
       "        0.86840959, 0.86928105, 0.86928105, 0.87015251, 0.87015251,\n",
       "        0.86971678, 0.86971678, 0.87015251, 0.87015251, 0.87058824,\n",
       "        0.87058824, 0.87145969, 0.87145969, 0.87189542, 0.87189542,\n",
       "        0.87276688, 0.87276688]),\n",
       " 'split1_test_recall': array([0.81830065, 0.73681917, 0.86884532, 0.86884532, 0.86840959,\n",
       "        0.86840959, 0.86971678, 0.86971678, 0.8671024 , 0.8671024 ,\n",
       "        0.86579521, 0.86579521, 0.86623094, 0.86623094, 0.86623094,\n",
       "        0.86623094, 0.86623094, 0.86623094, 0.8671024 , 0.8671024 ,\n",
       "        0.8671024 , 0.8671024 ]),\n",
       " 'split2_test_recall': array([0.82883275, 0.73780488, 0.87456446, 0.87456446, 0.8793554 ,\n",
       "        0.8793554 , 0.88066202, 0.88066202, 0.87979094, 0.87979094,\n",
       "        0.88109756, 0.88109756, 0.88109756, 0.88109756, 0.88022648,\n",
       "        0.88022648, 0.87979094, 0.87979094, 0.88066202, 0.88066202,\n",
       "        0.88109756, 0.88109756]),\n",
       " 'split3_test_recall': array([0.82970383, 0.73780488, 0.87587108, 0.87587108, 0.8793554 ,\n",
       "        0.8793554 , 0.88066202, 0.88066202, 0.88327526, 0.88327526,\n",
       "        0.88458188, 0.88458188, 0.88545296, 0.88545296, 0.88632404,\n",
       "        0.88632404, 0.88632404, 0.88632404, 0.88719512, 0.88719512,\n",
       "        0.88675958, 0.88675958]),\n",
       " 'split4_test_recall': array([0.82352941, 0.74074074, 0.87189542, 0.87189542, 0.87102397,\n",
       "        0.87102397, 0.87407407, 0.87407407, 0.87538126, 0.87538126,\n",
       "        0.87494553, 0.87494553, 0.87538126, 0.87538126, 0.87538126,\n",
       "        0.87538126, 0.87538126, 0.87538126, 0.87538126, 0.87538126,\n",
       "        0.87494553, 0.87494553]),\n",
       " 'mean_test_recall': array([0.82390775, 0.73695202, 0.87174288, 0.87174288, 0.87331079,\n",
       "        0.87331079, 0.87487919, 0.87487919, 0.87514047, 0.87514047,\n",
       "        0.87522739, 0.87522739, 0.87566305, 0.87566305, 0.87575019,\n",
       "        0.87575019, 0.87583738, 0.87583738, 0.87644725, 0.87644725,\n",
       "        0.87653439, 0.87653439]),\n",
       " 'std_test_recall': array([0.00472989, 0.00298575, 0.00319695, 0.00319695, 0.00502688,\n",
       "        0.00502688, 0.00501039, 0.00501039, 0.00595567, 0.00595567,\n",
       "        0.00694806, 0.00694806, 0.00699695, 0.00699695, 0.00706033,\n",
       "        0.00706033, 0.00688849, 0.00688849, 0.00696366, 0.00696366,\n",
       "        0.00679791, 0.00679791]),\n",
       " 'rank_test_recall': array([21, 22, 19, 19, 17, 17, 15, 15, 13, 13, 11, 11,  9,  9,  7,  7,  5,\n",
       "         5,  3,  3,  1,  1], dtype=int32),\n",
       " 'split0_test_f1': array([0.7815423 , 0.73511384, 0.81866776, 0.81866776, 0.81864859,\n",
       "        0.81864859, 0.8203125 , 0.8203125 , 0.8201232 , 0.8201232 ,\n",
       "        0.8200493 , 0.8200493 , 0.82062872, 0.82062872, 0.82137718,\n",
       "        0.82137718, 0.82152393, 0.82152393, 0.82142857, 0.82142857,\n",
       "        0.82123821, 0.82123821]),\n",
       " 'split1_test_f1': array([0.78298937, 0.74856131, 0.82772935, 0.82772935, 0.82869023,\n",
       "        0.82869023, 0.8290758 , 0.8290758 , 0.82692707, 0.82692707,\n",
       "        0.82533749, 0.82533749, 0.8255814 , 0.8255814 , 0.82523869,\n",
       "        0.82523869, 0.82472516, 0.82472516, 0.8241872 , 0.8241872 ,\n",
       "        0.82487047, 0.82487047]),\n",
       " 'split2_test_f1': array([0.78701406, 0.74445177, 0.82667765, 0.82667765, 0.82847764,\n",
       "        0.82847764, 0.83004926, 0.83004926, 0.82956879, 0.82956879,\n",
       "        0.82977851, 0.82977851, 0.82977851, 0.82977851, 0.82861829,\n",
       "        0.82861829, 0.82854799, 0.82854799, 0.8276709 , 0.8276709 ,\n",
       "        0.82740286, 0.82740286]),\n",
       " 'split3_test_f1': array([0.78784119, 0.74298246, 0.82740177, 0.82740177, 0.8298397 ,\n",
       "        0.8298397 , 0.83141447, 0.83141447, 0.83268323, 0.83268323,\n",
       "        0.83391501, 0.83391501, 0.83507907, 0.83507907, 0.83555738,\n",
       "        0.83555738, 0.83504309, 0.83504309, 0.83415233, 0.83415233,\n",
       "        0.83374283, 0.83374283]),\n",
       " 'split4_test_f1': array([0.79029898, 0.74988972, 0.82754342, 0.82754342, 0.82603306,\n",
       "        0.82603306, 0.82755776, 0.82755776, 0.82742998, 0.82742998,\n",
       "        0.82752936, 0.82752936, 0.82760041, 0.82760041, 0.82708934,\n",
       "        0.82708934, 0.82708934, 0.82708934, 0.82691912, 0.82691912,\n",
       "        0.82514896, 0.82514896]),\n",
       " 'mean_test_f1': array([0.78593718, 0.74419982, 0.82560399, 0.82560399, 0.82633784,\n",
       "        0.82633784, 0.82768196, 0.82768196, 0.82734646, 0.82734646,\n",
       "        0.82732193, 0.82732193, 0.82773362, 0.82773362, 0.82757618,\n",
       "        0.82757618, 0.8273859 , 0.8273859 , 0.82687162, 0.82687162,\n",
       "        0.82648067, 0.82648067]),\n",
       " 'std_test_f1': array([0.00321915, 0.00520573, 0.00348639, 0.00348639, 0.00403963,\n",
       "        0.00403963, 0.00389366, 0.00389366, 0.00414194, 0.00414194,\n",
       "        0.0046125 , 0.0046125 , 0.00475955, 0.00475955, 0.0046672 ,\n",
       "        0.0046672 , 0.00450584, 0.00450584, 0.004254  , 0.004254  ,\n",
       "        0.00413374, 0.00413374]),\n",
       " 'rank_test_f1': array([21, 22, 19, 19, 17, 17,  3,  3,  9,  9, 11, 11,  1,  1,  5,  5,  7,\n",
       "         7, 13, 13, 15, 15], dtype=int32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bayes__alpha': 0.3, 'bayes__force_alpha': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7560 candidates, totalling 37800 fits\n",
      "[CV 1/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 4.3min\n",
      "[CV 2/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 4.2min\n",
      "[CV 3/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 4.3min\n",
      "[CV 4/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 4.2min\n",
      "[CV 5/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 3.0min\n",
      "[CV 1/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.1; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 2/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.1; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 3/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.1; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 4/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.1; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 5/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.1; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 1/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.01; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 2/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.01; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n",
      "[CV 3/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.01; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.7min\n",
      "[CV 4/5] END lstm__batch_size=32, lstm__max_epochs=100, lstm__module__hidden_size=100, lstm__module__num_layers=1, lstm__optimizer__lr=0.1, lstm__optimizer__weight_decay=0.01; accuracy: (test=nan) f1: (test=nan) precision: (test=nan) recall: (test=nan) total time= 2.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lstm_grid_search \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   estimator\u001b[39m=\u001b[39mLSTM\u001b[39m.\u001b[39mLstmPipeline,\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   param_grid\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   verbose\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/train.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m lstm_grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/pipeline.py:423\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 423\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    424\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    375\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    376\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    378\u001b[0m     cloned_transformer,\n\u001b[1;32m    379\u001b[0m     X,\n\u001b[1;32m    380\u001b[0m     y,\n\u001b[1;32m    381\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    382\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    383\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    384\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/src/LSTM.py:111\u001b[0m, in \u001b[0;36mCalamancyTokenizer.transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    106\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mvalues\n\u001b[1;32m    108\u001b[0m \u001b[39m# Pipe is a faster way of iterating through all the data.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# We get the vector of the tokenized text and reshape them\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# to be the right output shape.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m result \u001b[39m=\u001b[39m [\n\u001b[1;32m    112\u001b[0m     text\u001b[39m.\u001b[39mvector\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[39mfor\u001b[39;00m text \n\u001b[1;32m    114\u001b[0m     \u001b[39min\u001b[39;00m Calamancy\u001b[39m.\u001b[39mpipe(data)\n\u001b[1;32m    115\u001b[0m ]\n\u001b[1;32m    117\u001b[0m \u001b[39m# Concatenate all of them to form tensors of the right\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# output shape.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(result)\n",
      "File \u001b[0;32m/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/src/LSTM.py:111\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mvalues\n\u001b[1;32m    108\u001b[0m \u001b[39m# Pipe is a faster way of iterating through all the data.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# We get the vector of the tokenized text and reshape them\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# to be the right output shape.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m result \u001b[39m=\u001b[39m [\n\u001b[1;32m    112\u001b[0m     text\u001b[39m.\u001b[39mvector\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[39mfor\u001b[39;00m text \n\u001b[1;32m    114\u001b[0m     \u001b[39min\u001b[39;00m Calamancy\u001b[39m.\u001b[39mpipe(data)\n\u001b[1;32m    115\u001b[0m ]\n\u001b[1;32m    117\u001b[0m \u001b[39m# Concatenate all of them to form tensors of the right\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# output shape.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(result)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1617\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1618\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1619\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1650\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[0;32m-> 1650\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1652\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/util.py:1703\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1694\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1695\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1701\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1703\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1704\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1705\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1706\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_dim(\u001b[39m\"\u001b[39m\u001b[39mnO\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39malloc((\u001b[39m0\u001b[39m, width)) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(docs)\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/layernorm.py:26\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m N, mu, var \u001b[39m=\u001b[39m _get_moments(model\u001b[39m.\u001b[39mops, X)\n\u001b[1;32m     25\u001b[0m Xhat \u001b[39m=\u001b[39m (X \u001b[39m-\u001b[39m mu) \u001b[39m*\u001b[39m var \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m Y, backprop_rescale \u001b[39m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dY: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m InT:\n\u001b[1;32m     29\u001b[0m     dY \u001b[39m=\u001b[39m backprop_rescale(dY)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/thinc/layers/layernorm.py:61\u001b[0m, in \u001b[0;36m_begin_update_scale_shift\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     59\u001b[0m G \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mG\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m b \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m Y \u001b[39m=\u001b[39m X \u001b[39m*\u001b[39;49m G\n\u001b[1;32m     62\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m b\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfinish_update_scale_shift\u001b[39m(dY: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m InT:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_grid_search = GridSearchCV(\n",
    "  estimator=LSTM.LstmPipeline,\n",
    "  param_grid={\n",
    "    'lstm__max_epochs': [100, 200, 300],\n",
    "    'lstm__batch_size': [32, 64, 128],\n",
    "    'lstm__optimizer__lr': [0.1, 0.02, 0.015, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'lstm__optimizer__weight_decay': [0, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'lstm__module__hidden_size': [100, 200, 300, 400],\n",
    "    'lstm__module__num_layers': [1, 2, 3, 4, 5],\n",
    "  },\n",
    "  scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "  refit='f1',\n",
    "  cv=cross_validator,\n",
    "  verbose=3,\n",
    ")\n",
    "\n",
    "lstm_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Training Function\n",
    "\n",
    "The `train_ensemble` function initializes and trains the ensemble model using the provided training data. It takes the training features and labels as input, along with the ensemble model instance, and returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(X_train: list, y_train: list, ensemble):\n",
    "    seed_random_number_generators()  # Ensure reproducibility\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    print(\"Ensemble model trained.\")\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation Function\n",
    "\n",
    "The `get_prediction_results` function uses the trained ensemble model to make predictions on the test set and then evaluates these predictions by calculating the accuracy, recall, precision, and F1-score. It returns these metrics for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_results(X_test: list, y_test: list, ensemble):\n",
    "    with torch.inference_mode():\n",
    "        y_pred = ensemble.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy}\\nRecall: {recall}\\nPrecision: {precision}\\nF1-score: {f1}\")\n",
    "        return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Function\n",
    "\n",
    "The `save_trained_model` function saves the trained ensemble model to disk using the joblib library. This allows for the model to be reloaded and used for predictions without the need for retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(ensemble, filename=\"Ensemble\"):\n",
    "    import joblib\n",
    "    joblib.dump(ensemble, f'{filename}.pkl', compress=True)\n",
    "    print(f\"Ensemble model saved to {filename}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Workflow\n",
    "\n",
    "This cell combines all the previous steps to execute the workflow. It includes reading the dataset, splitting it into training and testing sets, selecting the ensemble method, training the model, evaluating its performance, and saving the trained model. Replace 'your_dataset.csv' with the path to your dataset and choose an appropriate ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'datasets/datasetall.csv'\n",
    "ENSEMBLE_METHOD = 'hard'\n",
    "\n",
    "# Read data and prepare train-test split\n",
    "data_frame = read_csv_file(FILENAME)\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(data_frame)\n",
    "\n",
    "# Initialize and train the ensemble\n",
    "ensemble_methods = {\n",
    "    'hard': Ensemble.HardVotingEnsemble(),\n",
    "    'soft': Ensemble.SoftVotingEnsemble(),\n",
    "    'stacking': Ensemble.StackingEnsemble(),\n",
    "}\n",
    "ensemble = train_ensemble(X_train, y_train, ensemble_methods[ENSEMBLE_METHOD])\n",
    "\n",
    "# Evaluate the trained ensemble and display results\n",
    "accuracy, recall, precision, f1 = get_prediction_results(X_test, y_test, ensemble)\n",
    "\n",
    "# Save the trained model\n",
    "save_trained_model(ensemble, f'ensemble-{ENSEMBLE_METHOD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "To better visualize the evaluation results, this cell creates a pandas DataFrame to display the accuracy, recall, precision, and F1-score in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'F1-Score'],\n",
    "    'Value': [accuracy, recall, precision, f1]\n",
    "})\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
