{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This notebook demonstrates the process of training an ensemble learning model using a provided CSV file. It showcases data preprocessing, model training, evaluation, and saving the trained model. The ensemble method (hard voting, soft voting, or stacking) can be selected based on the user's choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "First, we import all the necessary libraries and modules needed for this script. This includes libraries for handling warnings, data manipulation, machine learning, and the custom Ensemble module containing ensemble learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    f1_score\n",
    ")\n",
    "from src import Ensemble, Bayes, LSTM, BERT\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Read CSV File\n",
    "\n",
    "The `read_csv_file` function reads the CSV file and returns a pandas DataFrame. If the file is not found, the script will exit with an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file read successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binay: Patuloy ang kahirapan dahil sa maling p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait so ur telling me Let Leni Lead mo pero NY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[USERNAME]wish this is just a nightmare that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc willie ong and isko sabunutan po</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28456</th>\n",
       "      <td>Bisaya, Probinsyano/a, mostly Bisaya = katulong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>Amnesia. In my whole life wala pa ako nakasala...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>Kontrabida na ilang beses na tinalo at obvious...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>Yung antagonist laging kailangang sobrang sama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>May nabaril or nasaksak na pero 'di pa tatawag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Binay: Patuloy ang kahirapan dahil sa maling p...      0\n",
       "1      SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...      0\n",
       "2      wait so ur telling me Let Leni Lead mo pero NY...      1\n",
       "3       [USERNAME]wish this is just a nightmare that ...      0\n",
       "4                   doc willie ong and isko sabunutan po      0\n",
       "...                                                  ...    ...\n",
       "28456    Bisaya, Probinsyano/a, mostly Bisaya = katulong      1\n",
       "28457  Amnesia. In my whole life wala pa ako nakasala...      1\n",
       "28458  Kontrabida na ilang beses na tinalo at obvious...      1\n",
       "28459  Yung antagonist laging kailangang sobrang sama...      1\n",
       "28460  May nabaril or nasaksak na pero 'di pa tatawag...      1\n",
       "\n",
       "[28461 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv_file(filename: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        data = pd.read_csv(filename, lineterminator='\\n', usecols=range(2))\n",
    "        print(\"CSV file read successfully!\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: File not found\")\n",
    "        exit(1)\n",
    "\n",
    "# Demonstrate reading a CSV file (use a sample or mock filename)\n",
    "dataset = read_csv_file('datasets/datasetall.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14115\n",
       "1    14346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Seed Random Number Generators\n",
    "\n",
    "To ensure reproducibility, the `seed_random_number_generators` function seeds the random number generators for PyTorch and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number generators seeded.\n"
     ]
    }
   ],
   "source": [
    "def seed_random_number_generators(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    print(\"Random number generators seeded.\")\n",
    "\n",
    "# Seed the random number generators\n",
    "seed_random_number_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Train-Test Split\n",
    "\n",
    "The `get_train_test_split` function splits the dataset into training and testing sets with an 80-20 split ratio and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data_frame(data_frame):\n",
    "    text = list(data_frame['text'])\n",
    "    label = list(data_frame['label'])\n",
    "\n",
    "    assert(len(text) == len(label))\n",
    "\n",
    "    indices = list(range(len(label)))\n",
    "\n",
    "    # Make a random number generator that will shuffle list of indices\n",
    "    # It is seeded to be reproducible\n",
    "    random_number_generator = np.random.default_rng(seed=0)\n",
    "    random_number_generator.shuffle(indices)\n",
    "\n",
    "    shuffled_text = []\n",
    "    shuffled_labels = []\n",
    "\n",
    "    # Iterate through the list of indices and add the original data\n",
    "    # from those shuffled indices\n",
    "    for index in indices:\n",
    "        shuffled_text.append(text[index])\n",
    "        shuffled_labels.append(label[index])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'text': shuffled_text,\n",
    "        'label': shuffled_labels,\n",
    "    })\n",
    "\n",
    "\n",
    "def get_train_test_split(data_frame: pd.DataFrame, test_size: float):\n",
    "    \"\"\"\n",
    "    Makes a stratified train test split.\n",
    "    This aims to preserve the distribution between classes.\n",
    "    \"\"\"\n",
    "    if not (1 >= test_size >= 0):\n",
    "        print('ERROR: test_size must be between 0 and 1')\n",
    "        return\n",
    "\n",
    "    data_frame = shuffle_data_frame(data_frame)\n",
    "\n",
    "    data_frame_length = len(data_frame)\n",
    "    train_size = 1 - test_size\n",
    "\n",
    "    nonhate_rows = data_frame[data_frame['label'] == 0] \n",
    "    nonhate_row_length = len(nonhate_rows)\n",
    "\n",
    "    nonhate_row_train_size = math.ceil(nonhate_row_length * train_size)\n",
    "\n",
    "    nonhate_row_train = nonhate_rows[0:nonhate_row_train_size]\n",
    "    nonhate_row_test = nonhate_rows[nonhate_row_train_size:nonhate_row_length]\n",
    "\n",
    "    assert(len(nonhate_row_train) + len(nonhate_row_test) == nonhate_row_length)\n",
    "\n",
    "    hate_rows = data_frame[data_frame['label'] == 1] \n",
    "    hate_row_length = len(hate_rows)\n",
    "\n",
    "    hate_row_train_size = math.ceil(hate_row_length * train_size)\n",
    "\n",
    "    hate_row_train = hate_rows[0:hate_row_train_size]\n",
    "    hate_row_test = hate_rows[hate_row_train_size:hate_row_length]\n",
    "\n",
    "    assert(len(hate_row_train) + len(hate_row_test) == hate_row_length)\n",
    "\n",
    "    combined_train = pd.concat([nonhate_row_train, hate_row_train])\n",
    "    combined_test = pd.concat([nonhate_row_test, hate_row_test])\n",
    "\n",
    "    shuffled_train = shuffle_data_frame(combined_train)\n",
    "    shuffled_test = shuffle_data_frame(combined_test)\n",
    "\n",
    "    return (\n",
    "        shuffled_train['text'],\n",
    "        shuffled_test['text'],\n",
    "        shuffled_train['label'],\n",
    "        shuffled_test['label'],\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(dataset, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[USERNAME] Palangga ka man sang mga taga Baco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who dafuq is Jose Montemayor Jr.???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Di na nakakatuwa yung mukha ni Mar Roxas sa TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>national elections. | via[USERNAME]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binay will be staring in a movie called \"The D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22764</th>\n",
       "      <td>\"Kala ko wala andito pala si Marcos.\"*pertaini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22765</th>\n",
       "      <td>sie ~ [USERNAME]Marcos Magnanakaw Marcos Dikta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22766</th>\n",
       "      <td>If Mar is BatMarBinay is Bane-ay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22767</th>\n",
       "      <td>to my moots im sorry in not sorry for flooding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>Uunlad tayo kay Binay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22769 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0       [USERNAME] Palangga ka man sang mga taga Baco...\n",
       "1                    Who dafuq is Jose Montemayor Jr.???\n",
       "2      Di na nakakatuwa yung mukha ni Mar Roxas sa TV...\n",
       "3                    national elections. | via[USERNAME]\n",
       "4      Binay will be staring in a movie called \"The D...\n",
       "...                                                  ...\n",
       "22764  \"Kala ko wala andito pala si Marcos.\"*pertaini...\n",
       "22765  sie ~ [USERNAME]Marcos Magnanakaw Marcos Dikta...\n",
       "22766                  If Mar is BatMarBinay is Bane-ay.\n",
       "22767  to my moots im sorry in not sorry for flooding...\n",
       "22768                              Uunlad tayo kay Binay\n",
       "\n",
       "[22769 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22765</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22767</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22769 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          0\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "...      ...\n",
       "22764      0\n",
       "22765      1\n",
       "22766      1\n",
       "22767      1\n",
       "22768      0\n",
       "\n",
       "[22769 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dataframe = pd.DataFrame(y_train, columns=['label'])\n",
    "y_train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        11292\n",
       "1        11477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dataframe.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bakit trending ang Only Binay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mare @ Cebu [USERNAME][USERNAME] Marcos Never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kahit anong gawin ko bakit di ko ma appreciate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oras na para tayo'y bumoto ng taong mag tataas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VP[USERNAME]is currently in Zamboanga Sibugay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>[USERNAME] Laban LeniAngat Buhay LahatLeni Kiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>Nagconcede ka man Maimarwala ka prinnagdala ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>Did You Know that former Philippine secretary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>Bakit nakakairita commercial ni Mar Roxas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>To Doc Willie Ong I'd like to believe you are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5692 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                        Bakit trending ang Only Binay?\n",
       "1     Mare @ Cebu [USERNAME][USERNAME] Marcos Never ...\n",
       "2     Kahit anong gawin ko bakit di ko ma appreciate...\n",
       "3     Oras na para tayo'y bumoto ng taong mag tataas...\n",
       "4     VP[USERNAME]is currently in Zamboanga Sibugay ...\n",
       "...                                                 ...\n",
       "5687    [USERNAME] Laban LeniAngat Buhay LahatLeni Kiko\n",
       "5688  Nagconcede ka man Maimarwala ka prinnagdala ka...\n",
       "5689  Did You Know that former Philippine secretary ...\n",
       "5690         Bakit nakakairita commercial ni Mar Roxas?\n",
       "5691  To Doc Willie Ong I'd like to believe you are ...\n",
       "\n",
       "[5692 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5692 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "5687      0\n",
       "5688      1\n",
       "5689      0\n",
       "5690      1\n",
       "5691      0\n",
       "\n",
       "[5692 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dataframe = pd.DataFrame(y_test, columns=['label'])\n",
    "y_test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        2823\n",
       "1        2869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dataframe.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1212: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;akin&#x27;,\n",
       "                                                                    &#x27;aking&#x27;,\n",
       "                                                                    &#x27;ako&#x27;,\n",
       "                                                                    &#x27;alin&#x27;,\n",
       "                                                                    &#x27;am&#x27;,\n",
       "                                                                    &#x27;amin&#x27;,\n",
       "                                                                    &#x27;aming&#x27;,\n",
       "                                                                    &#x27;ang&#x27;,\n",
       "                                                                    &#x27;ano&#x27;,\n",
       "                                                                    &#x27;anumang&#x27;,\n",
       "                                                                    &#x27;apat&#x27;,\n",
       "                                                                    &#x27;at&#x27;,\n",
       "                                                                    &#x27;atin&#x27;,\n",
       "                                                                    &#x27;ating&#x27;,\n",
       "                                                                    &#x27;ay&#x27;,\n",
       "                                                                    &#x27;bababa&#x27;,\n",
       "                                                                    &#x27;bago&#x27;,\n",
       "                                                                    &#x27;bakit&#x27;,\n",
       "                                                                    &#x27;bawat&#x27;,\n",
       "                                                                    &#x27;bilang&#x27;,\n",
       "                                                                    &#x27;dahil&#x27;,\n",
       "                                                                    &#x27;dalawa&#x27;,\n",
       "                                                                    &#x27;dapat&#x27;,\n",
       "                                                                    &#x27;din&#x27;,\n",
       "                                                                    &#x27;dito&#x27;,\n",
       "                                                                    &#x27;doon&#x27;,\n",
       "                                                                    &#x27;gagawin&#x27;,\n",
       "                                                                    &#x27;gayunman&#x27;,\n",
       "                                                                    &#x27;ginagawa&#x27;,\n",
       "                                                                    &#x27;ginawa&#x27;, ...])),\n",
       "                                       (&#x27;bayes&#x27;, BernoulliNB())]),\n",
       "             param_grid={&#x27;bayes__alpha&#x27;: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
       "                         &#x27;bayes__force_alpha&#x27;: [False, True]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;akin&#x27;,\n",
       "                                                                    &#x27;aking&#x27;,\n",
       "                                                                    &#x27;ako&#x27;,\n",
       "                                                                    &#x27;alin&#x27;,\n",
       "                                                                    &#x27;am&#x27;,\n",
       "                                                                    &#x27;amin&#x27;,\n",
       "                                                                    &#x27;aming&#x27;,\n",
       "                                                                    &#x27;ang&#x27;,\n",
       "                                                                    &#x27;ano&#x27;,\n",
       "                                                                    &#x27;anumang&#x27;,\n",
       "                                                                    &#x27;apat&#x27;,\n",
       "                                                                    &#x27;at&#x27;,\n",
       "                                                                    &#x27;atin&#x27;,\n",
       "                                                                    &#x27;ating&#x27;,\n",
       "                                                                    &#x27;ay&#x27;,\n",
       "                                                                    &#x27;bababa&#x27;,\n",
       "                                                                    &#x27;bago&#x27;,\n",
       "                                                                    &#x27;bakit&#x27;,\n",
       "                                                                    &#x27;bawat&#x27;,\n",
       "                                                                    &#x27;bilang&#x27;,\n",
       "                                                                    &#x27;dahil&#x27;,\n",
       "                                                                    &#x27;dalawa&#x27;,\n",
       "                                                                    &#x27;dapat&#x27;,\n",
       "                                                                    &#x27;din&#x27;,\n",
       "                                                                    &#x27;dito&#x27;,\n",
       "                                                                    &#x27;doon&#x27;,\n",
       "                                                                    &#x27;gagawin&#x27;,\n",
       "                                                                    &#x27;gayunman&#x27;,\n",
       "                                                                    &#x27;ginagawa&#x27;,\n",
       "                                                                    &#x27;ginawa&#x27;, ...])),\n",
       "                                       (&#x27;bayes&#x27;, BernoulliNB())]),\n",
       "             param_grid={&#x27;bayes__alpha&#x27;: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
       "                         &#x27;bayes__force_alpha&#x27;: [False, True]},\n",
       "             refit=&#x27;accuracy&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;akin&#x27;, &#x27;aking&#x27;, &#x27;ako&#x27;, &#x27;alin&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;amin&#x27;, &#x27;aming&#x27;, &#x27;ang&#x27;,\n",
       "                                             &#x27;ano&#x27;, &#x27;anumang&#x27;, &#x27;apat&#x27;, &#x27;at&#x27;,\n",
       "                                             &#x27;atin&#x27;, &#x27;ating&#x27;, &#x27;ay&#x27;, &#x27;bababa&#x27;,\n",
       "                                             &#x27;bago&#x27;, &#x27;bakit&#x27;, &#x27;bawat&#x27;, &#x27;bilang&#x27;,\n",
       "                                             &#x27;dahil&#x27;, &#x27;dalawa&#x27;, &#x27;dapat&#x27;, &#x27;din&#x27;,\n",
       "                                             &#x27;dito&#x27;, &#x27;doon&#x27;, &#x27;gagawin&#x27;,\n",
       "                                             &#x27;gayunman&#x27;, &#x27;ginagawa&#x27;, &#x27;ginawa&#x27;, ...])),\n",
       "                (&#x27;bayes&#x27;, BernoulliNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;akin&#x27;, &#x27;aking&#x27;, &#x27;ako&#x27;, &#x27;alin&#x27;, &#x27;am&#x27;, &#x27;amin&#x27;,\n",
       "                            &#x27;aming&#x27;, &#x27;ang&#x27;, &#x27;ano&#x27;, &#x27;anumang&#x27;, &#x27;apat&#x27;, &#x27;at&#x27;,\n",
       "                            &#x27;atin&#x27;, &#x27;ating&#x27;, &#x27;ay&#x27;, &#x27;bababa&#x27;, &#x27;bago&#x27;, &#x27;bakit&#x27;,\n",
       "                            &#x27;bawat&#x27;, &#x27;bilang&#x27;, &#x27;dahil&#x27;, &#x27;dalawa&#x27;, &#x27;dapat&#x27;,\n",
       "                            &#x27;din&#x27;, &#x27;dito&#x27;, &#x27;doon&#x27;, &#x27;gagawin&#x27;, &#x27;gayunman&#x27;,\n",
       "                            &#x27;ginagawa&#x27;, &#x27;ginawa&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words=['akin',\n",
       "                                                                    'aking',\n",
       "                                                                    'ako',\n",
       "                                                                    'alin',\n",
       "                                                                    'am',\n",
       "                                                                    'amin',\n",
       "                                                                    'aming',\n",
       "                                                                    'ang',\n",
       "                                                                    'ano',\n",
       "                                                                    'anumang',\n",
       "                                                                    'apat',\n",
       "                                                                    'at',\n",
       "                                                                    'atin',\n",
       "                                                                    'ating',\n",
       "                                                                    'ay',\n",
       "                                                                    'bababa',\n",
       "                                                                    'bago',\n",
       "                                                                    'bakit',\n",
       "                                                                    'bawat',\n",
       "                                                                    'bilang',\n",
       "                                                                    'dahil',\n",
       "                                                                    'dalawa',\n",
       "                                                                    'dapat',\n",
       "                                                                    'din',\n",
       "                                                                    'dito',\n",
       "                                                                    'doon',\n",
       "                                                                    'gagawin',\n",
       "                                                                    'gayunman',\n",
       "                                                                    'ginagawa',\n",
       "                                                                    'ginawa', ...])),\n",
       "                                       ('bayes', BernoulliNB())]),\n",
       "             param_grid={'bayes__alpha': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
       "                         'bayes__force_alpha': [False, True]},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validator = StratifiedKFold(n_splits=5)\n",
    "\n",
    "nb_grid_search = GridSearchCV(\n",
    "  estimator=Bayes.BayesPipeline,\n",
    "  param_grid={\n",
    "    'bayes__alpha': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    'bayes__force_alpha': [False, True],\n",
    "  },\n",
    "  scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "  refit='accuracy',\n",
    "  cv=cross_validator,\n",
    ")\n",
    "\n",
    "nb_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.51526742, 0.48221383, 0.56515198, 0.54316058, 0.54379282,\n",
       "        0.54369125, 0.56222711, 0.54059415, 0.53951893, 0.54264879,\n",
       "        0.48067026, 0.49868836]),\n",
       " 'std_fit_time': array([0.03347867, 0.00735723, 0.06698537, 0.02326728, 0.00953409,\n",
       "        0.00571984, 0.0316702 , 0.00416228, 0.00741439, 0.01542321,\n",
       "        0.0023286 , 0.00687449]),\n",
       " 'mean_score_time': array([0.1149817 , 0.11269097, 0.14183369, 0.12423892, 0.12758465,\n",
       "        0.12492566, 0.12986035, 0.1293364 , 0.12791314, 0.12741041,\n",
       "        0.11581264, 0.11706367]),\n",
       " 'std_score_time': array([0.00405036, 0.00363129, 0.03198623, 0.0051025 , 0.00264587,\n",
       "        0.0022377 , 0.004564  , 0.0022927 , 0.00440311, 0.00170536,\n",
       "        0.00221504, 0.00355707]),\n",
       " 'param_bayes__alpha': masked_array(data=[0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6, 0.8, 0.8, 1.0,\n",
       "                    1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_bayes__force_alpha': masked_array(data=[False, True, False, True, False, True, False, True,\n",
       "                    False, True, False, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'bayes__alpha': 0.0, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.0, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.2, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.2, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.4, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.4, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.6, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.6, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 0.8, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 0.8, 'bayes__force_alpha': True},\n",
       "  {'bayes__alpha': 1.0, 'bayes__force_alpha': False},\n",
       "  {'bayes__alpha': 1.0, 'bayes__force_alpha': True}],\n",
       " 'split0_test_accuracy': array([0.76921388, 0.73429952, 0.80610452, 0.80610452, 0.80764163,\n",
       "        0.80764163, 0.8083004 , 0.8083004 , 0.80917874, 0.80917874,\n",
       "        0.80851998, 0.80851998]),\n",
       " 'split1_test_accuracy': array([0.77140975, 0.75054897, 0.81906017, 0.81906017, 0.81708388,\n",
       "        0.81708388, 0.81554677, 0.81554677, 0.81444884, 0.81444884,\n",
       "        0.81444884, 0.81444884]),\n",
       " 'split2_test_accuracy': array([0.77382521, 0.74462011, 0.81642512, 0.81642512, 0.81774264,\n",
       "        0.81774264, 0.81774264, 0.81774264, 0.81642512, 0.81642512,\n",
       "        0.81466842, 0.81466842]),\n",
       " 'split3_test_accuracy': array([0.77470356, 0.74264383, 0.81818182, 0.81818182, 0.82103645,\n",
       "        0.82103645, 0.8236715 , 0.8236715 , 0.82345191, 0.82345191,\n",
       "        0.82169521, 0.82169521]),\n",
       " 'split4_test_accuracy': array([0.77970569, 0.75093345, 0.81506699, 0.81506699, 0.81594553,\n",
       "        0.81594553, 0.81616517, 0.81616517, 0.81550626, 0.81550626,\n",
       "        0.81309027, 0.81309027]),\n",
       " 'mean_test_accuracy': array([0.77377162, 0.74460918, 0.81496772, 0.81496772, 0.81589003,\n",
       "        0.81589003, 0.81628529, 0.81628529, 0.81580217, 0.81580217,\n",
       "        0.81448455, 0.81448455]),\n",
       " 'std_test_accuracy': array([0.00353372, 0.00608982, 0.0046426 , 0.0046426 , 0.0044583 ,\n",
       "        0.0044583 , 0.00491932, 0.00491932, 0.00457592, 0.00457592,\n",
       "        0.00423199, 0.00423199]),\n",
       " 'rank_test_accuracy': array([11, 12,  7,  7,  3,  3,  1,  1,  5,  5,  9,  9], dtype=int32),\n",
       " 'split0_test_precision': array([0.74721781, 0.73867136, 0.77428127, 0.77428127, 0.77553398,\n",
       "        0.77553398, 0.77643857, 0.77643857, 0.77700078, 0.77700078,\n",
       "        0.7754549 , 0.7754549 ]),\n",
       " 'split1_test_precision': array([0.75059952, 0.76068376, 0.79244533, 0.79244533, 0.79030977,\n",
       "        0.79030977, 0.78857596, 0.78857596, 0.78701504, 0.78701504,\n",
       "        0.78656126, 0.78656126]),\n",
       " 'split2_test_precision': array([0.7492126 , 0.75121951, 0.78316524, 0.78316524, 0.78477078,\n",
       "        0.78477078, 0.78410853, 0.78410853, 0.78294574, 0.78294574,\n",
       "        0.77987664, 0.77987664]),\n",
       " 'split3_test_precision': array([0.75      , 0.74823322, 0.78560311, 0.78560311, 0.78757282,\n",
       "        0.78757282, 0.79012825, 0.79012825, 0.78937161, 0.78937161,\n",
       "        0.78670788, 0.78670788]),\n",
       " 'split4_test_precision': array([0.7596463 , 0.75926753, 0.78546169, 0.78546169, 0.7844592 ,\n",
       "        0.7844592 , 0.78476563, 0.78476563, 0.78384705, 0.78384705,\n",
       "        0.7807154 , 0.7807154 ]),\n",
       " 'mean_test_precision': array([0.75133525, 0.75161508, 0.78419133, 0.78419133, 0.78452931,\n",
       "        0.78452931, 0.78480339, 0.78480339, 0.78403604, 0.78403604,\n",
       "        0.78186322, 0.78186322]),\n",
       " 'std_test_precision': array([0.00430945, 0.00799918, 0.00584803, 0.00584803, 0.00497304,\n",
       "        0.00497304, 0.00475481, 0.00475481, 0.00419672, 0.00419672,\n",
       "        0.00428656, 0.00428656]),\n",
       " 'rank_test_precision': array([12, 11,  5,  5,  3,  3,  1,  1,  7,  7,  9,  9], dtype=int32),\n",
       " 'split0_test_recall': array([0.81917211, 0.73159041, 0.86840959, 0.86840959, 0.87015251,\n",
       "        0.87015251, 0.87015251, 0.87015251, 0.87145969, 0.87145969,\n",
       "        0.87276688, 0.87276688]),\n",
       " 'split1_test_recall': array([0.81830065, 0.73681917, 0.86840959, 0.86840959, 0.8671024 ,\n",
       "        0.8671024 , 0.86623094, 0.86623094, 0.86623094, 0.86623094,\n",
       "        0.8671024 , 0.8671024 ]),\n",
       " 'split2_test_recall': array([0.82883275, 0.73780488, 0.8793554 , 0.8793554 , 0.87979094,\n",
       "        0.87979094, 0.88109756, 0.88109756, 0.87979094, 0.87979094,\n",
       "        0.88109756, 0.88109756]),\n",
       " 'split3_test_recall': array([0.82970383, 0.73780488, 0.8793554 , 0.8793554 , 0.88327526,\n",
       "        0.88327526, 0.88545296, 0.88545296, 0.88632404, 0.88632404,\n",
       "        0.88675958, 0.88675958]),\n",
       " 'split4_test_recall': array([0.82352941, 0.74074074, 0.87102397, 0.87102397, 0.87538126,\n",
       "        0.87538126, 0.87538126, 0.87538126, 0.87538126, 0.87538126,\n",
       "        0.87494553, 0.87494553]),\n",
       " 'mean_test_recall': array([0.82390775, 0.73695202, 0.87331079, 0.87331079, 0.87514047,\n",
       "        0.87514047, 0.87566305, 0.87566305, 0.87583738, 0.87583738,\n",
       "        0.87653439, 0.87653439]),\n",
       " 'std_test_recall': array([0.00472989, 0.00298575, 0.00502688, 0.00502688, 0.00595567,\n",
       "        0.00595567, 0.00699695, 0.00699695, 0.00688849, 0.00688849,\n",
       "        0.00679791, 0.00679791]),\n",
       " 'rank_test_recall': array([11, 12,  9,  9,  7,  7,  5,  5,  3,  3,  1,  1], dtype=int32),\n",
       " 'split0_test_f1': array([0.7815423 , 0.73511384, 0.81864859, 0.81864859, 0.8201232 ,\n",
       "        0.8201232 , 0.82062872, 0.82062872, 0.82152393, 0.82152393,\n",
       "        0.82123821, 0.82123821]),\n",
       " 'split1_test_f1': array([0.78298937, 0.74856131, 0.82869023, 0.82869023, 0.82692707,\n",
       "        0.82692707, 0.8255814 , 0.8255814 , 0.82472516, 0.82472516,\n",
       "        0.82487047, 0.82487047]),\n",
       " 'split2_test_f1': array([0.78701406, 0.74445177, 0.82847764, 0.82847764, 0.82956879,\n",
       "        0.82956879, 0.82977851, 0.82977851, 0.82854799, 0.82854799,\n",
       "        0.82740286, 0.82740286]),\n",
       " 'split3_test_f1': array([0.78784119, 0.74298246, 0.8298397 , 0.8298397 , 0.83268323,\n",
       "        0.83268323, 0.83507907, 0.83507907, 0.83504309, 0.83504309,\n",
       "        0.83374283, 0.83374283]),\n",
       " 'split4_test_f1': array([0.79029898, 0.74988972, 0.82603306, 0.82603306, 0.82742998,\n",
       "        0.82742998, 0.82760041, 0.82760041, 0.82708934, 0.82708934,\n",
       "        0.82514896, 0.82514896]),\n",
       " 'mean_test_f1': array([0.78593718, 0.74419982, 0.82633784, 0.82633784, 0.82734646,\n",
       "        0.82734646, 0.82773362, 0.82773362, 0.8273859 , 0.8273859 ,\n",
       "        0.82648067, 0.82648067]),\n",
       " 'std_test_f1': array([0.00321915, 0.00520573, 0.00403963, 0.00403963, 0.00414194,\n",
       "        0.00414194, 0.00475955, 0.00475955, 0.00450584, 0.00450584,\n",
       "        0.00413374, 0.00413374]),\n",
       " 'rank_test_f1': array([11, 12,  9,  9,  5,  5,  1,  1,  3,  3,  7,  7], dtype=int32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bayes__alpha': 0.6, 'bayes__force_alpha': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Training Function\n",
    "\n",
    "The `train_ensemble` function initializes and trains the ensemble model using the provided training data. It takes the training features and labels as input, along with the ensemble model instance, and returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(X_train: list, y_train: list, ensemble):\n",
    "    seed_random_number_generators()  # Ensure reproducibility\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    print(\"Ensemble model trained.\")\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation Function\n",
    "\n",
    "The `get_prediction_results` function uses the trained ensemble model to make predictions on the test set and then evaluates these predictions by calculating the accuracy, recall, precision, and F1-score. It returns these metrics for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_results(X_test: list, y_test: list, ensemble):\n",
    "    with torch.inference_mode():\n",
    "        y_pred = ensemble.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy}\\nRecall: {recall}\\nPrecision: {precision}\\nF1-score: {f1}\")\n",
    "        return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Function\n",
    "\n",
    "The `save_trained_model` function saves the trained ensemble model to disk using the joblib library. This allows for the model to be reloaded and used for predictions without the need for retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(ensemble, filename=\"Ensemble\"):\n",
    "    import joblib\n",
    "    joblib.dump(ensemble, f'{filename}.pkl', compress=True)\n",
    "    print(f\"Ensemble model saved to {filename}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Workflow\n",
    "\n",
    "This cell combines all the previous steps to execute the workflow. It includes reading the dataset, splitting it into training and testing sets, selecting the ensemble method, training the model, evaluating its performance, and saving the trained model. Replace 'your_dataset.csv' with the path to your dataset and choose an appropriate ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'datasets/datasetall.csv'\n",
    "ENSEMBLE_METHOD = 'hard'\n",
    "\n",
    "# Read data and prepare train-test split\n",
    "data_frame = read_csv_file(FILENAME)\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(data_frame)\n",
    "\n",
    "# Initialize and train the ensemble\n",
    "ensemble_methods = {\n",
    "    'hard': Ensemble.HardVotingEnsemble(),\n",
    "    'soft': Ensemble.SoftVotingEnsemble(),\n",
    "    'stacking': Ensemble.StackingEnsemble(),\n",
    "}\n",
    "ensemble = train_ensemble(X_train, y_train, ensemble_methods[ENSEMBLE_METHOD])\n",
    "\n",
    "# Evaluate the trained ensemble and display results\n",
    "accuracy, recall, precision, f1 = get_prediction_results(X_test, y_test, ensemble)\n",
    "\n",
    "# Save the trained model\n",
    "save_trained_model(ensemble, f'ensemble-{ENSEMBLE_METHOD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "To better visualize the evaluation results, this cell creates a pandas DataFrame to display the accuracy, recall, precision, and F1-score in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'F1-Score'],\n",
    "    'Value': [accuracy, recall, precision, f1]\n",
    "})\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
