{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30208/4062262799.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'tl_calamancy_md' (0.1.0) specifies an under-constrained spaCy version requirement: >=3.5.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n",
      "/home/nate/miniconda3/lib/python3.9/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'tl_calamancy_lg' (0.1.0) specifies an under-constrained spaCy version requirement: >=3.5.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src import Utils, LSTM\n",
    "from skorch.dataset import ValidSplit\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = 'model_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file read successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binay: Patuloy ang kahirapan dahil sa maling p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait so ur telling me Let Leni Lead mo pero NY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[USERNAME]wish this is just a nightmare that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc willie ong and isko sabunutan po</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28456</th>\n",
       "      <td>Bisaya, Probinsyano/a, mostly Bisaya = katulong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>Amnesia. In my whole life wala pa ako nakasala...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>Kontrabida na ilang beses na tinalo at obvious...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>Yung antagonist laging kailangang sobrang sama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>May nabaril or nasaksak na pero 'di pa tatawag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Binay: Patuloy ang kahirapan dahil sa maling p...      0\n",
       "1      SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...      0\n",
       "2      wait so ur telling me Let Leni Lead mo pero NY...      1\n",
       "3       [USERNAME]wish this is just a nightmare that ...      0\n",
       "4                   doc willie ong and isko sabunutan po      0\n",
       "...                                                  ...    ...\n",
       "28456    Bisaya, Probinsyano/a, mostly Bisaya = katulong      1\n",
       "28457  Amnesia. In my whole life wala pa ako nakasala...      1\n",
       "28458  Kontrabida na ilang beses na tinalo at obvious...      1\n",
       "28459  Yung antagonist laging kailangang sobrang sama...      1\n",
       "28460  May nabaril or nasaksak na pero 'di pa tatawag...      1\n",
       "\n",
       "[28461 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Utils.read_csv_file('datasets/datasetall.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number generators seeded.\n"
     ]
    }
   ],
   "source": [
    "Utils.seed_random_number_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = Utils.get_train_test_split(dataset, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        pag hindi nanalo si Norberto Gonzales pwede ba...\n",
       "1        Ngayon lang ako super proud sa PRESIDENTE na i...\n",
       "2        JUST SAW SOMEONE CALL BBM BLENGBLONG HAHAHAHAH...\n",
       "3        Rep. Binay on her leadership style: I am very ...\n",
       "4        Liwanag o dilim? May oras pa. Kakampink Leni L...\n",
       "                               ...                        \n",
       "25611    \"Kala ko wala andito pala si Marcos.\"*pertaini...\n",
       "25612    cathy [USERNAME] Dec [USERNAME] parang tanga i...\n",
       "25613                             Nognog+pandak= BINAY ftw\n",
       "25614    BINAY:Did your enormous wealth all come from y...\n",
       "25615                                Uunlad tayo kay Binay\n",
       "Name: text, Length: 25616, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "25611    0\n",
       "25612    1\n",
       "25613    1\n",
       "25614    1\n",
       "25615    0\n",
       "Name: label, Length: 25616, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       PRESIDENTE DUTERTE I'm sure in last debateitao...\n",
       "1       CHANGE IS BADLY NEEDED No To Mar Roxas2016 Dut...\n",
       "2                                One Pink March Leni Kiko\n",
       "3                               see youuu later Leni Kiko\n",
       "4       [USERNAME] Nangyari na yan eh pero kahit anong...\n",
       "                              ...                        \n",
       "2840    kaya siguro umabot ng milyon yung boto kay MAR...\n",
       "2841    Dedicating my 21km run for my chosen Presand V...\n",
       "2842    Bakit si Mar? Because DuterteGrace Poe and VP ...\n",
       "2843    patalo po ung patalastas ni Mar Roxas....malas...\n",
       "2844    Kapihan with Sen. Bongbong Marcos startshe say...\n",
       "Name: text, Length: 2845, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2840    1\n",
       "2841    0\n",
       "2842    1\n",
       "2843    1\n",
       "2844    0\n",
       "Name: label, Length: 2845, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [100, 200, 300]\n",
    "learning_rate = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "batch_size = [32, 64, 128]\n",
    "hidden_size = [100, 200, 300, 400]\n",
    "num_layers = [1, 2, 3]\n",
    "\n",
    "train_lstm = LSTM.LstmPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm.set_params(\n",
    "  lstm__train_split=None,\n",
    "  lstm__module__hidden_size=250,\n",
    "  lstm__module__num_layers=1,\n",
    "  lstm__module__output_size=1,\n",
    "  lstm__optimizer__lr=0.015,\n",
    "  lstm__max_epochs=30,\n",
    "  lstm__batch_size=32,\n",
    "  lstm__criterion=BCEWithLogitsLoss,\n",
    ")\n",
    "\n",
    "train_lstm['lstm'].callbacks[0].dirname = f'{MODEL_FOLDER}/train_lstm'\n",
    "train_lstm['lstm'].callbacks[0].monitor = 'train_loss_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tokenizer&#x27;, CalamancyTokenizer()),\n",
       "                (&#x27;lstm&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;src.LSTM.LstmModel&#x27;&gt;,\n",
       "  module__hidden_size=250,\n",
       "  module__num_layers=1,\n",
       "  module__output_size=1,\n",
       "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tokenizer&#x27;, CalamancyTokenizer()),\n",
       "                (&#x27;lstm&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;src.LSTM.LstmModel&#x27;&gt;,\n",
       "  module__hidden_size=250,\n",
       "  module__num_layers=1,\n",
       "  module__output_size=1,\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalamancyTokenizer</label><div class=\"sk-toggleable__content\"><pre>CalamancyTokenizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;src.LSTM.LstmModel&#x27;&gt;,\n",
       "  module__hidden_size=250,\n",
       "  module__num_layers=1,\n",
       "  module__output_size=1,\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tokenizer', CalamancyTokenizer()),\n",
       "                ('lstm',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class 'src.LSTM.LstmModel'>,\n",
       "  module__hidden_size=250,\n",
       "  module__num_layers=1,\n",
       "  module__output_size=1,\n",
       "))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008330345153808594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 801,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b13970a5d8424bbb0c7c5be20fda8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/lstm_train.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/78F8812CF880EA28/Github/Hate-Speech-Detection/lstm_train.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_lstm\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/classifier.py:165\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1319\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[0;32m-> 1319\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1320\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1278\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1277\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1279\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1190\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m   1188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_epoch_begin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single_epoch(iterator_train, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1191\u001b[0m                           step_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1226\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_batch_begin\u001b[39m\u001b[39m\"\u001b[39m, batch\u001b[39m=\u001b[39mbatch, training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m-> 1226\u001b[0m     step \u001b[39m=\u001b[39m step_fn(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mrecord_batch(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, step[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[1;32m   1228\u001b[0m     batch_size \u001b[39m=\u001b[39m (get_len(batch[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[1;32m   1229\u001b[0m                   \u001b[39melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1105\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[1;32m   1103\u001b[0m     \u001b[39mreturn\u001b[39;00m step[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_optimizer(step_fn)\n\u001b[1;32m   1106\u001b[0m \u001b[39mreturn\u001b[39;00m step_accumulator\u001b[39m.\u001b[39mget_step()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1060\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[0;34m(self, step_fn)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m   1059\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(step_fn)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/adam.py:146\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 146\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    149\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1094\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_fn\u001b[39m():\n\u001b[1;32m   1093\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_optimizer()\n\u001b[0;32m-> 1094\u001b[0m     step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step_single(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1095\u001b[0m     step_accumulator\u001b[39m.\u001b[39mstore_step(step)\n\u001b[1;32m   1097\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1098\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1099\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1100\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1101\u001b[0m         training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1102\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:994\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m    992\u001b[0m Xi, yi \u001b[39m=\u001b[39m unpack_data(batch)\n\u001b[1;32m    993\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(Xi, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 994\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loss(y_pred, yi, X\u001b[39m=\u001b[39;49mXi, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    995\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    996\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    997\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: loss,\n\u001b[1;32m    998\u001b[0m     \u001b[39m'\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m'\u001b[39m: y_pred,\n\u001b[1;32m    999\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/classifier.py:150\u001b[0m, in \u001b[0;36mNeuralNetClassifier.get_loss\u001b[0;34m(self, y_pred, y_true, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     eps \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfinfo(y_pred\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39meps\n\u001b[1;32m    149\u001b[0m     y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(y_pred \u001b[39m+\u001b[39m eps)\n\u001b[0;32m--> 150\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_loss(y_pred, y_true, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skorch/net.py:1665\u001b[0m, in \u001b[0;36mNeuralNet.get_loss\u001b[0;34m(self, y_pred, y_true, X, training)\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[39m\"\"\"Return the loss for this batch.\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m \n\u001b[1;32m   1638\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1662\u001b[0m \n\u001b[1;32m   1663\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m y_true \u001b[39m=\u001b[39m to_tensor(y_true, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1665\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion_(y_pred, y_true)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:726\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    725\u001b[0m     \u001b[39mprint\u001b[39m(target\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m--> 726\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39;49m, target,\n\u001b[1;32m    727\u001b[0m                                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    728\u001b[0m                                               pos_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_weight,\n\u001b[1;32m    729\u001b[0m                                               reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:3197\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()):\n\u001b[0;32m-> 3197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTarget size (\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m) must be the same as input size (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[39minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 1]))"
     ]
    }
   ],
   "source": [
    "train_lstm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8073813708260106\n",
      "Recall: 0.8835425383542538\n",
      "Precision: 0.7688106796116505\n",
      "F1-score: 0.8221933809214796\n"
     ]
    }
   ],
   "source": [
    "accuracy, recall, precision, f1 = Utils.get_prediction_results(\n",
    "  X_test,\n",
    "  y_test,\n",
    "  train_lstm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model saved to Pipeline(steps=[('tokenizer', CalamancyTokenizer()),\n",
      "                ('lstm',\n",
      "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
      "  module_=LstmModel(\n",
      "    (lstm): LSTM(200, 250, batch_first=True)\n",
      "    (fc): Linear(in_features=250, out_features=2, bias=True)\n",
      "  ),\n",
      "))]).pkl\n"
     ]
    }
   ],
   "source": [
    "Utils.save_trained_model(train_lstm, f\"{MODEL_FOLDER}/LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data_frame = pd.DataFrame(\n",
    "    train_lstm['lstm'].history\n",
    ").set_index('epoch')\n",
    "history_data_frame.to_csv(f'{MODEL_FOLDER}/lstm_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batches</th>\n",
       "      <th>train_batch_count</th>\n",
       "      <th>dur</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_loss_best</th>\n",
       "      <th>event_cp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'train_loss': 0.6997741460800171, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>6.049480</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'train_loss': 0.4156422019004822, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.568352</td>\n",
       "      <td>0.437506</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'train_loss': 0.4834706783294678, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.483173</td>\n",
       "      <td>0.419422</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'train_loss': 0.45560380816459656, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.481784</td>\n",
       "      <td>0.410213</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'train_loss': 0.43198901414871216, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.544000</td>\n",
       "      <td>0.407133</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'train_loss': 0.4549972414970398, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.393241</td>\n",
       "      <td>0.402168</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'train_loss': 0.44017869234085083, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.469340</td>\n",
       "      <td>0.395549</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[{'train_loss': 0.4254568815231323, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.651236</td>\n",
       "      <td>0.387816</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[{'train_loss': 0.4351150691509247, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.423012</td>\n",
       "      <td>0.384601</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[{'train_loss': 0.40971314907073975, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.667397</td>\n",
       "      <td>0.383889</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[{'train_loss': 0.4092741012573242, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.482280</td>\n",
       "      <td>0.384306</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[{'train_loss': 0.4727783799171448, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.431602</td>\n",
       "      <td>0.388840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[{'train_loss': 0.45592331886291504, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.462765</td>\n",
       "      <td>0.401849</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[{'train_loss': 0.4543054401874542, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.395766</td>\n",
       "      <td>0.390924</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[{'train_loss': 0.40055471658706665, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.436109</td>\n",
       "      <td>0.387394</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[{'train_loss': 0.3841395676136017, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.918426</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[{'train_loss': 0.4024539589881897, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.813650</td>\n",
       "      <td>0.381994</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[{'train_loss': 0.40165823698043823, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.443073</td>\n",
       "      <td>0.380914</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[{'train_loss': 0.4155670404434204, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.435102</td>\n",
       "      <td>0.380698</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[{'train_loss': 0.4002845883369446, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.522174</td>\n",
       "      <td>0.380507</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[{'train_loss': 0.3864077627658844, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.466747</td>\n",
       "      <td>0.379088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[{'train_loss': 0.360564261674881, 'train_batc...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.722328</td>\n",
       "      <td>0.379799</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[{'train_loss': 0.3499508798122406, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.487054</td>\n",
       "      <td>0.378184</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[{'train_loss': 0.3469657301902771, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.448048</td>\n",
       "      <td>0.377604</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[{'train_loss': 0.3608141541481018, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.430021</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[{'train_loss': 0.34804725646972656, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>6.224376</td>\n",
       "      <td>0.374561</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[{'train_loss': 0.34344103932380676, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.969081</td>\n",
       "      <td>0.373130</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[{'train_loss': 0.32879120111465454, 'train_ba...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.732788</td>\n",
       "      <td>0.370934</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[{'train_loss': 0.3421878218650818, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.551231</td>\n",
       "      <td>0.373884</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[{'train_loss': 0.3585273027420044, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.467388</td>\n",
       "      <td>0.370935</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[{'train_loss': 0.3379594087600708, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.471120</td>\n",
       "      <td>0.370090</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[{'train_loss': 0.3393729031085968, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.539190</td>\n",
       "      <td>0.369419</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[{'train_loss': 0.3418298065662384, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.484113</td>\n",
       "      <td>0.367376</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[{'train_loss': 0.333863765001297, 'train_batc...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.534157</td>\n",
       "      <td>0.365118</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[{'train_loss': 0.3437289595603943, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.570180</td>\n",
       "      <td>0.364548</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[{'train_loss': 0.3647664487361908, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.415571</td>\n",
       "      <td>0.364561</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[{'train_loss': 0.3505314290523529, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.674273</td>\n",
       "      <td>0.364179</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[{'train_loss': 0.3604566752910614, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.883387</td>\n",
       "      <td>0.362273</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[{'train_loss': 0.3543098270893097, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.521063</td>\n",
       "      <td>0.362840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[{'train_loss': 0.3621722161769867, 'train_bat...</td>\n",
       "      <td>801</td>\n",
       "      <td>5.470967</td>\n",
       "      <td>0.361463</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 batches  train_batch_count  \\\n",
       "epoch                                                                         \n",
       "1      [{'train_loss': 0.6997741460800171, 'train_bat...                801   \n",
       "2      [{'train_loss': 0.4156422019004822, 'train_bat...                801   \n",
       "3      [{'train_loss': 0.4834706783294678, 'train_bat...                801   \n",
       "4      [{'train_loss': 0.45560380816459656, 'train_ba...                801   \n",
       "5      [{'train_loss': 0.43198901414871216, 'train_ba...                801   \n",
       "6      [{'train_loss': 0.4549972414970398, 'train_bat...                801   \n",
       "7      [{'train_loss': 0.44017869234085083, 'train_ba...                801   \n",
       "8      [{'train_loss': 0.4254568815231323, 'train_bat...                801   \n",
       "9      [{'train_loss': 0.4351150691509247, 'train_bat...                801   \n",
       "10     [{'train_loss': 0.40971314907073975, 'train_ba...                801   \n",
       "11     [{'train_loss': 0.4092741012573242, 'train_bat...                801   \n",
       "12     [{'train_loss': 0.4727783799171448, 'train_bat...                801   \n",
       "13     [{'train_loss': 0.45592331886291504, 'train_ba...                801   \n",
       "14     [{'train_loss': 0.4543054401874542, 'train_bat...                801   \n",
       "15     [{'train_loss': 0.40055471658706665, 'train_ba...                801   \n",
       "16     [{'train_loss': 0.3841395676136017, 'train_bat...                801   \n",
       "17     [{'train_loss': 0.4024539589881897, 'train_bat...                801   \n",
       "18     [{'train_loss': 0.40165823698043823, 'train_ba...                801   \n",
       "19     [{'train_loss': 0.4155670404434204, 'train_bat...                801   \n",
       "20     [{'train_loss': 0.4002845883369446, 'train_bat...                801   \n",
       "21     [{'train_loss': 0.3864077627658844, 'train_bat...                801   \n",
       "22     [{'train_loss': 0.360564261674881, 'train_batc...                801   \n",
       "23     [{'train_loss': 0.3499508798122406, 'train_bat...                801   \n",
       "24     [{'train_loss': 0.3469657301902771, 'train_bat...                801   \n",
       "25     [{'train_loss': 0.3608141541481018, 'train_bat...                801   \n",
       "26     [{'train_loss': 0.34804725646972656, 'train_ba...                801   \n",
       "27     [{'train_loss': 0.34344103932380676, 'train_ba...                801   \n",
       "28     [{'train_loss': 0.32879120111465454, 'train_ba...                801   \n",
       "29     [{'train_loss': 0.3421878218650818, 'train_bat...                801   \n",
       "30     [{'train_loss': 0.3585273027420044, 'train_bat...                801   \n",
       "31     [{'train_loss': 0.3379594087600708, 'train_bat...                801   \n",
       "32     [{'train_loss': 0.3393729031085968, 'train_bat...                801   \n",
       "33     [{'train_loss': 0.3418298065662384, 'train_bat...                801   \n",
       "34     [{'train_loss': 0.333863765001297, 'train_batc...                801   \n",
       "35     [{'train_loss': 0.3437289595603943, 'train_bat...                801   \n",
       "36     [{'train_loss': 0.3647664487361908, 'train_bat...                801   \n",
       "37     [{'train_loss': 0.3505314290523529, 'train_bat...                801   \n",
       "38     [{'train_loss': 0.3604566752910614, 'train_bat...                801   \n",
       "39     [{'train_loss': 0.3543098270893097, 'train_bat...                801   \n",
       "40     [{'train_loss': 0.3621722161769867, 'train_bat...                801   \n",
       "\n",
       "            dur  train_loss  train_loss_best  event_cp  \n",
       "epoch                                                   \n",
       "1      6.049480    0.475823             True      True  \n",
       "2      5.568352    0.437506             True      True  \n",
       "3      5.483173    0.419422             True      True  \n",
       "4      5.481784    0.410213             True      True  \n",
       "5      5.544000    0.407133             True      True  \n",
       "6      5.393241    0.402168             True      True  \n",
       "7      5.469340    0.395549             True      True  \n",
       "8      5.651236    0.387816             True      True  \n",
       "9      5.423012    0.384601             True      True  \n",
       "10     5.667397    0.383889             True      True  \n",
       "11     5.482280    0.384306            False     False  \n",
       "12     5.431602    0.388840            False     False  \n",
       "13     5.462765    0.401849            False     False  \n",
       "14     5.395766    0.390924            False     False  \n",
       "15     5.436109    0.387394            False     False  \n",
       "16     5.918426    0.380990             True      True  \n",
       "17     5.813650    0.381994            False     False  \n",
       "18     5.443073    0.380914             True      True  \n",
       "19     5.435102    0.380698             True      True  \n",
       "20     5.522174    0.380507             True      True  \n",
       "21     5.466747    0.379088             True      True  \n",
       "22     5.722328    0.379799            False     False  \n",
       "23     5.487054    0.378184             True      True  \n",
       "24     5.448048    0.377604             True      True  \n",
       "25     5.430021    0.377419             True      True  \n",
       "26     6.224376    0.374561             True      True  \n",
       "27     5.969081    0.373130             True      True  \n",
       "28     5.732788    0.370934             True      True  \n",
       "29     5.551231    0.373884            False     False  \n",
       "30     5.467388    0.370935            False     False  \n",
       "31     5.471120    0.370090             True      True  \n",
       "32     5.539190    0.369419             True      True  \n",
       "33     5.484113    0.367376             True      True  \n",
       "34     5.534157    0.365118             True      True  \n",
       "35     5.570180    0.364548             True      True  \n",
       "36     5.415571    0.364561            False     False  \n",
       "37     5.674273    0.364179             True      True  \n",
       "38     5.883387    0.362273             True      True  \n",
       "39     5.521063    0.362840            False     False  \n",
       "40     5.470967    0.361463             True      True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data_frame = pd.DataFrame([{\n",
    "  'accuracy': accuracy,\n",
    "  'recall': recall,\n",
    "  'precision': precision,\n",
    "  'f1': f1,\n",
    "}])\n",
    "metrics_data_frame.to_csv(f'{MODEL_FOLDER}/lstm_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
