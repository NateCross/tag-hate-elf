{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Collection and Visualization\n",
    "\n",
    "This notebook is designed to collect comments from a specified subreddit using Reddit's API through PRAW (Python Reddit API Wrapper). It filters out comments based on predefined blacklists and visualizes the data for insights.\n",
    "\n",
    "## Features:\n",
    "- Fetch comments from a chosen subreddit and filter ('top', 'hot', 'controversial').\n",
    "- Exclude comments from blacklisted authors and comments with specific content (e.g., '[deleted]', '[removed]').\n",
    "- Visualize the collected data for insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Before running this notebook, ensure you have installed the necessary Python packages: `praw`, `pandas`, and any others required for your specific environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import TypedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PRAW core exceptions\n",
    "import prawcore\n",
    "from prawcore.exceptions import Redirect, RequestException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the target subreddit, and other configurations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subreddit configuration\n",
    "SUBREDDIT_NAME = 'Philippines'\n",
    "SUBREDDIT_FILTER = 'hot'\n",
    "LIMIT = 11  # Adjust as needed, up to a maximum of 1000 due to Reddit's API limit\n",
    "\n",
    "# Data filtering criteria\n",
    "AUTHOR_BLACKLIST = ['AutoModerator']\n",
    "BODY_BLACKLIST = ['[deleted]', '[removed]']\n",
    "\n",
    "# Define options for subreddit fetching, mainly the limit\n",
    "OPTIONS = {\n",
    "    'limit': LIMIT,\n",
    "}\n",
    "\n",
    "# Constants for file naming\n",
    "CURRENT_DATETIME = datetime.today().strftime(\"%Y%m%d-%H%M%S\")   # Current date and time for filename\n",
    "FILENAME = f'data-{SUBREDDIT_NAME}-{CURRENT_DATETIME}-{SUBREDDIT_FILTER}.csv'  # Filename format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRow Definition\n",
    "\n",
    "Define a structure for the data rows to ensure consistent data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRow(TypedDict):\n",
    "    id: str\n",
    "    author: str\n",
    "    body: str\n",
    "    score: int\n",
    "    subreddit: str\n",
    "    timestamp: str\n",
    "    submission_name: str\n",
    "    submission_text: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection & Execution\n",
    "\n",
    "In this section, we will execute the data collection process which involves connecting to the Reddit API through PRAW (Python Reddit API Wrapper), fetching comments from the specified subreddit, and filtering the data based on predefined criteria. The final dataset will then be prepared for analysis and saved to a CSV file for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file for reddit secrets\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PRAW Reddit instance with credentials & user agent\n",
    "reddit = praw.Reddit(\n",
    "    client_id=%env ,\n",
    "    client_secret=,\n",
    "    user_agent=,\n",
    "    ratelimit_seconds=6000, # Give heavy allowance for rate limits to avoid TooManyRequests error\n",
    ")\n",
    "\n",
    "data_collection: list[DataRow] = [] # List to hold all DataRow items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subreddit instance from PRAW\n",
    "subreddit_instance = reddit.subreddit(SUBREDDIT_NAME)\n",
    "print(subreddit_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subreddit section based on the filter argument (top, controversial, hot)\n",
    "result = {\n",
    "    'top': subreddit_instance.top(**OPTIONS),\n",
    "    'controversial': subreddit_instance.controversial(**OPTIONS),\n",
    "    'hot': subreddit_instance.hot(**OPTIONS),\n",
    "}[SUBREDDIT_FILTER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # Import tqdm for fancy progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/11 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with tqdm(total=LIMIT) as progress_bar:\n",
    "        for submission in result:   # Iterate through submissions in the selected subreddit section\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            submission.comments.replace_more(limit=None)    # Load all comments by replacing \"MoreComments\"\n",
    "            comments = submission.comments.list()   # Flatten the comment tree into a list\n",
    "\n",
    "            for comment in tqdm(comments):    # Iterate through each comment\n",
    "                # Get author name, or set as empty string if not available\n",
    "                author = (\n",
    "                    comment.author.name \n",
    "                    if isinstance(comment.author, praw.models.Redditor) \n",
    "                    else ''\n",
    "                )\n",
    "                body = comment.body # Comment text\n",
    "    \n",
    "                # Skip comment if the author is in the blacklist\n",
    "                if author in AUTHOR_BLACKLIST: continue\n",
    "    \n",
    "                # Skip comment if body is in the blacklist\n",
    "                if body in BODY_BLACKLIST: continue\n",
    "    \n",
    "                data_row: DataRow = {\n",
    "                    'id': comment.id,\n",
    "                    'subreddit': comment.subreddit.display_name,\n",
    "                    'submission_name': submission.title,\n",
    "                    'submission_text': submission.selftext,\n",
    "                    'author': author,\n",
    "                    'body': body,\n",
    "                    'score': comment.score,\n",
    "                    'timestamp': datetime.utcfromtimestamp(\n",
    "                        comment.created_utc\n",
    "                    ).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                }\n",
    "                data_collection.append(data_row)    # Add the data row to the collection\n",
    "except prawcore.exceptions.TooManyRequests:\n",
    "    pass    # Handle rate limit exceptions gracefully\n",
    "except Redirect:\n",
    "    print(\"ERROR: Request redirected. Please check subreddit name and try again\")\n",
    "    exit(1)\n",
    "except RequestException:\n",
    "    print(\"ERROR: Request exception. Please check subreddit name and try again\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of DataRow dictionaries to a Pandas DataFrame\n",
    "data_frame = pd.DataFrame(data_collection)\n",
    "\n",
    "data_frame.to_csv(FILENAME) # Save the DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Visualize the collected data to gain insights, such as the number of comments per post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the table\n",
    "\n",
    "data_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by submission_name and count the number of comments for each post\n",
    "comments_per_post = data_frame.groupby('submission_name')['id'].count()\n",
    "\n",
    "# Sorting the counts and selecting the top N posts for better visibility in the bar chart\n",
    "top_comments_per_post = comments_per_post.sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_comments_per_post.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Top 10 Posts by Number of Comments')\n",
    "plt.xlabel('Post Title')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate post titles for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'submission_name' and count the number of comments for each post\n",
    "comments_per_post = data_frame.groupby('submission_name')['id'].count().sort_values(ascending=False)\n",
    "\n",
    "# Convert the Series object to DataFrame for better readability\n",
    "comments_per_post_df = comments_per_post.to_frame(name='Number of Comments')\n",
    "\n",
    "# Resetting the index to have 'submission_name' as a column instead of an index\n",
    "comments_per_post_df.reset_index(inplace=True)\n",
    "\n",
    "# Optionally, rename the columns for better readability\n",
    "comments_per_post_df.columns = ['Post Title', 'Number of Comments']\n",
    "\n",
    "# Display the DataFrame\n",
    "comments_per_post_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
