{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Installation on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    subprocess.run(['python', '-m', 'pip', 'install',  'transformers', 'joblib', 'calamanCy'])\n",
        "except ImportError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "eH1p9VOvzTXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXkQqRohza8j",
        "outputId": "cccdd11d-6380-497d-a01d-0f01d8f4bfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH0f4jc_weKf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "MODELS_FOLDER = '/content/drive/MyDrive/School/Thesis - Hate Speech/Models/100-try-2'\n",
        "# torch.cuda.is_available = lambda: False\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z60rbr0_weKg"
      },
      "source": [
        "## Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BlUWWcqweKk"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h1o44ZMweKn",
        "outputId": "c2acbeec-2540-45e1-dc45-f701df57a4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.3.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  CountVec = joblib.load(f'{MODELS_FOLDER}/model_bayes/countvec.pkl')\n",
        "except FileNotFoundError:\n",
        "  print(\"ERROR: Model not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "bT_BHuCJweKn",
        "outputId": "e1cc564a-d35f-44d5-a166-e42de4c225fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(binary=True, lowercase=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True, lowercase=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, lowercase=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "CountVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBlrLxfBweKo",
        "outputId": "15f8830c-0472-4ac5-da9e-bcb2030be2da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'USERNAME': 20502,\n",
              " 'Palangga': 15535,\n",
              " 'ka': 32210,\n",
              " 'man': 35904,\n",
              " 'sang': 44342,\n",
              " 'mga': 36751,\n",
              " 'taga': 46406,\n",
              " 'Bacolod': 2311,\n",
              " 'vp': 48733,\n",
              " 'Let': 10756,\n",
              " 'Leni': 10622,\n",
              " 'Lead': 10541,\n",
              " 'MonLaurista': 12862,\n",
              " 'Grabeh': 6955,\n",
              " 'ang': 22554,\n",
              " 'loilo': 34438,\n",
              " 'namon': 38534,\n",
              " 'Kiko': 9742,\n",
              " 'Robredo': 17387,\n",
              " 'iloilo': 30940,\n",
              " 'kakampinkLaban': 32505,\n",
              " 'Who': 21275,\n",
              " 'dafuq': 26253,\n",
              " 'is': 31703,\n",
              " 'Jose': 8908,\n",
              " 'Montemayor': 12881,\n",
              " 'Jr': 8933,\n",
              " 'Di': 5045,\n",
              " 'na': 37317,\n",
              " 'nakakatuwa': 38224,\n",
              " 'yung': 49644,\n",
              " 'mukha': 37204,\n",
              " 'ni': 39296,\n",
              " 'Mar': 12232,\n",
              " 'Roxas': 17522,\n",
              " 'sa': 44084,\n",
              " 'TV': 19569,\n",
              " 'Nakakatamad': 13765,\n",
              " 'manood': 36086,\n",
              " 'national': 38951,\n",
              " 'elections': 27676,\n",
              " 'via': 48554,\n",
              " 'Binay': 2732,\n",
              " 'will': 49116,\n",
              " 'be': 23672,\n",
              " 'staring': 45721,\n",
              " 'in': 31049,\n",
              " 'movie': 37168,\n",
              " 'called': 24856,\n",
              " 'The': 19905,\n",
              " 'Dark': 4795,\n",
              " 'Force': 6339,\n",
              " 'Awakens': 1775,\n",
              " 'Nog': 14189,\n",
              " 'Hambog': 7567,\n",
              " 'fact': 28271,\n",
              " 'that': 46924,\n",
              " 'we': 48925,\n",
              " 'are': 22825,\n",
              " 'even': 28045,\n",
              " 'discussing': 26977,\n",
              " 'the': 46949,\n",
              " 'probability': 42684,\n",
              " 'of': 39820,\n",
              " 'BinayMarcosDuterte': 2763,\n",
              " 'Administration': 1058,\n",
              " 'horrifying': 30414,\n",
              " 'Lito': 10870,\n",
              " 'Atienza': 1696,\n",
              " 'goi': 29342,\n",
              " 'Yung': 21605,\n",
              " 'yaman': 49418,\n",
              " 'ng': 39189,\n",
              " 'Marcos': 12288,\n",
              " 'ninakaw': 39393,\n",
              " 'nila': 39328,\n",
              " 'bawiin': 23606,\n",
              " 'natin': 38932,\n",
              " 'at': 23003,\n",
              " 'Itoy': 8612,\n",
              " 'panibagong': 41034,\n",
              " 'dagdag': 26258,\n",
              " 'pondo': 42320,\n",
              " 'kailangan': 32406,\n",
              " 'bayan': 23618,\n",
              " 'Ka': 9325,\n",
              " 'Leody': 10733,\n",
              " 'De': 4865,\n",
              " 'GuzmanKBP': 7087,\n",
              " 'Forum': 6361,\n",
              " 'Ay': 1794,\n",
              " 'dyuskoJudgemental': 27452,\n",
              " 'peepsI': 41473,\n",
              " 'KENNAT': 9194,\n",
              " 'Election': 5726,\n",
              " 'PH': 14946,\n",
              " 'Mas': 12425,\n",
              " 'pipiliin': 42057,\n",
              " 'kong': 33441,\n",
              " 'si': 44937,\n",
              " 'manalo': 35921,\n",
              " 'kesa': 33127,\n",
              " 'kay': 33044,\n",
              " 'Bayan': 2530,\n",
              " 'Muna': 12991,\n",
              " 'Bago': 2331,\n",
              " 'Sarili': 18394,\n",
              " 'Negros': 14058,\n",
              " 'Occidental': 14440,\n",
              " 'Governor': 6944,\n",
              " 'Eugenio': 5927,\n",
              " 'Bong': 3122,\n",
              " 'Lacson': 10278,\n",
              " 'finally': 28538,\n",
              " 'comes': 25572,\n",
              " 'out': 40136,\n",
              " 'with': 49188,\n",
              " 'an': 22487,\n",
              " 'open': 39995,\n",
              " 'endorsement': 27826,\n",
              " 'Vice': 20866,\n",
              " 'President': 16496,\n",
              " 'PHVote': 14984,\n",
              " 'We': 21197,\n",
              " 'Decide': 4918,\n",
              " 'rappler': 43272,\n",
              " 'com': 25555,\n",
              " 'Philippine': 15971,\n",
              " 'Results': 17276,\n",
              " 'and': 22512,\n",
              " 'latest': 33996,\n",
              " 'news': 39151,\n",
              " 'Rappler': 17082,\n",
              " 'coverage': 26016,\n",
              " 'electoral': 27689,\n",
              " 'exercises': 28139,\n",
              " 'presidential': 42596,\n",
              " 'local': 34412,\n",
              " 'barangay': 23474,\n",
              " 'Sangguniang': 18354,\n",
              " 'Kabataan': 9348,\n",
              " 'special': 45574,\n",
              " 'plebiscites': 42165,\n",
              " 'provide': 42837,\n",
              " 'depth': 26654,\n",
              " 'reports': 43634,\n",
              " 'Reese': 17154,\n",
              " 'Magnanakaw': 11789,\n",
              " 'pa': 40232,\n",
              " 'rinInquirer': 43868,\n",
              " 'JUST': 8716,\n",
              " 'IN': 8067,\n",
              " 'House': 7908,\n",
              " 'Deputy': 5008,\n",
              " 'Minority': 12772,\n",
              " 'Leader': 10566,\n",
              " 'Carlos': 3778,\n",
              " 'Zarate': 21632,\n",
              " 'Chairman': 3907,\n",
              " 'Neri': 14069,\n",
              " 'Colmenares': 4144,\n",
              " 'call': 24855,\n",
              " 'on': 39938,\n",
              " 'NTC': 13441,\n",
              " 'DITC': 4581,\n",
              " 'to': 47359,\n",
              " 'immediately': 30986,\n",
              " 'investigate': 31509,\n",
              " 'explain': 28194,\n",
              " 'how': 30446,\n",
              " 'campaign': 24876,\n",
              " 'was': 48873,\n",
              " 'able': 21760,\n",
              " 'hijack': 30198,\n",
              " 'emergency': 27759,\n",
              " 'alerts': 22287,\n",
              " 'frequency': 28813,\n",
              " 'Winners': 21305,\n",
              " 'losers': 34494,\n",
              " 'CNN': 3543,\n",
              " 'Philippines': 15973,\n",
              " 'Presidential': 16546,\n",
              " 'Debate': 4876,\n",
              " 'Winner': 21303,\n",
              " 'PangilinanBiggest': 15635,\n",
              " 'surprise': 46195,\n",
              " 'Walden': 21129,\n",
              " 'Bello': 2602,\n",
              " 'Neutral': 14085,\n",
              " 'Manny': 12198,\n",
              " 'LopezLosers': 10944,\n",
              " 'Tito': 20039,\n",
              " 'Sotto': 18941,\n",
              " 'Willie': 21293,\n",
              " 'Ong': 14535,\n",
              " 'Serapio': 18564,\n",
              " 'Rizalito': 17359,\n",
              " 'DavidBiggest': 4827,\n",
              " 'loser': 34493,\n",
              " 'Sara': 18380,\n",
              " 'Duterte': 5362,\n",
              " 'Because': 2572,\n",
              " 'this': 47066,\n",
              " 'interview': 31453,\n",
              " 'my': 37288,\n",
              " 'respect': 43718,\n",
              " 'for': 28693,\n",
              " 'VP': 20771,\n",
              " 'soars': 45415,\n",
              " 'Puta': 16738,\n",
              " 'may': 36537,\n",
              " 'bagong': 23297,\n",
              " 'commercial': 25601,\n",
              " 'Hahahahahaha': 7488,\n",
              " 'Ako': 1190,\n",
              " 'rin': 43865,\n",
              " 'mayroon': 36568,\n",
              " 'Laban': 10264,\n",
              " 'UniThieves': 20622,\n",
              " 'BBM': 1930,\n",
              " 'SARA': 17781,\n",
              " 'leni': 34127,\n",
              " 'tanga': 46576,\n",
              " 'hahahahahah': 29717,\n",
              " 'BONUS': 2163,\n",
              " 'NORBERTO': 13404,\n",
              " 'GONZALES': 6564,\n",
              " 'ERNESTO': 5576,\n",
              " 'ABELLA': 551,\n",
              " 'FAISAL': 6016,\n",
              " 'MANGONDATO': 11288,\n",
              " 'JOSE': 8684,\n",
              " 'MONTEMAYOR': 11560,\n",
              " 'They': 19929,\n",
              " 'were': 49006,\n",
              " 'not': 39581,\n",
              " 'included': 31128,\n",
              " 'because': 23697,\n",
              " 'their': 46980,\n",
              " 'chances': 25147,\n",
              " 'extremely': 28237,\n",
              " 'slim': 45345,\n",
              " 'plus': 42184,\n",
              " 'must': 37275,\n",
              " 'improve': 31043,\n",
              " 'numbers': 39685,\n",
              " 'if': 30777,\n",
              " 'they': 47028,\n",
              " 'want': 48845,\n",
              " 'media': 36629,\n",
              " 'take': 46450,\n",
              " 'candidacies': 24908,\n",
              " 'seriously': 44731,\n",
              " 'null': 39679,\n",
              " 'vote': 48681,\n",
              " 'all': 22316,\n",
              " 'you': 49566,\n",
              " 'Sobrang': 18874,\n",
              " 'proud': 42825,\n",
              " 'ko': 33377,\n",
              " 'talaga': 46464,\n",
              " 'father': 28378,\n",
              " 'partner': 41259,\n",
              " 'nia': 39298,\n",
              " 'being': 23753,\n",
              " 'so': 45410,\n",
              " 'supportive': 46165,\n",
              " 'volunteers': 48674,\n",
              " 'Thank': 19892,\n",
              " 'muchIpanalo': 37194,\n",
              " 'Na10': 13472,\n",
              " 'To': 20052,\n",
              " 'Angat': 1400,\n",
              " 'Buhay': 3262,\n",
              " 'Lahat': 10321,\n",
              " 'UNTVRepaso2015': 20474,\n",
              " 'CA': 3400,\n",
              " 'dismisses': 27016,\n",
              " 'Junjun': 8993,\n",
              " 'Binays': 2958,\n",
              " 'petition': 41616,\n",
              " 'against': 22058,\n",
              " 'Ombudsman': 14515,\n",
              " 'suspension': 46239,\n",
              " 'order': 40072,\n",
              " '11': 46,\n",
              " '2015': 164,\n",
              " 'NY': 13460,\n",
              " 'A1710': 522,\n",
              " 'Nasa': 13965,\n",
              " 'VMUF': 20757,\n",
              " 'daw': 26373,\n",
              " 'Ahe': 1160,\n",
              " 'Shit': 18653,\n",
              " 'Pumangalawa': 16695,\n",
              " 'Poe': 16275,\n",
              " 'Eleksyon2016': 5745,\n",
              " 'Paki': 15487,\n",
              " 'forward': 28762,\n",
              " 'nga': 39201,\n",
              " 'ito': 31880,\n",
              " 'Office': 14462,\n",
              " 'Baka': 2359,\n",
              " 'from': 28839,\n",
              " 'Cebu': 3850,\n",
              " 'Baguiomakarating': 2345,\n",
              " 'BOO': 2164,\n",
              " 'am': 22399,\n",
              " 'freelance': 28805,\n",
              " 'Photographer': 16006,\n",
              " 'film': 28520,\n",
              " 'maker': 35687,\n",
              " 'MyLuv': 13030,\n",
              " 'Titindig': 20037,\n",
              " 'para': 41168,\n",
              " 'pag': 40332,\n",
              " 'asa': 22909,\n",
              " 'maganda': 34875,\n",
              " 'kinabukasan': 33210,\n",
              " 'fb': 28401,\n",
              " 'stan': 45699,\n",
              " 'twt': 47937,\n",
              " 'lol': 34445,\n",
              " 'panalo': 40899,\n",
              " 'Natin': 14000,\n",
              " 'Para': 15706,\n",
              " 'Sa': 18221,\n",
              " 'DuwagBBM': 5452,\n",
              " 'If': 8244,\n",
              " 'Won': 21346,\n",
              " 'candidate': 24912,\n",
              " 're': 43302,\n",
              " 'dead': 26421,\n",
              " 'Election2016': 5728,\n",
              " '4Ps': 336,\n",
              " 'tinuligsa': 47285,\n",
              " 'kampo': 32697,\n",
              " 'Brigada': 3212,\n",
              " 'News': 14096,\n",
              " 'WILL': 21040,\n",
              " 'WIN': 21045,\n",
              " 'Lets': 10763,\n",
              " 'unite': 48231,\n",
              " 'better': 23850,\n",
              " 'generation': 29137,\n",
              " 'Pagbabago': 15417,\n",
              " 'Halalan': 7536,\n",
              " 'Mabuti': 11673,\n",
              " 'nalang': 38420,\n",
              " 'Tinapon': 20007,\n",
              " 'ABS': 562,\n",
              " 'CBN': 3446,\n",
              " 'itong': 31898,\n",
              " 'BASURA': 1900,\n",
              " 'MatapangLeni': 12480,\n",
              " 'Either': 5711,\n",
              " 'lying': 34667,\n",
              " 'people': 41505,\n",
              " 'about': 21775,\n",
              " 'supporting': 46161,\n",
              " 'PNoy': 15114,\n",
              " 'five': 28588,\n",
              " 'years': 49489,\n",
              " 'or': 40059,\n",
              " 'he': 30021,\n",
              " 'now': 39620,\n",
              " 'his': 30316,\n",
              " 'attacks': 23057,\n",
              " 'lazy': 34045,\n",
              " 'teka': 46831,\n",
              " 'govt': 29405,\n",
              " 'Hindi': 7806,\n",
              " 'lang': 33904,\n",
              " 'naman': 38466,\n",
              " 'isang': 31724,\n",
              " 'umaming': 48044,\n",
              " 'nilapitan': 39373,\n",
              " 'sila': 44999,\n",
              " 'marami': 36210,\n",
              " 'Ping': 16137,\n",
              " 'Isko': 8566,\n",
              " 'Moreno': 12906,\n",
              " 'Pacquiao': 15389,\n",
              " 'Norberto': 14237,\n",
              " 'Gonzales': 6900,\n",
              " 'Apat': 1495,\n",
              " 'laban': 33742,\n",
              " 'isa': 31712,\n",
              " 'Kanino': 9573,\n",
              " 'kayo': 33066,\n",
              " 'maniniwala': 36056,\n",
              " 'kulang': 33561,\n",
              " 'ANGAT': 773,\n",
              " 'BUHAY': 2226,\n",
              " 'TERORISTA': 19365,\n",
              " 'neri': 39120,\n",
              " 'colmenaresANGAT': 25545,\n",
              " 'AKTIBISTA': 686,\n",
              " 'leody': 34160,\n",
              " 'de': 26420,\n",
              " 'guzman': 29611,\n",
              " 'Takot': 19656,\n",
              " 'matalo': 36405,\n",
              " 'Unity': 20637,\n",
              " 'what': 49026,\n",
              " 'You': 21576,\n",
              " 'really': 43339,\n",
              " 'weak': 48926,\n",
              " 'leader': 34056,\n",
              " 'Mga': 12699,\n",
              " 'echos': 27502,\n",
              " 'mo': 36977,\n",
              " 'Ika': 8265,\n",
              " 'tumigil': 47821,\n",
              " 'patan': 41344,\n",
              " 'awun': 23155,\n",
              " 'nako': 38376,\n",
              " 'mama': 35849,\n",
              " 'papa': 41093,\n",
              " 'ani': 22595,\n",
              " 'unya': 48304,\n",
              " 'tan': 46555,\n",
              " 'awon': 23153,\n",
              " 'pod': 42228,\n",
              " 'kung': 33641,\n",
              " 'ba': 23200,\n",
              " 'after': 22030,\n",
              " 'wala': 48802,\n",
              " 'baya': 23609,\n",
              " 'jud': 32145,\n",
              " 'koy': 33502,\n",
              " 'Kakampink': 9423,\n",
              " 'dires': 26921,\n",
              " 'balay': 23360,\n",
              " 'over': 40172,\n",
              " 'Santiago': 18359,\n",
              " 'beyond': 23857,\n",
              " 'pathetic': 41355,\n",
              " 'Ms': 12962,\n",
              " 'Have': 7643,\n",
              " 'been': 23714,\n",
              " 'looking': 34476,\n",
              " 'Eto': 5921,\n",
              " 'ata': 23009,\n",
              " 'nakalimot': 38245,\n",
              " 'lenikiko202Your': 34141,\n",
              " 'Daily': 4755,\n",
              " 'Dose': 5256,\n",
              " 'In': 8350,\n",
              " 'Imelda': 8326,\n",
              " 'tried': 47659,\n",
              " 'upstage': 48347,\n",
              " 'Charles': 3939,\n",
              " 'Diana': 5046,\n",
              " 'wedding': 48951,\n",
              " 'Irene': 8526,\n",
              " 'Greggy': 6998,\n",
              " 'She': 18627,\n",
              " 'spent': 45598,\n",
              " '3M': 294,\n",
              " 'building': 24606,\n",
              " 'new': 39147,\n",
              " 'airport': 22168,\n",
              " 'hotel': 30430,\n",
              " 'booked': 24345,\n",
              " 'cruiseliner': 26129,\n",
              " 'guests': 29528,\n",
              " 'imported': 31027,\n",
              " 'Austrian': 1746,\n",
              " 'carriage': 25004,\n",
              " 'Moroccan': 12929,\n",
              " 'horses': 30416,\n",
              " 'turned': 47865,\n",
              " 'town': 47524,\n",
              " 'Sarrat': 18398,\n",
              " 'into': 31476,\n",
              " 'Spanish': 18969,\n",
              " 'Colonial': 4149,\n",
              " 'Kulay': 9937,\n",
              " 'Rosas': 17498,\n",
              " 'Ang': 1395,\n",
              " 'Bukas': 3266,\n",
              " 'Liwanag': 10879,\n",
              " 'Dilim': 5087,\n",
              " 'For': 6336,\n",
              " 'photo': 41657,\n",
              " 'showing': 44910,\n",
              " 'official': 39857,\n",
              " 'ballot': 23392,\n",
              " 'received': 43380,\n",
              " 'by': 24816,\n",
              " 'overseas': 40192,\n",
              " 'voter': 48699,\n",
              " 'New': 14091,\n",
              " 'Zealand': 21635,\n",
              " 'has': 29943,\n",
              " 'deliberately': 26568,\n",
              " 'edited': 27524,\n",
              " 'make': 35685,\n",
              " 'it': 31823,\n",
              " 'appear': 22761,\n",
              " 'Robredos': 17434,\n",
              " 'name': 38499,\n",
              " 'missing': 36926,\n",
              " 'Overseas': 14653,\n",
              " 'Voting': 20968,\n",
              " 'saidHalalan': 44194,\n",
              " 'Feel': 6211,\n",
              " 'Ernie': 5864,\n",
              " 'Abella': 951,\n",
              " 'Tignan': 19983,\n",
              " 'nyo': 39752,\n",
              " 'gaano': 28918,\n",
              " 'kalala': 32609,\n",
              " 'bobo': 24271,\n",
              " 'pinasLeni': 41940,\n",
              " 'Pasasalamat': 15768,\n",
              " '88m': 479,\n",
              " 'Duwag': 5451,\n",
              " 'Reporter': 17237,\n",
              " 'Sino': 18769,\n",
              " 'po': 42204,\n",
              " 'dapat': 26330,\n",
              " 'mag': 34843,\n",
              " 'responsibility': 43745,\n",
              " 'laglag': 33796,\n",
              " 'bala': 23351,\n",
              " 'Paano': 15363,\n",
              " 'naging': 37652,\n",
              " 'problema': 42695,\n",
              " 'gobyerno': 29325,\n",
              " 'yon': 49547,\n",
              " 'Gago': 6668,\n",
              " 'PUTA': 15332,\n",
              " 'Booooo': 3150,\n",
              " 'HINDI': 7339,\n",
              " 'KA': 9020,\n",
              " 'MANANALO': 11273,\n",
              " 'PiliPinas': 16036,\n",
              " 'Debates': 4901,\n",
              " '2016': 167,\n",
              " 'Vote': 20954,\n",
              " 'Lisa': 10861,\n",
              " 'said': 44191,\n",
              " 'pink': 41987,\n",
              " 'tayo': 46773,\n",
              " 'Lfamily': 10786,\n",
              " 'From': 6414,\n",
              " 'Nkkbwiset': 14174,\n",
              " 'tong': 47433,\n",
              " 'binay': 24017,\n",
              " 'Pag': 15414,\n",
              " 'nanalo': 38551,\n",
              " 'Binaysolid': 2972,\n",
              " 'pagiging': 40417,\n",
              " 'noob': 39556,\n",
              " 'Pinoy': 16199,\n",
              " 'Hahaha': 7471,\n",
              " 'Natupad': 14013,\n",
              " 'pangarap': 40978,\n",
              " 'makapag': 35616,\n",
              " 'jump': 32166,\n",
              " 'serve': 44738,\n",
              " 'Araneta': 1552,\n",
              " 'Coliseum': 4138,\n",
              " 'Salamat': 18287,\n",
              " 'Sen': 18519,\n",
              " 'KikoAngat': 9749,\n",
              " 'AC': 583,\n",
              " 'Elections': 5734,\n",
              " 'just': 32193,\n",
              " 'like': 34270,\n",
              " 'COMELEC': 3568,\n",
              " 'scam': 44498,\n",
              " 'Never': 14086,\n",
              " 'Again': 1096,\n",
              " 'MagnanakawMiss': 11842,\n",
              " 'Maggie': 11761,\n",
              " 'TIN': 19420,\n",
              " 'stands': 45712,\n",
              " 'number': 39682,\n",
              " 'BIR': 2110,\n",
              " 'should': 44895,\n",
              " 'know': 33362,\n",
              " 'Kay': 9676,\n",
              " 'Tayo': 19807,\n",
              " 'Huwag': 7977,\n",
              " 'Papaloko': 15689,\n",
              " 'Only': 14561,\n",
              " 'Cara': 3761,\n",
              " 'Kendall': 9704,\n",
              " 'On': 14528,\n",
              " 'BATB': 1908,\n",
              " 'Monica': 12870,\n",
              " 'Sacay': 18247,\n",
              " '10': 24,\n",
              " 'Team': 19828,\n",
              " 'Asia': 1645,\n",
              " '22': 197,\n",
              " '02': 9,\n",
              " '33': 276,\n",
              " 'PHT': 14982,\n",
              " 'trndnl': 47680,\n",
              " 'kang': 32728,\n",
              " 'pinipilit': 41986,\n",
              " 'nagbayad': 37542,\n",
              " 'survey': 46210,\n",
              " 'epal': 27922,\n",
              " 'mar': 36207,\n",
              " 'roxassana': 44003,\n",
              " 'eyes': 28246,\n",
              " 'as': 22907,\n",
              " 'election': 27659,\n",
              " 'kasi': 32910,\n",
              " 'Alan': 1210,\n",
              " 'sino': 45148,\n",
              " 'Putangina': 16742,\n",
              " 'political': 42280,\n",
              " 'ad': 21902,\n",
              " 'Nakakaumay': 13771,\n",
              " 'any': 22691,\n",
              " 'NOT': 13409,\n",
              " 'leading': 34066,\n",
              " 'fakeclass': 28305,\n",
              " 'ABCDE': 549,\n",
              " 'ano': 22638,\n",
              " 'kala': 32594,\n",
              " 'laylayan': 34033,\n",
              " 'beshiiHalalan': 23823,\n",
              " 'Gov': 6940,\n",
              " 'Pogi': 16349,\n",
              " 'president': 42567,\n",
              " 'houseeeew': 30439,\n",
              " 'Seen': 18502,\n",
              " 'Great': 6988,\n",
              " 'Hack': 7452,\n",
              " 'Netflix': 14078,\n",
              " 'yet': 49526,\n",
              " 'kakam': 32463,\n",
              " 'Pink': 16147,\n",
              " 'kakampink': 32485,\n",
              " 'Connect': 4226,\n",
              " 'NGO': 13337,\n",
              " 'netflixcom': 39126,\n",
              " 'Watch': 21163,\n",
              " 'HackNetflix': 7453,\n",
              " 'Official': 14465,\n",
              " 'Site': 18818,\n",
              " 'Explore': 5987,\n",
              " 'data': 26353,\n",
              " 'company': 25640,\n",
              " 'named': 38502,\n",
              " 'Cambridge': 3714,\n",
              " 'Analytica': 1366,\n",
              " 'came': 24869,\n",
              " 'symbolize': 46332,\n",
              " 'dark': 26343,\n",
              " 'side': 44953,\n",
              " 'social': 45424,\n",
              " 'wake': 48801,\n",
              " 'theUS': 46961,\n",
              " 'pala': 40764,\n",
              " 'sir': 45200,\n",
              " 'basura': 23557,\n",
              " 'sinabi': 45056,\n",
              " 'Wlang': 21333,\n",
              " 'tinamaan': 47210,\n",
              " 'kahit': 32387,\n",
              " 'BERDUGO': 2036,\n",
              " 'ALERTPWERSA': 719,\n",
              " 'NG': 13323,\n",
              " 'MGA': 11475,\n",
              " 'PARAMILITAR': 14840,\n",
              " 'SA': 17713,\n",
              " 'BUKIDNON': 2231,\n",
              " 'PINAPUTUKAN': 15022,\n",
              " 'BALA': 1860,\n",
              " 'SINA': 17955,\n",
              " 'LEODY': 10108,\n",
              " 'AT': 867,\n",
              " 'ANG': 772,\n",
              " 'LIDER': 10150,\n",
              " 'MANOBONgayong': 11303,\n",
              " 'hapon': 29896,\n",
              " 'pinaputukan': 41933,\n",
              " 'sina': 45054,\n",
              " 'Guzman': 7073,\n",
              " 'kasama': 32891,\n",
              " 'kanyang': 32760,\n",
              " 'kapartido': 32803,\n",
              " 'habang': 29651,\n",
              " 'bumibisita': 24676,\n",
              " 'Brgy': 3208,\n",
              " 'Butong': 3370,\n",
              " 'Quezon': 16803,\n",
              " 'Bukidnon': 3293,\n",
              " 'ProvinceGIF': 16650,\n",
              " 'textbook': 46899,\n",
              " 'case': 25016,\n",
              " 'relatively': 43533,\n",
              " 'strong': 45873,\n",
              " 'academically': 21813,\n",
              " 'but': 24755,\n",
              " 'hopeless': 30409,\n",
              " 'human': 30507,\n",
              " 'Transparency': 20179,\n",
              " 'Accountability': 1010,\n",
              " 'People': 15890,\n",
              " 'Empowerment': 5791,\n",
              " 'Gobyernong': 6869,\n",
              " 'Tapat': 19746,\n",
              " 'Sharingthis': 18620,\n",
              " 'nice': 39304,\n",
              " 'Sulu': 19147,\n",
              " 'Boy': 3181,\n",
              " 'Sayang': 18436,\n",
              " 'Doc': 5205,\n",
              " 'Inis': 8418,\n",
              " 'Binaydumagdag': 2840,\n",
              " 'Sige': 18700,\n",
              " 'parinigan': 41219,\n",
              " 'ewan': 28091,\n",
              " 'Nognogpandakpero': 14205,\n",
              " 'nagawa': 37519,\n",
              " 'Yan': 21495,\n",
              " 'HALOS': 7257,\n",
              " 'IBATO': 7999,\n",
              " 'KO': 9258,\n",
              " 'KAPAG': 9127,\n",
              " 'NAKIKITA': 13148,\n",
              " 'AD': 601,\n",
              " 'NA': 13046,\n",
              " 'ITO': 8185,\n",
              " 'witty': 49211,\n",
              " 'Bulacan': 3301,\n",
              " 'Is': 8534,\n",
              " 'Baliwag': 2386,\n",
              " 'Republika': 17249,\n",
              " 'Dos': 5254,\n",
              " 'Ipanalo': 8505,\n",
              " 'Mostly': 12938,\n",
              " 'courier': 26004,\n",
              " 'riders': 43838,\n",
              " 'kupal': 33659,\n",
              " 'Haha': 7462,\n",
              " 'mas': 36305,\n",
              " 'okay': 39903,\n",
              " 'wheels': 49042,\n",
              " 'Lalamove': 10427,\n",
              " 'pati': 41358,\n",
              " 'Grab': 6949,\n",
              " 'rider': 43837,\n",
              " 'mostly': 37120,\n",
              " 'din': 26848,\n",
              " 'basta': 23546,\n",
              " 'lisensya': 34352,\n",
              " 'galing': 28991,\n",
              " 'fixer': 28590,\n",
              " 'pasok': 41300,\n",
              " 'Minsan': 12773,\n",
              " 'pinagpipiyestahan': 41788,\n",
              " 'customer': 26188,\n",
              " 'screenshot': 44557,\n",
              " 'tapos': 46662,\n",
              " 'ipopost': 31654,\n",
              " 'group': 29494,\n",
              " 'eh': 27587,\n",
              " 'Two': 20377,\n",
              " 'candidates': 24927,\n",
              " 'Faisal': 6152,\n",
              " 'Mangondato': 12157,\n",
              " 'showed': 44908,\n",
              " 'privileged': 42679,\n",
              " 'enough': 27877,\n",
              " 'stay': 45759,\n",
              " 'away': 23137,\n",
              " 'danger': 26325,\n",
              " 'pandemic': 40938,\n",
              " 'Sana': 18338,\n",
              " 'CNNPHPresidential': 3546,\n",
              " 'Basta': 2483,\n",
              " 'masasabi': 36333,\n",
              " 'fans': 28347,\n",
              " 'marcos': 36223,\n",
              " 'panatiks': 40916,\n",
              " 'hahaha': 29696,\n",
              " 'lagi': 33787,\n",
              " 'nakasubay2': 38304,\n",
              " 'kqy': 33513,\n",
              " 'bbm': 23649,\n",
              " 'hahahaha': 29706,\n",
              " 'wag': 48766,\n",
              " 'mahiya': 35396,\n",
              " 'denies': 26629,\n",
              " 'hand': 29851,\n",
              " 'housing': 30445,\n",
              " 'backlog': 23263,\n",
              " 'Yolanda': 21563,\n",
              " 'PH2016': 14947,\n",
              " 'Zquirrel': 21650,\n",
              " 'family': 28325,\n",
              " 'wants': 48850,\n",
              " 'help': 30095,\n",
              " 'return': 43782,\n",
              " 'money': 37054,\n",
              " 'stole': 45799,\n",
              " 'Pangtawid': 15650,\n",
              " 'pandemya': 40944,\n",
              " 'Roxasmay': 17635,\n",
              " 'sasabihin': 44407,\n",
              " 'ako': 22197,\n",
              " 'yo': 49544,\n",
              " 'SHUT': 17928,\n",
              " 'UP': 20477,\n",
              " 'NALANG': 13161,\n",
              " 'Absent': 991,\n",
              " 'Davao': 4820,\n",
              " 'City': 4054,\n",
              " 'Mayor': 12579,\n",
              " 'Carpio': 3789,\n",
              " 'declined': 26491,\n",
              " 'invitation': 31516,\n",
              " 'Rep': 17226,\n",
              " 'undergo': 48151,\n",
              " 'knee': 33349,\n",
              " 'replacement': 43620,\n",
              " 'surgery': 46185,\n",
              " 'hope': 30403,\n",
              " 'everyone': 28061,\n",
              " 'review': 43802,\n",
              " 'every': 28057,\n",
              " 'candidatesplatform': 24935,\n",
              " 'achievementsvote': 21865,\n",
              " 'objectively': 39784,\n",
              " 'mayPH': 36540,\n",
              " 'Kenn': 9706,\n",
              " 'lito': 34371,\n",
              " 'atienza': 23029,\n",
              " 'EmeQuote': 5775,\n",
              " 'Tweet': 20365,\n",
              " 'LOOK': 10206,\n",
              " 'file': 28507,\n",
              " 'certificates': 25113,\n",
              " 'candidacy': 24909,\n",
              " 'vice': 48563,\n",
              " 'Halalan2022': 7540,\n",
              " 'FULL': 6119,\n",
              " 'STORY': 18150,\n",
              " 'appealing': 22759,\n",
              " 'Grace': 6959,\n",
              " 'form': 28739,\n",
              " 'alliance': 22333,\n",
              " 'Desperate': 5023,\n",
              " 'much': 37193,\n",
              " 'Halalan2016': 7537,\n",
              " 'Philippines2016': 15974,\n",
              " 'LOL': 10196,\n",
              " 'meron': 36720,\n",
              " 'duterte': 27400,\n",
              " 'CROWDSOURCE': 3660,\n",
              " 'start': 45726,\n",
              " 'thread': 47104,\n",
              " 'What': 21255,\n",
              " 'issues': 31803,\n",
              " 'actions': 21882,\n",
              " 'would': 49327,\n",
              " 'touch': 47507,\n",
              " 'Move': 12946,\n",
              " 'Kakam': 9410,\n",
              " 'Christmas': 4025,\n",
              " 'Please': 16248,\n",
              " 'world': 49296,\n",
              " 'full': 28871,\n",
              " 'Norman': 14241,\n",
              " 'Daez': 4741,\n",
              " 'naconvict': 37459,\n",
              " 'hirap': 30302,\n",
              " 'baliin': 23371,\n",
              " 'katotohanan': 32995,\n",
              " 'supporters': 46146,\n",
              " 'kanya': 32757,\n",
              " 'mental': 36700,\n",
              " 'gymnastics': 29623,\n",
              " 'magising': 34994,\n",
              " 'MagnanakawManila': 11838,\n",
              " 'Bulletin': 3310,\n",
              " 'aspirant': 22955,\n",
              " 'Ferdinand': 6225,\n",
              " 'Bongbong': 3125,\n",
              " 'tax': 46759,\n",
              " 'evasion': 28042,\n",
              " 'crime': 26080,\n",
              " 'puts': 43092,\n",
              " 'question': 43153,\n",
              " 'morality': 37091,\n",
              " 'could': 25967,\n",
              " 'disqualified': 27030,\n",
              " 'seeking': 44621,\n",
              " 'highest': 30175,\n",
              " 'post': 42406,\n",
              " 'country': 25982,\n",
              " 'camp': 24874,\n",
              " 'believed': 23762,\n",
              " 'READ': 16846,\n",
              " 'Zaxezaxezaxe': 21633,\n",
              " 'STYLE': 18165,\n",
              " 'NYO': 13464,\n",
              " 'BULOK': 2245,\n",
              " 'ANGKAN': 777,\n",
              " 'MAGNANAKAW': 11148,\n",
              " 'Forget': 6347,\n",
              " 'Fuck': 6429,\n",
              " 'SAVE': 17820,\n",
              " 'THE': 19383,\n",
              " 'PHILIPPINES': 14962,\n",
              " 'NO': 13386,\n",
              " 'TO': 19455,\n",
              " 'BINAY': 2077,\n",
              " 'Abigail': 974,\n",
              " 'Derpcon': 5012,\n",
              " 'SecondChanceFor': 18488,\n",
              " 'CHARLHONE': 3486,\n",
              " 'LOISHUA': 10193,\n",
              " 'MusicAndLyrics': 13014,\n",
              " 'Gone': 6894,\n",
              " 'Girl': 6825,\n",
              " '18': 113,\n",
              " '01': 7,\n",
              " '54': 371,\n",
              " 'Roxaspabor': 17644,\n",
              " 'magpagulong': 35141,\n",
              " 'ulo': 48003,\n",
              " 'Escuderobinanatan': 5883,\n",
              " 'Abaya': 943,\n",
              " 'tanim': 46608,\n",
              " 'Breaktime': 3202,\n",
              " 'Headlines': 7680,\n",
              " 'Im': 8309,\n",
              " 'liking': 34281,\n",
              " 'presence': 42548,\n",
              " 'mainstream': 35460,\n",
              " 'Kung': 9961,\n",
              " 'hindi': 30265,\n",
              " 'siya': 45256,\n",
              " 'palarin': 40791,\n",
              " 'ngayon': 39237,\n",
              " 'sana': 44324,\n",
              " 'sunod': 46096,\n",
              " 'Senator': 18532,\n",
              " 'sounds': 45536,\n",
              " 'real': 43325,\n",
              " 'good': 29357,\n",
              " 'let': 34173,\n",
              " 'lead': 34050,\n",
              " 'us': 48367,\n",
              " 'doom': 27189,\n",
              " 'HAHAHA': 7140,\n",
              " 'kapag': 32770,\n",
              " 'babae': 23208,\n",
              " 'lider': 34236,\n",
              " 'walang': 48807,\n",
              " 'unlad': 48251,\n",
              " 'bansa': 23456,\n",
              " 'Anton': 1465,\n",
              " 'Lean': 10576,\n",
              " 'Alam': 1206,\n",
              " 'market': 36272,\n",
              " 'no': 39498,\n",
              " 'straight': 45830,\n",
              " 'male': 35795,\n",
              " 'babad': 23206,\n",
              " 'internet': 31442,\n",
              " 'And': 1371,\n",
              " 'formerly': 28745,\n",
              " 'page': 40382,\n",
              " 'thosame': 47090,\n",
              " 'circle': 25350,\n",
              " 'Quote': 16821,\n",
              " 'BARAKOS': 1888,\n",
              " 'NAKAKADIRI': 13121,\n",
              " 'Dti': 5302,\n",
              " 'bilib': 23940,\n",
              " 'aq': 22799,\n",
              " 'jan': 31994,\n",
              " 'ky': 33714,\n",
              " 'doc': 27126,\n",
              " 'willie': 49118,\n",
              " 'pero': 41573,\n",
              " 'ncancel': 39042,\n",
              " 'qna': 43129,\n",
              " 'xa': 49377,\n",
              " 'bakit': 23341,\n",
              " 'ngppagamit': 39281,\n",
              " 'ganyang': 29058,\n",
              " 'nasisira': 38882,\n",
              " 'lng': 34402,\n",
              " 'pinagingatan': 41763,\n",
              " 'nyan': 39737,\n",
              " 'pangalan': 40961,\n",
              " 'pinoy': 42021,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "CountVec.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM-6TPYeweKp",
        "outputId": "8cdfb99b-fb9f-4172-f6be-79650131d4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator BernoulliNB from version 1.3.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  BayesModel = joblib.load(f'{MODELS_FOLDER}/model_bayes/bayes.pkl')\n",
        "except FileNotFoundError:\n",
        "  print(\"ERROR: Model not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "wJxUkmCUweKt",
        "outputId": "94147402-6c95-45cc-b649-a649214efb08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "BayesModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC0R8AIvweK6"
      },
      "outputs": [],
      "source": [
        "def predict_bayes(inputs: list):\n",
        "  inputs_transformed = CountVec.transform(inputs)\n",
        "  predictions = BayesModel.predict(inputs_transformed)\n",
        "  return predictions\n",
        "\n",
        "def predict_proba_bayes(inputs: list):\n",
        "  inputs_transformed = CountVec.transform(inputs)\n",
        "  predictions = BayesModel.predict_proba(inputs_transformed)\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkYLJxozweK9"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXtTnVYFweK9",
        "outputId": "473125a3-2691-4b50-c3bd-1ff87c2a22b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:918: UserWarning: [W094] Model 'tl_calamancy_md' (0.1.0) specifies an under-constrained spaCy version requirement: >=3.5.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.tl.Tagalog at 0x7e6873086020>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import calamancy\n",
        "\n",
        "Calamancy = calamancy.load(\"tl_calamancy_md-0.1.0\")\n",
        "\n",
        "Calamancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7-1wwE1weK_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch import Tensor\n",
        "\n",
        "def get_calamancy_tokens(data):\n",
        "  # Allows it to work with both dataframes and\n",
        "  # simple lists of strings\n",
        "  if isinstance(data, pd.Series):\n",
        "    data = data.values\n",
        "\n",
        "  samples = []\n",
        "\n",
        "  for sample in Calamancy.pipe(data):\n",
        "    tokens = [\n",
        "      token\n",
        "      for token\n",
        "      in sample\n",
        "    ]\n",
        "\n",
        "    samples.append(tokens)\n",
        "\n",
        "  return samples\n",
        "\n",
        "def get_token_vectors(tokens):\n",
        "  vectors = []\n",
        "\n",
        "  for sample in tokens:\n",
        "    vector = Tensor(np.array([token.vector for token in sample]))\n",
        "\n",
        "    vectors.append(vector)\n",
        "\n",
        "  return vectors\n",
        "\n",
        "def get_input_lengths(inputs):\n",
        "  return [len(sample) for sample in inputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_982AazSweLA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "INPUT_SIZE = 200\n",
        "NUM_OF_HIDDEN_NODES = 50\n",
        "OUTPUT_SIZE = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1s6LfpWweLB",
        "outputId": "bca667a6-9724-4d13-ea2a-b1647674039c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LstmModel(\n",
              "  (lstm): LSTM(200, 50, batch_first=True)\n",
              "  (linear): Linear(in_features=50, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "class LstmModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(\n",
        "      INPUT_SIZE,\n",
        "      NUM_OF_HIDDEN_NODES,\n",
        "      batch_first=True,\n",
        "    )\n",
        "    self.linear = nn.Linear(NUM_OF_HIDDEN_NODES, OUTPUT_SIZE)\n",
        "\n",
        "    self.lstm_output = None\n",
        "    self.lstm_packed_output = None\n",
        "    self.lstm_input_lengths = None\n",
        "    self.lstm_last_valid_outputs = None\n",
        "    self.lstm_hidden_state = None\n",
        "    self.lstm_cell_state = None\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.lstm_packed_output, (self.lstm_hidden_state, self.lstm_cell_state) = self.lstm(input)\n",
        "\n",
        "    # Unpack padded sequence to get last valid output state\n",
        "    # before padding\n",
        "    self.lstm_output, self.lstm_input_lengths = nn.utils.rnn.pad_packed_sequence(self.lstm_packed_output, batch_first=True)\n",
        "    self.lstm_last_valid_outputs = self.lstm_output[torch.arange(self.lstm_output.size(0)), self.lstm_input_lengths - 1]\n",
        "\n",
        "    linear_output = self.linear(self.lstm_last_valid_outputs)\n",
        "\n",
        "    return linear_output\n",
        "\n",
        "Lstm = LstmModel()\n",
        "Lstm.load_state_dict(\n",
        "  torch.load(\n",
        "    f\"{MODELS_FOLDER}/model_lstm/lstm_state_dict.pth\",\n",
        "    map_location=DEVICE,\n",
        "  )\n",
        ")\n",
        "\n",
        "Lstm.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIuexKaDweLD",
        "outputId": "07458737-8736-411d-f3d6-6cd683af72e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('lstm.weight_ih_l0',\n",
              "              tensor([[-0.0299,  0.1702, -0.0789,  ..., -0.0876,  0.0782, -0.0295],\n",
              "                      [-0.0865, -0.2574, -0.1096,  ..., -0.0537, -0.1267, -0.1884],\n",
              "                      [ 0.1750,  0.0076, -0.1551,  ..., -0.2672,  0.1077,  0.1745],\n",
              "                      ...,\n",
              "                      [ 0.0542, -0.1413,  0.0746,  ...,  0.0926, -0.2215, -0.0346],\n",
              "                      [-0.0894, -0.0629, -0.2509,  ...,  0.0662, -0.1074,  0.1109],\n",
              "                      [-0.0335, -0.0938,  0.1750,  ..., -0.0449, -0.1669, -0.1992]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.weight_hh_l0',\n",
              "              tensor([[ 0.0409,  0.1266, -0.0090,  ..., -0.0003,  0.0947, -0.1279],\n",
              "                      [ 0.0620,  0.1572, -0.0572,  ..., -0.1911,  0.1077,  0.1340],\n",
              "                      [ 0.0410, -0.1172, -0.0481,  ..., -0.0174,  0.0447, -0.0930],\n",
              "                      ...,\n",
              "                      [ 0.0430, -0.0281,  0.0648,  ...,  0.1466,  0.0659, -0.0070],\n",
              "                      [ 0.0950,  0.0101, -0.0249,  ..., -0.1842, -0.0170, -0.1256],\n",
              "                      [ 0.0042,  0.0063, -0.0468,  ...,  0.0349,  0.0395,  0.1085]],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_ih_l0',\n",
              "              tensor([-0.0284, -0.1833, -0.0874,  0.0742, -0.0955,  0.0149, -0.1100,  0.0114,\n",
              "                      -0.0100, -0.0219,  0.1159,  0.0284, -0.0595,  0.0976,  0.1160, -0.0425,\n",
              "                       0.0160, -0.0479,  0.1176,  0.0865, -0.1037, -0.1309,  0.1634, -0.0588,\n",
              "                      -0.0381, -0.1295,  0.0122, -0.0880,  0.0276, -0.0307, -0.1511,  0.0802,\n",
              "                      -0.0837, -0.1317, -0.0100, -0.0081,  0.0178,  0.0541,  0.0007,  0.0855,\n",
              "                      -0.0397,  0.0810, -0.0894,  0.0376,  0.1074,  0.0506, -0.0249, -0.0618,\n",
              "                      -0.0919, -0.0157,  0.0288, -0.1365,  0.0261,  0.2154,  0.0964,  0.2062,\n",
              "                       0.0250, -0.0732,  0.0911,  0.0131,  0.0426, -0.0595, -0.0136,  0.0623,\n",
              "                      -0.1502,  0.0780, -0.0836,  0.2085,  0.0502, -0.1000, -0.1178,  0.1450,\n",
              "                       0.1257,  0.1420,  0.0020, -0.0766,  0.0573, -0.0009, -0.1699,  0.1085,\n",
              "                       0.0752, -0.0281,  0.0007,  0.0090,  0.0227, -0.0395, -0.0881,  0.1935,\n",
              "                      -0.0650, -0.0238,  0.0402, -0.0666,  0.1955,  0.0255,  0.0015, -0.0276,\n",
              "                      -0.1278,  0.1196, -0.1513,  0.0026,  0.0965,  0.0520, -0.0838, -0.0227,\n",
              "                       0.0983,  0.0797, -0.0075, -0.0638, -0.1113, -0.0012,  0.1024,  0.1040,\n",
              "                       0.0201,  0.0425, -0.0320,  0.0261, -0.1553,  0.0330, -0.0903,  0.1142,\n",
              "                      -0.1466,  0.0299, -0.0131, -0.0522,  0.0902,  0.1103,  0.0279, -0.0994,\n",
              "                      -0.0703, -0.1342,  0.0659,  0.0221, -0.0353, -0.0283,  0.0545,  0.1149,\n",
              "                      -0.0258, -0.0308,  0.1247, -0.0039, -0.0429, -0.1289, -0.0455,  0.0099,\n",
              "                      -0.0804,  0.1394,  0.1333,  0.1298,  0.0702, -0.1146, -0.0524,  0.0657,\n",
              "                      -0.0906, -0.0357, -0.0858,  0.0171,  0.0051,  0.1045,  0.1174,  0.0558,\n",
              "                      -0.0020,  0.0600, -0.1511, -0.0811,  0.0433, -0.0257, -0.0542,  0.1196,\n",
              "                      -0.0436, -0.1452, -0.0013,  0.0179, -0.0585, -0.0128,  0.2056, -0.1098,\n",
              "                      -0.1246, -0.0978,  0.0628,  0.0390,  0.1463,  0.0042, -0.0816,  0.0771,\n",
              "                       0.1410,  0.0127, -0.0070,  0.1010,  0.0838,  0.1449, -0.1358, -0.0262,\n",
              "                      -0.0939, -0.0407,  0.1696, -0.0406, -0.1690,  0.0945, -0.0476, -0.0630],\n",
              "                     device='cuda:0')),\n",
              "             ('lstm.bias_hh_l0',\n",
              "              tensor([-0.1528,  0.0002, -0.0862,  0.0023, -0.0645,  0.0768, -0.0383,  0.0054,\n",
              "                       0.0284, -0.0033, -0.1308, -0.1336, -0.0168,  0.0947, -0.0774,  0.0259,\n",
              "                      -0.0933, -0.0154, -0.0183, -0.0390, -0.0301,  0.0857,  0.0400,  0.0274,\n",
              "                      -0.0483,  0.0617,  0.1307, -0.1289, -0.0291, -0.0355,  0.0774, -0.0992,\n",
              "                       0.0100,  0.0833, -0.0563, -0.0263,  0.0587, -0.1160, -0.0630,  0.0929,\n",
              "                      -0.1810, -0.0474,  0.0774, -0.1082, -0.0716, -0.1142, -0.1774,  0.0230,\n",
              "                       0.0089,  0.0208, -0.0922, -0.0915, -0.1336,  0.0238, -0.0452, -0.0649,\n",
              "                       0.1547,  0.1139,  0.1410,  0.0290,  0.0924, -0.0530,  0.0089,  0.1226,\n",
              "                       0.0884, -0.0618,  0.1169, -0.0465,  0.0420, -0.0716, -0.0578,  0.0126,\n",
              "                       0.2013,  0.0577, -0.1157,  0.0773,  0.0772, -0.1535, -0.0207,  0.0483,\n",
              "                       0.0440,  0.1466, -0.0687,  0.0227,  0.1198, -0.1857,  0.0987, -0.0011,\n",
              "                      -0.1620,  0.1055, -0.2110, -0.0980, -0.0073, -0.0422,  0.1211,  0.1794,\n",
              "                       0.0390,  0.2199, -0.0017, -0.1177, -0.0358,  0.1709, -0.0645,  0.0182,\n",
              "                      -0.0009,  0.0332,  0.0832,  0.0625,  0.0598,  0.0558,  0.0135, -0.0618,\n",
              "                       0.0820, -0.1329, -0.0526, -0.0313, -0.1352, -0.0464, -0.0726,  0.0826,\n",
              "                      -0.1281,  0.0911, -0.0036, -0.0364,  0.0246,  0.0150, -0.1200,  0.0154,\n",
              "                      -0.0514, -0.1533,  0.1235, -0.0707,  0.1559, -0.0054, -0.0105, -0.0780,\n",
              "                       0.0229,  0.0709, -0.0992, -0.0940, -0.0887,  0.1279,  0.0819,  0.0899,\n",
              "                       0.0473,  0.0691, -0.0016, -0.0156, -0.0815,  0.1150, -0.1399, -0.1266,\n",
              "                      -0.0431,  0.1554,  0.0799,  0.1169,  0.0392,  0.0830, -0.0382, -0.0524,\n",
              "                       0.0932,  0.1330, -0.0842,  0.1104,  0.0659,  0.0910,  0.1630, -0.0222,\n",
              "                       0.1157, -0.0832,  0.1008,  0.1485,  0.1562,  0.0115,  0.1407,  0.0841,\n",
              "                       0.0365, -0.1796, -0.0336, -0.0350,  0.1474, -0.1494, -0.0037,  0.0911,\n",
              "                       0.1378, -0.1311, -0.0391, -0.0445, -0.0234, -0.0387,  0.0381,  0.0401,\n",
              "                       0.0822,  0.0128, -0.0537,  0.0287,  0.0257, -0.0499, -0.1295, -0.1444],\n",
              "                     device='cuda:0')),\n",
              "             ('linear.weight',\n",
              "              tensor([[ 0.0302, -0.1259,  0.0106, -0.0029,  0.0653,  0.1215, -0.1702, -0.1643,\n",
              "                        0.0640, -0.1033,  0.1687, -0.0858, -0.0887,  0.1754, -0.1182,  0.1825,\n",
              "                       -0.2087, -0.0482, -0.1299,  0.0003, -0.0578,  0.0281, -0.0588,  0.0137,\n",
              "                        0.2326, -0.0950, -0.1522, -0.0832, -0.0156, -0.1068,  0.1321,  0.1284,\n",
              "                       -0.1076, -0.0561,  0.1560,  0.0685, -0.0487,  0.0931, -0.0245,  0.1674,\n",
              "                       -0.0293, -0.1475,  0.2006, -0.1200,  0.1223,  0.0054, -0.1092, -0.1847,\n",
              "                       -0.0279, -0.1655],\n",
              "                      [-0.0722, -0.0440, -0.1256,  0.2212,  0.1301, -0.1528,  0.0870,  0.1540,\n",
              "                       -0.0823,  0.0562, -0.0445,  0.0454, -0.0198, -0.1679,  0.1568, -0.1435,\n",
              "                        0.0887,  0.1729,  0.0311, -0.0997, -0.0332, -0.0186,  0.1753, -0.1484,\n",
              "                       -0.0334, -0.1500,  0.1300, -0.0165,  0.0178,  0.1441, -0.0746, -0.1491,\n",
              "                        0.0271,  0.1420, -0.1496,  0.0659, -0.1677, -0.1618, -0.1184, -0.0007,\n",
              "                       -0.0377, -0.0126,  0.0340,  0.0458, -0.0273,  0.1272, -0.0604,  0.0568,\n",
              "                        0.0412,  0.1677]], device='cuda:0')),\n",
              "             ('linear.bias', tensor([-0.0310, -0.1640], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "Lstm.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5mqPM-GweLE"
      },
      "outputs": [],
      "source": [
        "softmax_function = nn.Softmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntGlonrcweLF"
      },
      "outputs": [],
      "source": [
        "def process_lstm(inputs: list):\n",
        "  tokens = get_calamancy_tokens(inputs)\n",
        "  vectors = get_token_vectors(tokens)\n",
        "  sequence_lengths = get_input_lengths(tokens)\n",
        "  vectors_padded = nn.utils.rnn.pad_sequence(\n",
        "    vectors,\n",
        "    batch_first=True,\n",
        "  )\n",
        "  vectors_packed = nn.utils.rnn.pack_padded_sequence(\n",
        "    vectors_padded,\n",
        "    sequence_lengths,\n",
        "    batch_first=True,\n",
        "    enforce_sorted=False,\n",
        "  )\n",
        "  return vectors_packed.to(DEVICE)\n",
        "\n",
        "def predict_proba_lstm(inputs: list):\n",
        "  vectors = process_lstm(inputs)\n",
        "  predictions = Lstm(vectors)\n",
        "  probabilities = softmax_function(predictions)\n",
        "\n",
        "  return probabilities.cpu()\n",
        "\n",
        "def predict_lstm(inputs: list):\n",
        "  probabilities = predict_proba_lstm(inputs)\n",
        "  discrete_probabilities = torch.argmax(\n",
        "    probabilities,\n",
        "    dim=1,\n",
        "  )\n",
        "  return discrete_probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4j5ewTeweLH"
      },
      "source": [
        "## mBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d617l8QHweLI"
      },
      "outputs": [],
      "source": [
        "BERT_MAX_LENGTH = 255\n",
        "BERT_MODEL_NAME = \"bert-base-multilingual-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhx36gP6weLJ"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "  BertForSequenceClassification,\n",
        "  BertTokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-gU7QFzweLK",
        "outputId": "fcfecbcd-2120-45e9-e50e-153b3709fbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "  BERT_MODEL_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OhXcU48weLK",
        "outputId": "cdcc6c45-6cdd-40e1-ce98-c7ad70ca00be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Bert = torch.load(\n",
        "  f'{MODELS_FOLDER}/model_bert/bert_state_dict.pth',\n",
        "  map_location=DEVICE,\n",
        ")\n",
        "\n",
        "Bert.to(DEVICE)\n",
        "\n",
        "Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-4db925weLK"
      },
      "outputs": [],
      "source": [
        "def process_bert(inputs):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in inputs:\n",
        "        # Tokenize the text\n",
        "        tokens = bert_tokenizer.tokenize(text)\n",
        "\n",
        "        # Truncate the tokens if necessary\n",
        "        if len(tokens) > BERT_MAX_LENGTH - 2:\n",
        "            tokens = tokens[:BERT_MAX_LENGTH - 2]\n",
        "\n",
        "        # Add special tokens\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        # Convert tokens to token IDs\n",
        "        token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Pad the token IDs to BERT_MAX_LENGTH\n",
        "        padding = [0] * (BERT_MAX_LENGTH - len(token_ids))\n",
        "        token_ids += padding\n",
        "\n",
        "        # Create attention mask\n",
        "        attention_mask = [1] * len(tokens) + [0] * len(padding)\n",
        "\n",
        "        input_ids.append(token_ids)\n",
        "        attention_masks.append(attention_mask)\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids).to(DEVICE)\n",
        "    attention_masks = torch.tensor(attention_masks).to(DEVICE)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Custom data loader\n",
        "def data_loader(input_ids, attention_masks, batch_size):\n",
        "    for i in range(0, len(input_ids), batch_size):\n",
        "        yield input_ids[i:i+batch_size], attention_masks[i:i+batch_size]\n",
        "\n",
        "def predict_proba_bert(inputs: list):\n",
        "  with torch.inference_mode():\n",
        "    input_ids, attention_masks = process_bert(inputs)\n",
        "\n",
        "    all_predictions = []\n",
        "    for batch_input_ids, batch_attention_masks in data_loader(input_ids, attention_masks, 16):\n",
        "      batch_input_ids = batch_input_ids.to(DEVICE)\n",
        "      batch_attention_masks = batch_attention_masks.to(DEVICE)\n",
        "\n",
        "      predictions = Bert(\n",
        "        batch_input_ids,\n",
        "        attention_mask=batch_attention_masks,\n",
        "      ).logits\n",
        "\n",
        "      probabilities = softmax_function(predictions)\n",
        "\n",
        "      all_predictions.append(probabilities)\n",
        "\n",
        "    return torch.cat(all_predictions).cpu()\n",
        "\n",
        "def predict_bert(inputs: list):\n",
        "  probabilities = predict_proba_bert(inputs)\n",
        "  discrete_probabilities = torch.argmax(\n",
        "    probabilities,\n",
        "    dim=1,\n",
        "  )\n",
        "  return discrete_probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1jxz4GDweLM"
      },
      "source": [
        "## Ensemble Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j94Zq0xSweLM"
      },
      "outputs": [],
      "source": [
        "def get_learner_predictions(inputs: list):\n",
        "  bayes_pred = predict_bayes(inputs)\n",
        "  lstm_pred = predict_lstm(inputs)\n",
        "  bert_pred = predict_bert(inputs)\n",
        "\n",
        "  return np.array([\n",
        "    bayes_pred,\n",
        "    lstm_pred,\n",
        "    bert_pred,\n",
        "  ])\n",
        "\n",
        "def get_learner_predictions_proba(inputs: list):\n",
        "  bayes_pred = predict_proba_bayes(inputs)\n",
        "  lstm_pred = predict_proba_lstm(inputs)\n",
        "  bert_pred = predict_proba_bert(inputs)\n",
        "\n",
        "  return np.array([\n",
        "    bayes_pred,\n",
        "    lstm_pred.detach().numpy(),\n",
        "    bert_pred.detach().numpy(),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "EQ9Vhzlq3d31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gf102B5S35BG",
        "outputId": "6076d364-82a3-44f2-b0f4-26a366809899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "dRZDDUJO33eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def shuffle_data_frame(data_frame):\n",
        "    text = list(data_frame['text'])\n",
        "    label = list(data_frame['label'])\n",
        "\n",
        "    assert(len(text) == len(label))\n",
        "\n",
        "    indices = list(range(len(label)))\n",
        "\n",
        "    # Make a random number generator that will shuffle list of indices\n",
        "    # It is seeded to be reproducible\n",
        "    random_number_generator = np.random.default_rng(seed=0)\n",
        "    random_number_generator.shuffle(indices)\n",
        "\n",
        "    shuffled_text = []\n",
        "    shuffled_labels = []\n",
        "\n",
        "    # Iterate through the list of indices and add the original data\n",
        "    # from those shuffled indices\n",
        "    for index in indices:\n",
        "        shuffled_text.append(text[index])\n",
        "        shuffled_labels.append(label[index])\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'text': shuffled_text,\n",
        "        'label': shuffled_labels,\n",
        "    })\n",
        "\n",
        "\n",
        "def get_train_test_split(data_frame: pd.DataFrame, test_size: float):\n",
        "    \"\"\"\n",
        "    Makes a stratified train test split.\n",
        "    This aims to preserve the distribution between classes.\n",
        "    \"\"\"\n",
        "    if not (1 >= test_size >= 0):\n",
        "        print('ERROR: test_size must be between 0 and 1')\n",
        "        return\n",
        "\n",
        "    data_frame = shuffle_data_frame(data_frame)\n",
        "\n",
        "    data_frame_length = len(data_frame)\n",
        "    train_size = 1 - test_size\n",
        "\n",
        "    nonhate_rows = data_frame[data_frame['label'] == 0]\n",
        "    nonhate_row_length = len(nonhate_rows)\n",
        "\n",
        "    nonhate_row_train_size = math.ceil(nonhate_row_length * train_size)\n",
        "\n",
        "    nonhate_row_train = nonhate_rows[0:nonhate_row_train_size]\n",
        "    nonhate_row_test = nonhate_rows[nonhate_row_train_size:nonhate_row_length]\n",
        "\n",
        "    assert(len(nonhate_row_train) + len(nonhate_row_test) == nonhate_row_length)\n",
        "\n",
        "    hate_rows = data_frame[data_frame['label'] == 1]\n",
        "    hate_row_length = len(hate_rows)\n",
        "\n",
        "    hate_row_train_size = math.ceil(hate_row_length * train_size)\n",
        "\n",
        "    hate_row_train = hate_rows[0:hate_row_train_size]\n",
        "    hate_row_test = hate_rows[hate_row_train_size:hate_row_length]\n",
        "\n",
        "    assert(len(hate_row_train) + len(hate_row_test) == hate_row_length)\n",
        "\n",
        "    combined_train = pd.concat([nonhate_row_train, hate_row_train])\n",
        "    combined_test = pd.concat([nonhate_row_test, hate_row_test])\n",
        "\n",
        "    assert(len(combined_train) + len(combined_test) == data_frame_length)\n",
        "\n",
        "    shuffled_train = shuffle_data_frame(combined_train)\n",
        "    shuffled_test = shuffle_data_frame(combined_test)\n",
        "\n",
        "    assert(len(shuffled_train) + len(shuffled_test) == data_frame_length)\n",
        "\n",
        "    return (\n",
        "        shuffled_train['text'],\n",
        "        shuffled_test['text'],\n",
        "        shuffled_train['label'],\n",
        "        shuffled_test['label'],\n",
        "    )\n",
        "\n",
        "def seed_random_number_generators(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    print(\"Random number generators seeded.\")\n",
        "\n",
        "def read_csv_file(filename: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        data = pd.read_csv(filename, lineterminator='\\n', usecols=range(2))\n",
        "        print(\"CSV file read successfully!\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(\"ERROR: File not found\")\n",
        "        exit(1)"
      ],
      "metadata": {
        "id": "tWbaAKbY3fv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = read_csv_file('/content/drive/MyDrive/School/Thesis - Hate Speech/Data/datasetall.csv')\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "g1mnQS8k3k9E",
        "outputId": "15c2a531-c49f-4f20-b73e-c9d2ac68115b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file read successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      Binay: Patuloy ang kahirapan dahil sa maling p...      0\n",
              "1      SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...      0\n",
              "2      wait so ur telling me Let Leni Lead mo pero NY...      1\n",
              "3       [USERNAME]wish this is just a nightmare that ...      0\n",
              "4                   doc willie ong and isko sabunutan po      0\n",
              "...                                                  ...    ...\n",
              "28456    Bisaya, Probinsyano/a, mostly Bisaya = katulong      1\n",
              "28457  Amnesia. In my whole life wala pa ako nakasala...      1\n",
              "28458  Kontrabida na ilang beses na tinalo at obvious...      1\n",
              "28459  Yung antagonist laging kailangang sobrang sama...      1\n",
              "28460  May nabaril or nasaksak na pero 'di pa tatawag...      1\n",
              "\n",
              "[28461 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-381af41c-9530-4553-aef9-babca72eddba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Binay: Patuloy ang kahirapan dahil sa maling p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SA GOBYERNONG TAPAT WELCOME SA BAGUO ANG LAHAT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wait so ur telling me Let Leni Lead mo pero NY...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[USERNAME]wish this is just a nightmare that ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doc willie ong and isko sabunutan po</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28456</th>\n",
              "      <td>Bisaya, Probinsyano/a, mostly Bisaya = katulong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28457</th>\n",
              "      <td>Amnesia. In my whole life wala pa ako nakasala...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28458</th>\n",
              "      <td>Kontrabida na ilang beses na tinalo at obvious...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28459</th>\n",
              "      <td>Yung antagonist laging kailangang sobrang sama...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28460</th>\n",
              "      <td>May nabaril or nasaksak na pero 'di pa tatawag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28461 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-381af41c-9530-4553-aef9-babca72eddba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-381af41c-9530-4553-aef9-babca72eddba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-381af41c-9530-4553-aef9-babca72eddba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07f16f93-19da-4f9b-b7eb-1e9929e26449\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07f16f93-19da-4f9b-b7eb-1e9929e26449')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07f16f93-19da-4f9b-b7eb-1e9929e26449 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 28461,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28149,\n        \"samples\": [\n          \"Iba talaga pag kay Dingdong nanggaling Di ko alam kung bakit naiyak ako pero naiyak ako Happy Mothers Day sa lahat ng ina at tumatayong ina < Radikal Ang Magmahal Ipana7o Na10 Para Sa Lahat Angat Buhay Lahat\",\n          \"If MarGrace &amp; Binay spends billions just to protect their IMAGEDuterte won't even try to. Hindi uso sa kanya ang pakitang tao. Du30\",\n          \"[USERNAME] [USERNAME] pagnanalo si binay POREBER mahirap na ang pinas baliw hahahah!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = 0.2\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_split(dataset, TEST_SIZE)"
      ],
      "metadata": {
        "id": "FJ8aDKak3n-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcnsKvL_3qmK",
        "outputId": "064b35f9-7f93-426e-dc91-9ec1f3ac0799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [USERNAME] Palangga ka man sang mga taga Baco...\n",
              "1                      Who dafuq is Jose Montemayor Jr.???\n",
              "2        Di na nakakatuwa yung mukha ni Mar Roxas sa TV...\n",
              "3                      national elections. | via[USERNAME]\n",
              "4        Binay will be staring in a movie called \"The D...\n",
              "                               ...                        \n",
              "22764    \"Kala ko wala andito pala si Marcos.\"*pertaini...\n",
              "22765    sie ~ [USERNAME]Marcos Magnanakaw Marcos Dikta...\n",
              "22766                    If Mar is BatMarBinay is Bane-ay.\n",
              "22767    to my moots im sorry in not sorry for flooding...\n",
              "22768                                Uunlad tayo kay Binay\n",
              "Name: text, Length: 22769, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVvzJbI13rlO",
        "outputId": "00152cf1-a78d-411b-a223-59d02f65ddb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "22764    0\n",
              "22765    1\n",
              "22766    1\n",
              "22767    1\n",
              "22768    0\n",
              "Name: label, Length: 22769, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYQWP8GM3tKK",
        "outputId": "ab0884bf-2cf1-4264-e5d6-6be154317e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                          Bakit trending ang Only Binay?\n",
              "1       Mare @ Cebu [USERNAME][USERNAME] Marcos Never ...\n",
              "2       Kahit anong gawin ko bakit di ko ma appreciate...\n",
              "3       Oras na para tayo'y bumoto ng taong mag tataas...\n",
              "4       VP[USERNAME]is currently in Zamboanga Sibugay ...\n",
              "                              ...                        \n",
              "5687      [USERNAME] Laban LeniAngat Buhay LahatLeni Kiko\n",
              "5688    Nagconcede ka man Maimarwala ka prinnagdala ka...\n",
              "5689    Did You Know that former Philippine secretary ...\n",
              "5690           Bakit nakakairita commercial ni Mar Roxas?\n",
              "5691    To Doc Willie Ong I'd like to believe you are ...\n",
              "Name: text, Length: 5692, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMhbXkQA3uFn",
        "outputId": "199d085e-7ddb-42e0-9b58-0b224332b895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "5687    0\n",
              "5688    1\n",
              "5689    0\n",
              "5690    1\n",
              "5691    0\n",
              "Name: label, Length: 5692, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "lNiuFj1D30di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = get_learner_predictions_proba(X_train)\n",
        "train_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPXxIOM24d0j",
        "outputId": "27a19ffa-69b9-4c3e-940b-963f3a493d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[9.99999993e-01, 7.00971732e-09],\n",
              "        [4.59874362e-01, 5.40125638e-01],\n",
              "        [3.32930516e-04, 9.99667069e-01],\n",
              "        ...,\n",
              "        [6.02764160e-02, 9.39723584e-01],\n",
              "        [1.63029650e-01, 8.36970350e-01],\n",
              "        [4.03064708e-01, 5.96935292e-01]],\n",
              "\n",
              "       [[8.92643750e-01, 1.07356295e-01],\n",
              "        [4.13331658e-01, 5.86668313e-01],\n",
              "        [1.74131319e-01, 8.25868726e-01],\n",
              "        ...,\n",
              "        [6.43301129e-01, 3.56698871e-01],\n",
              "        [5.15367417e-03, 9.94846344e-01],\n",
              "        [7.13888526e-01, 2.86111444e-01]],\n",
              "\n",
              "       [[9.85889912e-01, 1.41101247e-02],\n",
              "        [3.12151182e-02, 9.68784928e-01],\n",
              "        [3.60256918e-02, 9.63974357e-01],\n",
              "        ...,\n",
              "        [1.23049222e-01, 8.76950800e-01],\n",
              "        [2.19592149e-03, 9.97804105e-01],\n",
              "        [7.85229623e-01, 2.14770436e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_positive_predictions = train_predictions[:, :, 1:]\n",
        "train_positive_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqHXPz1L41Fl",
        "outputId": "4650e46d-e37b-4f23-9b87-5e3f3cf6788c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[9.99999993e-01],\n",
              "        [4.59874362e-01],\n",
              "        [3.32930516e-04],\n",
              "        ...,\n",
              "        [6.02764160e-02],\n",
              "        [1.63029650e-01],\n",
              "        [4.03064708e-01]],\n",
              "\n",
              "       [[8.92643750e-01],\n",
              "        [4.13331658e-01],\n",
              "        [1.74131319e-01],\n",
              "        ...,\n",
              "        [6.43301129e-01],\n",
              "        [5.15367417e-03],\n",
              "        [7.13888526e-01]],\n",
              "\n",
              "       [[9.85889912e-01],\n",
              "        [3.12151182e-02],\n",
              "        [3.60256918e-02],\n",
              "        ...,\n",
              "        [1.23049222e-01],\n",
              "        [2.19592149e-03],\n",
              "        [7.85229623e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transposed_predictions = train_positive_predictions.T[0]\n",
        "train_transposed_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQAAFpK75BNX",
        "outputId": "1752753d-70da-44a0-959d-9d27a3a9487d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99999993e-01, 8.92643750e-01, 9.85889912e-01],\n",
              "       [4.59874362e-01, 4.13331658e-01, 3.12151182e-02],\n",
              "       [3.32930516e-04, 1.74131319e-01, 3.60256918e-02],\n",
              "       ...,\n",
              "       [6.02764160e-02, 6.43301129e-01, 1.23049222e-01],\n",
              "       [1.63029650e-01, 5.15367417e-03, 2.19592149e-03],\n",
              "       [4.03064708e-01, 7.13888526e-01, 7.85229623e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.fit(train_transposed_predictions, y_train)\n",
        "print(\"Fitted logistic regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmyV_u9s5H88",
        "outputId": "2751c3e5-6d7d-4f5f-bca0-7c35ce73e04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitted logistic regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "VWjODPpF55Cz",
        "outputId": "87c80c22-cc37-4227-bfff-8c3bd4ec4735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ7UhNOcPnXe",
        "outputId": "b31af261-60fe-4bcd-e93f-3af1988d571e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.4308728 ,  2.10088101, -7.04175227]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdPXAe93Pvgx",
        "outputId": "d2c82387-1480-48f5-a28b-67d0bd37ecda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.31425519])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(logistic_regression, f'/content/drive/MyDrive/School/Colab/new-lr/negative-predicts/lr.pkl', compress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj3bSbwc5pIt",
        "outputId": "a98d5867-2829-479f-88e7-217240afd727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/School/Colab/new-lr/negative-predicts/lr.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(train_positive_predictions, f'/content/drive/MyDrive/School/Colab/new-lr/negative-predicts/predictions', compress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mdosq_w6ZRR",
        "outputId": "29a540ec-6860-4ba6-9c35-21a1d13f41b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/School/Colab/new-lr/negative-predicts/predictions']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUn0I81yweLP"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = get_learner_predictions_proba(X_test)\n",
        "test_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP7uU9Bs6CG5",
        "outputId": "1f687b75-ab3d-4a76-9746-d145fc209903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[8.65234865e-02, 9.13476513e-01],\n",
              "        [9.33051590e-08, 9.99999907e-01],\n",
              "        [3.98806821e-03, 9.96011932e-01],\n",
              "        ...,\n",
              "        [9.99991231e-01, 8.76931405e-06],\n",
              "        [7.42873905e-05, 9.99925713e-01],\n",
              "        [9.99999023e-01, 9.76503584e-07]],\n",
              "\n",
              "       [[2.93145716e-01, 7.06854343e-01],\n",
              "        [1.79268643e-02, 9.82073188e-01],\n",
              "        [2.78609008e-01, 7.21391022e-01],\n",
              "        ...,\n",
              "        [2.64480144e-01, 7.35519826e-01],\n",
              "        [1.60028726e-01, 8.39971244e-01],\n",
              "        [8.60738873e-01, 1.39261156e-01]],\n",
              "\n",
              "       [[8.91134739e-01, 1.08865224e-01],\n",
              "        [2.17780750e-03, 9.97822165e-01],\n",
              "        [3.86222243e-01, 6.13777757e-01],\n",
              "        ...,\n",
              "        [8.87858868e-01, 1.12141132e-01],\n",
              "        [1.03478814e-02, 9.89652097e-01],\n",
              "        [9.56674814e-01, 4.33251895e-02]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_positive_predictions = test_predictions[:, :, 1:]\n",
        "test_positive_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIvoiWuz6NSl",
        "outputId": "4499c7f4-0a8e-4416-f7a7-ea6666a13060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[8.65234865e-02],\n",
              "        [9.33051590e-08],\n",
              "        [3.98806821e-03],\n",
              "        ...,\n",
              "        [9.99991231e-01],\n",
              "        [7.42873905e-05],\n",
              "        [9.99999023e-01]],\n",
              "\n",
              "       [[2.93145716e-01],\n",
              "        [1.79268643e-02],\n",
              "        [2.78609008e-01],\n",
              "        ...,\n",
              "        [2.64480144e-01],\n",
              "        [1.60028726e-01],\n",
              "        [8.60738873e-01]],\n",
              "\n",
              "       [[8.91134739e-01],\n",
              "        [2.17780750e-03],\n",
              "        [3.86222243e-01],\n",
              "        ...,\n",
              "        [8.87858868e-01],\n",
              "        [1.03478814e-02],\n",
              "        [9.56674814e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transposed_predictions = test_positive_predictions.T[0]\n",
        "test_transposed_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UFYm-Mf6Qdz",
        "outputId": "22884acd-111d-4d7f-82f4-0603288ff58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.65234865e-02, 2.93145716e-01, 8.91134739e-01],\n",
              "       [9.33051590e-08, 1.79268643e-02, 2.17780750e-03],\n",
              "       [3.98806821e-03, 2.78609008e-01, 3.86222243e-01],\n",
              "       ...,\n",
              "       [9.99991231e-01, 2.64480144e-01, 8.87858868e-01],\n",
              "       [7.42873905e-05, 1.60028726e-01, 1.03478814e-02],\n",
              "       [9.99999023e-01, 8.60738873e-01, 9.56674814e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = logistic_regression.predict(test_transposed_predictions)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCPcCTY-7ADP",
        "outputId": "26266712-fe01-4240-cb41-092033d68944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GueWiY7_6obg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_wfCviHO9YC",
        "outputId": "08a1f5ca-f575-4c35-f074-75bd0878d50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8608573436401967"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stacking_conf_matrix = confusion_matrix(y_test, y_preds)\n",
        "\n",
        "stacking_matrix_display = ConfusionMatrixDisplay(stacking_conf_matrix)\n",
        "\n",
        "stacking_matrix_display.plot()\n",
        "\n",
        "plt.title(\"Stacking\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mQTomIlt61Bf",
        "outputId": "7bfbea14-9c7d-48d7-a375-c6a615c0524a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}